<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Selection on 基于LLM的系统设计与实现</title>
    <link>https://www6v.github.io/www6vAIGC/categories/Data-Selection/</link>
    <description>Recent content in Data Selection on 基于LLM的系统设计与实现</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Fri, 05 May 2023 19:14:41 +0000</lastBuildDate>
    <atom:link href="https://www6v.github.io/www6vAIGC/categories/Data-Selection/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>(原理)Data Selection</title>
      <link>https://www6v.github.io/www6vAIGC/docs/FineTuning/Data/DataSelection/</link>
      <pubDate>Fri, 05 May 2023 19:14:41 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAIGC/docs/FineTuning/Data/DataSelection/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;ifd1&#34;&gt;&#xA;  IFD[1]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#ifd1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;三个步骤&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Learning from Brief Experience&#xA;利用少量进行进行&lt;strong&gt;模型初学&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Evaluating Based on Experience&#xA;利用初学模型计算原始数据中所有&lt;strong&gt;IFD指标&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;算法&#xA;&lt;ul&gt;&#xA;&lt;li&gt;条件回答分数（ Conditioned Answer Score，CAS）&lt;/li&gt;&#xA;&lt;li&gt;直接答案分数（Direct Answer Score，DAS）&lt;/li&gt;&#xA;&lt;li&gt;指令跟随难度（Instruction-Following Difficulty，IFD）分数&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Retraining from Self-Guided Experience&#xA;利用&lt;strong&gt;樱桃数据&lt;/strong&gt;进行模型&lt;strong&gt;重训练&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;mods2&#34;&gt;&#xA;  MoDS[2]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#mods2&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;质量筛选&#xA;采用OpenAssistant的&lt;strong&gt;reward-model&lt;/strong&gt;-debertav3-large-v2模型（一个基于&lt;strong&gt;DeBERTa架构&lt;/strong&gt;设计的奖励模型）对数据进行&lt;strong&gt;质量打分&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;多样性筛选&#xA;为了避免所选质量数据高度相似，通过&lt;strong&gt;K-Center-Greedy算法&lt;/strong&gt;进行数据筛选，在最大化多样性的情况下，使指令数据集最小。&#xA;在该步骤中，采用&lt;strong&gt;BERT模型&lt;/strong&gt;为指令数据生成句向量来计算不同数据之间的距离。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;必要性筛选&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;deita-3&#34;&gt;&#xA;  DEITA [3]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#deita-3&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h3 id=&#34;复杂性评分&#34;&gt;&#xA;  复杂性评分&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%a4%8d%e6%9d%82%e6%80%a7%e8%af%84%e5%88%86&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;复杂性评估的方法&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Random Selection：随机选择样本。&lt;/li&gt;&#xA;&lt;li&gt;Instruction Length：按照指令的长度计算复杂性。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Perplexity&lt;/strong&gt;：通过预训练模型计算回复的困惑度作为复杂性指标，困惑值越大意味着数据样本越难。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Direct Scoring&lt;/strong&gt;：利用ChaGPT给指令的复杂性打分。&lt;/li&gt;&#xA;&lt;li&gt;Instruction Node：利用ChatGPT将指令转换成语义树，通过树的节点数作为复杂性指标。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Instag Complexity&lt;/strong&gt;：利用ChatGPT对部分数据进行打标签，再训练一个Llama模型，再利用训练后的Llama模型对全量数据预测，标签越多说明数据约复杂。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;IFD&lt;/strong&gt;：指令跟随难度作为复杂性指标。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;DEITA评估复杂性的方法，主要先对一个小规模种子数据集（2k）进行数据复杂性&lt;strong&gt;扩展&lt;/strong&gt;，再利&lt;strong&gt;用ChatGPT对扩展数据进行打分&lt;/strong&gt;，并&lt;strong&gt;训练一个Llama1-7B的模型&lt;/strong&gt;，最后利用训练后的模型对数据的打分作为复杂性评估指标。&lt;/p&gt;&#xA;&lt;h3 id=&#34;质量评分&#34;&gt;&#xA;  质量评分&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e8%b4%a8%e9%87%8f%e8%af%84%e5%88%86&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;质量评估的方法有&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Random Selection：随机选择样本。&lt;/li&gt;&#xA;&lt;li&gt;Response Length：采用输出长度作为质量评估指标。&lt;/li&gt;&#xA;&lt;li&gt;Direct Scoring：利用ChatGPT直接评估对特定指令输出结果的准确性。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;DEITA评估质量的方法，&lt;strong&gt;与评估复杂性方法一致&lt;/strong&gt;。先对一个小规模种子数据集（2k，与复杂性数据一致）进行数据质量扩展，再利用ChatGPT对扩展数据进行打分并训练一个Llama1-7B的模型，最后利用训练后的模型对数据的打分作为质量评估指标。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
