<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Langchain on 基于LLM的系统设计与实现</title>
    <link>https://www6v.github.io/www6vAIGC/categories/Langchain/</link>
    <description>Recent content in Langchain on 基于LLM的系统设计与实现</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Wed, 11 Jan 2023 17:08:21 +0000</lastBuildDate>
    <atom:link href="https://www6v.github.io/www6vAIGC/categories/Langchain/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Langchain</title>
      <link>https://www6v.github.io/www6vAIGC/docs/Langchain/Langchain/</link>
      <pubDate>Wed, 02 Nov 2022 10:45:06 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAIGC/docs/Langchain/Langchain/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xD;&#xA;&lt;!-- more --&gt;&#xD;&#xA;&lt;h1 id=&#34;modules&#34;&gt;&#xA;  Modules&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#modules&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;main-modules&#34;&gt;&#xA;  main modules&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#main-modules&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;model-io&#34;&gt;&#xA;  Model I/O&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#model-io&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Language models  [10]&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLM&lt;/li&gt;&#xA;&lt;li&gt;Chat Model&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Embedding&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Prompts&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Prompt Template&lt;/li&gt;&#xA;&lt;li&gt;Few-shot example&lt;/li&gt;&#xA;&lt;li&gt;Example Selectors [类比选择]&#xA;关键字  相似度  长度&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Output parsers&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;function call&lt;/strong&gt;[2]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;retrieval&#34;&gt;&#xA;  Retrieval&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#retrieval&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Document Loaders&lt;/li&gt;&#xA;&lt;li&gt;Text Splitters&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Retrievers&lt;/strong&gt;[10]&lt;/li&gt;&#xA;&lt;li&gt;VectorStores&lt;/li&gt;&#xA;&lt;li&gt;index&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;agent&#34;&gt;&#xA;  Agent&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#agent&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Plan-and-execute agents&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;additional-modules&#34;&gt;&#xA;  Additional modules&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#additional-modules&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;chains&#34;&gt;&#xA;  Chains&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#chains&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;2大类&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Chain interface[Legacy]&lt;/li&gt;&#xA;&lt;li&gt;LangChain Expression Language (LCEL)&#xA;LCEL is a declarative way to compose chains.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Foundational&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLM&lt;/li&gt;&#xA;&lt;li&gt;Sequential- SequentialChain&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Router&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;Transformation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;memory-10&#34;&gt;&#xA;  Memory [10]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#memory-10&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;帮语言模型补充上下文&lt;/li&gt;&#xA;&lt;li&gt;ConversationBufferMemory&lt;/li&gt;&#xA;&lt;li&gt;ConversationBufferWindowMemory&#xA;窗口&lt;/li&gt;&#xA;&lt;li&gt;ConversationSummaryMemory&lt;/li&gt;&#xA;&lt;li&gt;VectorStoreRetrieverMemory&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;function-call&#34;&gt;&#xA;  Function Call&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#function-call&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; langchain.chains.openai_functions.base &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; (&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    create_openai_fn_chain,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    create_structured_output_chain,[&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; langchain.chains.openai_functions.citation_fuzzy_match &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; (&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    create_citation_fuzzy_match_chain,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; langchain.chains.openai_functions.extraction &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; (&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    create_extraction_chain,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    create_extraction_chain_pydantic,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; langchain.chains.openai_functions.qa_with_structure &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; (&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    create_qa_with_sources_chain,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    create_qa_with_structure_chain,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;from&lt;/span&gt; langchain.chains.openai_functions.tagging &lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; (&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    create_tagging_chain,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    create_tagging_chain_pydantic,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;应用4&#34;&gt;&#xA;  应用[4]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%ba%94%e7%94%a84&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Question &amp;amp; Answering Using Documents As Context[3]&lt;/li&gt;&#xA;&lt;li&gt;Extraction[Kor]&lt;/li&gt;&#xA;&lt;li&gt;Evaluation&lt;/li&gt;&#xA;&lt;li&gt;Querying Tabular Data[sqlite]&lt;/li&gt;&#xA;&lt;li&gt;Code Understanding&lt;/li&gt;&#xA;&lt;li&gt;Interacting with APIs&lt;/li&gt;&#xA;&lt;li&gt;Chatbots&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;chains-1-89&#34;&gt;&#xA;  Chains [1] [8][9]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#chains-1-89&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;chain &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; load_summarize_chain(llm, chain_type&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;stuff&amp;#34;&lt;/span&gt;, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;chain &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; load_summarize_chain(llm, chain_type&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;map_reduce&amp;#34;&lt;/span&gt;, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;chain &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; load_summarize_chain(llm, chain_type&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;refine&amp;#34;&lt;/span&gt;, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;chain &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; load_qa_chain(llm, chain_type&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;map_rerank&amp;#34;&lt;/span&gt;, verbose&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;, return_intermediate_steps&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;True&lt;/span&gt;)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;链类型&lt;/th&gt;&#xA;          &lt;th&gt;整合方法&lt;/th&gt;&#xA;          &lt;th&gt;优缺点&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;stuff&lt;/td&gt;&#xA;          &lt;td&gt;将所有内容放入一个提示中，输入LLM&lt;/td&gt;&#xA;          &lt;td&gt;简单、廉价、效果好/ 对输入文本有一定token限制&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Map_reduce&lt;/td&gt;&#xA;          &lt;td&gt;每个问题和文本块单独给语言模型，并将答案汇总生成最终结果&lt;/td&gt;&#xA;          &lt;td&gt;输入任意数量文本，且并行处理/ 速度慢，费token&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Refine&lt;/td&gt;&#xA;          &lt;td&gt;迭代处理多个文本，基于前一个文档答案构建下一个答案&lt;/td&gt;&#xA;          &lt;td&gt;用于组合信息，依次构建答案/ 速度慢，费token&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Map_rerank&lt;/td&gt;&#xA;          &lt;td&gt;每个文档单独调用LLM,并要求返回一个得分，然后选择最高的得分&lt;/td&gt;&#xA;          &lt;td&gt;需要告诉模型评分的规则/ 费token&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;&lt;img src=&#34;./images/chains-type.jpg&#34; alt=&#34;chains-type&#34; /&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Langchain  Agent</title>
      <link>https://www6v.github.io/www6vAIGC/docs/Langchain/LangchainAgent/</link>
      <pubDate>Wed, 11 Jan 2023 17:08:21 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAIGC/docs/Langchain/LangchainAgent/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;langchain-agent&#34;&gt;&#xA;  Langchain Agent&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#langchain-agent&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Conversational&lt;/li&gt;&#xA;&lt;li&gt;OpenAI assistants&lt;/li&gt;&#xA;&lt;li&gt;OpenAI functions&lt;/li&gt;&#xA;&lt;li&gt;OpenAI Multi Functions Agent&lt;/li&gt;&#xA;&lt;li&gt;OpenAI tools&#xA;OpenAI parallel function calling (a.k.a. tool calling)&lt;/li&gt;&#xA;&lt;li&gt;ReAct&#xA;ZeroShotReactAgent&lt;/li&gt;&#xA;&lt;li&gt;Self-ask with search&lt;/li&gt;&#xA;&lt;li&gt;Structured tool chat&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;langchain-apps&#34;&gt;&#xA;  Langchain Apps&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#langchain-apps&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h3 id=&#34;rag-chroma-private-2&#34;&gt;&#xA;  rag-chroma-private [2]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#rag-chroma-private-2&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;本地 部署&lt;/strong&gt;&#xA;This template performs RAG with no reliance on external APIs.&#xA;It utilizes &lt;strong&gt;Ollama the LLM, GPT4All for embeddings, and Chroma for the vectorstore&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;h3 id=&#34;research-assistant-34&#34;&gt;&#xA;  research-assistant [3][4]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#research-assistant-34&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;p&gt;This template implements a version of&#xA;&amp;ldquo;GPT Researcher&amp;rdquo; that you can use as a starting point for a &lt;strong&gt;research agent&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
