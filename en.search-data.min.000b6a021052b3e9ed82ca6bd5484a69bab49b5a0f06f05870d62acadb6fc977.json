[{"id":0,"href":"/www6vAIGC/docs/Agent/Communication/MCPSurvey/","title":"(综述)MCP +","section":"Communication *","content":"\nMCP 综述 # (综述)MCP\n"},{"id":1,"href":"/www6vAIGC/docs/Prompt-Engineering/Prompting101/","title":"(原理) 谷歌 Prompting guide 101 *","section":"Prompt Engineering","content":" 四个核心要素 # 1. Persona（角色） # 定义：使用者身份/职业定位，决定AI的回应视角\n关键作用：\n帮助AI理解用户的专业背景和需求层次 使输出内容更符合特定角色的思维方式和表达习惯 应用示例：\n行政支持：\u0026ldquo;You are a program manager in [industry]\u0026quot;（项目管理者身份） 市场营销：\u0026ldquo;I am a PR manager at [company name]\u0026quot;（公关经理身份） 技术岗位：\u0026ldquo;As the CIO at [company]\u0026quot;（首席信息官身份） 最佳实践：\n使用明确职称（如\u0026quot;executive assistant\u0026rdquo;） 补充行业属性（如\u0026quot;in the personal care industry\u0026rdquo;） 需保持角色一致性（同一会话中不宜切换角色） 2. Task（任务） # 定义：需要AI完成的具体工作指令\n关键作用：\n明确操作类型（生成/总结/分析/优化等） 界定输出内容的范围与深度 应用示例：\n内容生成：\u0026ldquo;Draft an executive summary email\u0026rdquo;（起草邮件） 数据分析：\u0026ldquo;Identify trends in customer feedback\u0026rdquo;（趋势分析） 流程优化：\u0026ldquo;Create a budget tracker for business travel\u0026rdquo;（创建模板） 最佳实践：\n必须包含动词（如generate/summarize/analyze） 明确操作对象（邮件/表格/报告等） 分层递进（主任务→子任务） 3. Context（上下文） # 定义：任务相关的背景信息与约束条件\n关键作用：\n提供必要的业务场景信息 确保输出内容的准确性和相关性 应用示例：\n行业背景：\u0026ldquo;newly formed team of content marketers\u0026rdquo;（团队构成） 数据来源：\u0026ldquo;based on @[Product Launch Notes]\u0026quot;（引用文件） 限制条件：\u0026ldquo;within 10-minute walk of the hotel\u0026rdquo;（地理限制） 最佳实践：\n使用占位符动态引用（[industry]/[date]等） 关联Workspace文件（@file语法调用云端文档） 说明特殊要求（如合规/隐私限制） 4. Format（格式） # 定义：期望的输出结构与呈现方式\n关键作用：\n规范内容组织逻辑 提高信息可读性和实用性 应用示例：\n结构化数据：\u0026ldquo;Put it in a table format\u0026rdquo;（表格格式） 视觉呈现：\u0026ldquo;Create an image of a trade show booth\u0026rdquo;（图像生成） 文本规范：\u0026ldquo;Limit to bullet points\u0026rdquo;（要点列表） 最佳实践：\n明确格式类型（邮件/报告/图表等） 指定内容层级（标题/段落/项目符号） 设置量化指标（如\u0026quot;3 different icebreaker activities\u0026rdquo;） 综合应用案例 # 场景：行政助理制定差旅行程\n提示词结构：\n\u0026quot;I am an executive assistant. Create a 2-day business trip itinerary in [location] during [dates]. Include breakfast/dinner options within 10-minute walk of [hotel], and one entertainment option. Put it in a table.\u0026quot;\n要素拆解：\nPersona：Executive assistant（角色定位） Task：Create itinerary（核心任务） Context：Business trip + location/time constraints（场景限制） Format：Table with specified columns（表格呈现） 优化建议 # 迭代优化：通过\u0026quot;Make this a power prompt\u0026quot;指令让AI优化原始提示 动态引用：使用@file语法调用云端文档增强上下文关联性 分层提示：复杂任务分解为\u0026quot;主提示→细化提示→格式调整\u0026quot;多轮对话 语气控制：通过\u0026quot;formal/casual/upbeat\u0026quot;等形容词调整输出语调 文档强调，有效提示的平均长度约21词（含关键上下文），而用户初始尝试往往不足9词，建议通过这四个要素的系统应用提升提示质量。\n参考 # Prompting Guide 101 更偏向各行各业的提示案例和实践， 围绕 Persona（角色）、Task（任务）、Context（上下文）、Format（格式）四要素展开： 【腾讯元宝 生成 根据文档内容，围绕\u0026quot;Persona（角色）、Task（任务）、Context（上下文）、Format（格式）\u0026ldquo;四个核心要素的解析如下：】\n"},{"id":2,"href":"/www6vAIGC/docs/Agent/Platform/Dify/","title":"(实现)Dify *","section":"Platform *","content":" Dify # 从零开始学 Dify-系统架构\n从零开始学 Dify- 工作流(Workflow)系统架构\n从零开始学 Dify - 一文搞懂 Dify 消息队列与任务调度的设计精髓\n"},{"id":3,"href":"/www6vAIGC/docs/Deep-Research/%E5%AE%9E%E7%8E%B0/DeepResearch/","title":"(原理\u0026实战)Deep Research","section":"实现","content":"\nDeep Research # (原理\u0026amp;实战)Deep Research\n"},{"id":4,"href":"/www6vAIGC/docs/FineTuning/%E5%AE%9E%E8%B7%B5/FineTuningBestPractice/","title":"(最佳实践)SFT  +","section":"实践 *","content":"\nSFT BestPractice # SFT BestPractice\n"},{"id":5,"href":"/www6vAIGC/docs/RAG/Pattern/RAGPattern/","title":"(原理) RAG Pattern *","section":"Pattern","content":"\n7 种 RAG 模式 # Naive RAG 是最基础的架构，包含简单的文档检索、处理和生成响应的流程 Retrieve-and-rerank 在基础 RAG 上增加了重排序步骤，可以优化检索结果的相关性 Multimodal RAG 能够处理图像等多种类型的数据，不仅限于文本 Graph RAG 利用图数据库增强知识连接，可以更好地理解文档间的关系 Hybrid RAG 结合了多种技术的优势，包含图结构和传统检索方法 Agentic RAG Router 使用 AI Agent 来路由和处理查询，可以选择最适合的处理路径 Agentic RAG Multi-Agent 使用多个专门的 AI Agent 协同工作，可以调用不同的工具（如向量搜索、网页搜索、Slack、Gmail 等） 核心组件 # 嵌入模型：将文本转换为向量表示 生成模型：负责最终的内容生成 重排序模型：优化检索结果的相关性 向量数据库：存储和检索向量化的内容 提示模板：规范化的查询处理模板 AI Agent：智能决策和任务协调 参考 # RAG 架构图解：从基础到高级的7种模式\nRAG 架构图解：从基础到高级的7种模式 x\n"},{"id":6,"href":"/www6vAIGC/docs/RAG/Pattern/KG-RAG/graphRAG/","title":"GraphRAG +","section":"KG-RAG","content":"\nGraphRAG # GraphRAG\n"},{"id":7,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/RAGBestPractice/","title":"(Work)RAG 最佳实践 +","section":"实战 *","content":" 最佳实践 # Best Practices\n"},{"id":8,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/RAG-ant/","title":"(蚂蚁)RAG","section":"实战 *","content":" Arch # 最重要 → 文档预处理 离线知识加工 pipeline # 【pipeline】\n知识抽取与生成 # 【 chunk - markdown 的chunk】\n【要素 标签】\n【markdown - chunking 器\n层级知识保留， chunk完后是张图】\nquery理解 # 【推理模型 - 大篇幅的意图理解 】\n参考 # 蚂蚁数科 AI Agent知识工程实践 datafun "},{"id":9,"href":"/www6vAIGC/docs/RAG/Pattern/Agentic-RAG/AgenticRAG/","title":"(原理|实战)Agentic RAG +","section":"Agentic RAG","content":"\nAgentic RAG # (原理|实战)Agentic RAG\n"},{"id":10,"href":"/www6vAIGC/docs/RAG/phase/phaseRAGIndex/RAGIndex/","title":"(原理) Index +","section":"(Phase)index","content":"\nIndex # (原理) Index\n"},{"id":11,"href":"/www6vAIGC/docs/RAG/phase/phaseRAGIndex/RAGChunk/","title":"(原理|实战) Chunk +","section":"(Phase)index","content":"\nChunk # (原理|实战) Chunk\n"},{"id":12,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Planning/AgentPlanning/","title":"Agent Planning","section":"Planning","content":"\nTypes[1] # 任务分解\n多计划选择\n外部规划器辅助规划\n反思和提炼[20]\n记忆增强规划\n任务分解 # ReACT 范式 [2] 把融合了Reasoning和Acting的一种范式，推理过程是浅显易懂，仅仅包含thought-action-observation步骤，很容易判断推理的过程的正确性，使用ReAct做决策甚至超过了强化学习.\nchain-of-thought推理-问题 事实幻想（fact hallucination）和错误传递（error propagation） Plan-and-execute agents [2] 本质上是先计划再执行，即先把用户的问题分解成一个个的子任务，然后再执行各个子任务，最后合并输出得到结果\nPatterns # Self-ask [2] Self-ask是一种follow-up的使用范式，仅仅包含follow-up, immediate answer步骤，至于follow-up多少个step，完全由它自己决定，估计这就是Self-ask的名字的由来。 参考 # 《Understanding the planning of LLM agents: A survey》\n大语言模型智能体规划能力综述: 分类、任务分解、选择、反思、记忆增强 翻译\nAgent四大范式 | 综述：全面理解Agent工作原理\n2023年新生代大模型Agents技术,ReAct,Self-Ask,Plan-and-execute,以及AutoGPT, HuggingGPT等应用 *** 论文+代码\n{% post_link \u0026lsquo;gptAgentReflection\u0026rsquo; %} self\n1xx. AI Agent规划能力全面拆解\n1xx. 引领语言智能：从思维链推理到语言智能体的探索指南 [译] paper\n1xx. 2023年大语言模型智能体规划技术(LLM Agent Planning)研究进展汇总\n"},{"id":13,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/framework/RAGFramework/","title":"RAG Framework","section":"framework","content":"\n框架 [0] # ragflow\nQAnything\nlangchainchat\nFastGPT\nLangChain\nLlamaIndex\nlangchain4j\nGPT-RAG\nUnstructured\nQuivr\nDify\nVerba\ndanswer\n参考 # 大模型RAG问答研发真实图鉴：一周出Demo，半年用不好，缝补之路漫漫 1xx. 大模型RAG问答开源框架的两个风向:兼看大模型安全的学术评测 RAGFlow - 引入文档理解及溯源机制 QAnything - 优化embeddding+召回侧方向的\n1xx. LlamaHub\nMix and match our Data Loaders and Agent Tools to build custom RAG apps or use our LlamaPacks as a starting point for your retrieval use cases.\n1xx. FlashRAG：可能是最全的、最快搭建RAG的开源框架 "},{"id":14,"href":"/www6vAIGC/docs/RAG/phase/phaseRAGPreRetrieval/QueryRewrite/","title":"(原理|实战)Query Rewrite","section":"(Phase)pre-retrival","content":"\nQuery rewrite # query rewrite [1][2] # 论文使用LLM重写用户查询，而不是直接使用原始用户查询进行检索。 因为对于LLM 而言，原始查询不可能总是最佳检索结果，可以让LLM重写查询。 Repo git 【问题的多样化】 Transformation-多样性 # Step Back # Step Back问答回退策略 [3] # Step Back问答回退，首先提示LLM提出一个关于高级概念或原则的通用后退问题，并检索有关它们的相关事实，使用此基础来帮助回答用户问题。\nStep-back Prompting [1][2] # 论文使用退一步提示，使用LLM生成\u0026quot;后退\u0026quot;(Step back prompting)问题。 使用检索时，\u0026ldquo;后退\u0026quot;问题和原始问题都会被用来进行检索，然后这两个结果都会被用来作为语言模型回复的基础。 Repo git 【问题的抽象化】 Transformation-抽象化 # HyDE # HyDE混合策略[3] # LLM将问题转换为回答问题的假设文档。使用嵌入的假设文档检索真实文档，前提是doc-doc相似性搜索可以产生更多相关匹配。\nHyDE At a high level, HyDE is an embedding technique that takes queries, generates a hypothetical answer, and then embeds that generated document and uses that as the final example. Transformation-具体化 # 参考 # 知识图谱用于细粒度大模型幻觉评估：兼论Langchain-RAG问答中的问题改写范式 RAG: rewrite , Step back, fusion\nQuery Transformations\n一文详看Langchain框架中的RAG多阶段优化策略：从问题转换到查询路由再到生成优化 *** 原理paper，代码示例\nMulti Query多查询策略， Decomposition问题，RAG-Fusion， Step Back， HyDE混合\nrag-from-scratch Repo git\nRAG(检索增强） 从入门到精通 虚拟文档嵌入（Hyde) V\n1xx. 业界总结｜搜索中的Query理解 ***\n1xx. 智能扩充机器人的“标准问”库之Query生成\nLLM之RAG实战（二十八）| 探索RAG query重写\n高级RAG检索中的五种查询重写策略\n"},{"id":15,"href":"/www6vAIGC/docs/RAG/phase/phaseRAGPreRetrieval/QueryTransformation/","title":"(原理|实战)Query Transformation","section":"(Phase)pre-retrival","content":"\nQuery Transformation # Multi Query多查询策略[3] # 该方法从多个角度重写用户问题，为每个重写的问题检索文档，返回所有查询的唯一文档。\nDecomposition问题分解策略[3] # Answer recursively迭代式回答 在问题分解的基础上，逐步迭代出答案，将上一步问题的答案，与下一步骤的答案进行拼接，送入大模型进行问答\nAnswer individually 也可以让每个subquery分别进行处理，然后得到答案，然后再拼接成一个QA pairspprompt最终形成答案。\n参考 # xxx\nxxx\n一文详看Langchain框架中的RAG多阶段优化策略：从问题转换到查询路由再到生成优化 *** 原理paper，代码示例\n[Multi Query多查询策略， Decomposition问题]， RAG-Fusion， Step Back， HyDE混合\nrag-from-scratch Repo git\n"},{"id":16,"href":"/www6vAIGC/docs/RAG/Pattern/Multimodal-RAG/RAGMultimodal/","title":"(Survey)多模态 RAG +","section":"Multimodal RAG","content":"\n多模态 RAG # (Survey)多模态 RAG\n"},{"id":17,"href":"/www6vAIGC/docs/FineTuning/Data/Data-Quality/Instruction-Diversity/SelfInstruct/","title":"(原理)SELF-INSTRUCT+","section":"Instruction Diversity","content":"\nSELF-INSTRUCT # (原理)SELF-INSTRUCT\n"},{"id":18,"href":"/www6vAIGC/docs/Agent/Multi-agent/MultiAgents/","title":"(原理)Multi-Agents +","section":"Multi-agent *","content":"\nMulti-Agents 原理 # (原理)Multi-Agents\n"},{"id":19,"href":"/www6vAIGC/docs/FineTuning/Instruct-Tuning/InstructTuning/","title":"(原理)Instruct Tuning","section":"Instruct Tuning","content":"\nIn Context Learning ( ICL ) 上下文学习 # in context learning，大意是在prompt learning的基础上，将少量有标签样本融入prompt。 上图的ICL模型可以理解成有监督、无训练的小样本学习。 但并非所有ICL都不训练。比如下图右上角的FLAN就是用instruction tuning训练参数的。 FLAN，既属于 in context learning，也属于 instruction learning Instruction Learning [1] # Instruct Tuning- # FLANv1, FLANv2 instructGPT # chatGPT # Instruction Tuning # 对于已有的预训练模型，继续在多项任务（B、C、D等）上做训练，在其他任务（A）上做预测。虽然依然没见过任务A，但是根据对B、C、D等的训练，对A的效果有所提升； [1]\nInstruct Tuning 本质上也是Prompt Tuning [2]\n研究了缩放对指令微调的影响 [3] 与微调指令的任务数量有关，任务数量越多效果越好 与模型的大小有关，模型越大效果越好\nPrompt vs. Instruction Tuning [4] Prompt是去激发语言模型的补全能力，比如给出上半句生成下半句、或者做完形填空，都还是像在做language model任务. 而Instruction Tuning则是激发语言模型的理解能力，通过给出更明显的指令/指示，让模型去理解并做出正确的action Prompt tuning都是针对一个任务的，比如做个情感分析任务的prompt tuning，精调完的模型只能用于情感分析任务，而经过Instruction Tuning多任务精调后，可以用于其他任务的zero-shot\nInstruction Tuning 指令微调 [4]\nSelf Instruction Alpaca = LLaMA + Intruction Tuning [2] Limitation of instruction finetuning [2] # 问题1. 开放性问题 问题2. 看图\n参考 # 各种tuning的简单逻辑解释\n第九课：Instruct Tuning *** V\nFLANv2：大模型指令微调必看论文\nInstruction Tuning｜谷歌Quoc V.Le团队提出又一精调范式\n1xx. June 2023, A Stage Review of Instruction Tuning\n1xx. 【LLM系列之FLAN-T5/PaLM】Scaling Instruction-Finetuned Language Models\n1xx. 如何优化大模型的In-Context Learning效果？\n1xx. Instruction Tuning（FLAN、instructGPT、chatGPT）\n"},{"id":20,"href":"/www6vAIGC/docs/FineTuning/PEFT/Soft-Prompt/PromptTuning/","title":"(原理)Prompt Tuning","section":"Soft Prompt","content":"\nNPL范式 [1] # Prompt Tuning [2] # 🔔 Prompt Tuning 🔗 文章：The Power of Scale for Parameter-Efficient Prompt Tuning (EMNLP 2021) https://aclanthology.org/2021.emnlp-main.243/ 🔑关键词和摘要 Keywords: Large-scale PLMs, Parameter-efficient Tuning, Prompt Tuning 摘要 Prompt变成可学习的向量，固定PLM，微调Prompt来适配下游任务 PLM参数规模越大，Prompt Tuning的性能和全参数微调越接近 这种基于Soft Prompt的Prompt Tuning方法可以看作是Prefix Tuning的简化版本（只加在输入上） ⚙️研究设计和结论 方法 模型示意图：xxx 模型基本思路： 经典分类：P(Y | X; θ) Hard Prompt: P(Y | [P;X] ; θ) Soft Prompt: P(Y | [P;X] ; θ; Δ) Pre-Training Fine-Tuning Prompt Tuning 实现细节： 模型参数量 参数量：T5 ~ T5-XXL(10B) 预训练：LM Adaptation Prompt长度：xxx 1、5、20、100、150 初始化方法：xxx 随机初始化 使用预设文本的词向量初始化，类似于设计hard prompt，然后将hard prompt转化为soft prompt 使用类别词向量初始化，类似于提供选项 实验 数据集：SuperGLUE xxx Prompt的规模越大，性能相对而言会越好 xxx 基于语义信息的初始化比随机初始化要好 xxx LM Adaptation 对性能提升显著 Prompt Tuning还是需要大模型有较好的文本生成能力 xxx 模型参数规模越大，Prompt Tuning效果越好 10B参数时与全参数微调性能接近 📚论文贡献 优点（计算友好） 大模型的微调新范式 一个中心模型服务多个下游任务，节省参数存储量 无需优化模型参数，节省优化器的计算量和存储量 只在输入层进行操作，适合多任务场景下的计算合并 缺点（性能和收敛性存在问题） Prompt Tuning的收敛速度很慢 Prompt Tuning的模型性能不稳定 Few-shot场景上表现不佳 Prompt Tuning[3] # Allow an additional k tunable tokens per downstream task to be prepended to the input text No intermediate-layer prefixes or task-specific output layers Freeze the entire pre-trained model and only optimize the embedding layer 参考 # [综述]鹏飞大神的Pre-train, Prompt, and Predict [1]\n清华博后带你轻松吃透Prompt Tuning顶会大模型论文 V\n第七课：Prompt Tuning *** V 有ppt\n1xx. 近代自然语言处理技术发展的“第四范式” Prompt Learning\n1xx. Prompt范式的缘起｜Pattern-Exploiting Training\n1xx. Prompt范式第二阶段｜Prefix-tuning、P-tuning、Prompt-tuning\nP-tuning v2 # 1xx. 清华P-tuning v2、谷歌SPoT｜Prompt可以超过精调了吗？\n"},{"id":21,"href":"/www6vAIGC/docs/Application/NL2SQL/NL2SQL/","title":"NL2SQL","section":"NL2SQL","content":" 参考 # 1xx. 大模型与数据科学：从Text-to-SQL 开始（一） 多款产品\n实践\u0026amp;优化 # 1xx. LLM在中文Text2SQL的实践 1xx. LLM在中文Text2SQL任务上的优化V2.0 1xx. LLM在中文Text2SQL任务上的优化V1.0\nWork # 1xx. C3: Zero-shot Text-to-SQL with ChatGPT笔记 1xx. C3SQL git\n1xx. 也看大模型与数据库查询分析的落地结合：C3 Text2SQL方案及Data-Copilot数据自动化编排机制的实现思想阅读 ***\n早期Work # 1xx. 语义解析 (Text-to-SQL) 技术研究及应用 上篇 1xx. 语义解析 (Text-to-SQL) 技术研究及应用 下篇 其他 # 1xx. LLMs and SQL\n百度千帆-ppt\nQCon-ppt\n"},{"id":22,"href":"/www6vAIGC/docs/RAG/%E6%A1%88%E4%BE%8B/RAGOpenAI/","title":"(原理)RAG OpenAI案例","section":"案例","content":"\nOpenAI RAG 案例[3] # retrieval with consine similarity HyDE retrieval [5] Fine-tune Embeddings Chunk/embedding experiments Reranking [6][8] Classification step Prompt engineering Tool use Query expansion[5] Query Transformations[5] # Query expansion Multi-query retriever HyDE Step back prompting [抽象prompting] Rewrite-Retrieve-Read Query Construction [4] # Examples Data source References Text-to-metadata-filter Vectorstores Docs Text-to-SQL SQL DB Docs, blog, blog Text-to-metadata-filter [7] A self-querying retriever is one that, as the name suggests, has the ability to query itself. Specifically, given any natural language query, the retriever uses a query-constructing LLM chain to write a structured query and then applies that structured query to its underlying VectorStore. This allows the retriever to not only use the user-input query for semantic similarity comparison with the contents of stored documents but to also extract filters from the user query on the metadata of stored documents and to execute those filters.\nAdvanced RAG # 架构 [1] # 离线 index 在线 查询 参考 # Deconstructing RAG ***\nxxx\nApplying OpenAI\u0026rsquo;s RAG Strategies ***\nQuery Construction ***\nQuery Transformations\nSay Goodbye to Irrelevant Search Results: Cohere Rerank Is Here Rerank Cohere Reranker\nself_query\nRAG Fusion Forget RAG, the Future is RAG-Fusion\n"},{"id":23,"href":"/www6vAIGC/docs/FineTuning/PEFT/FineTuning/","title":"(原理)PEFT +","section":"PEFT *","content":"\nPEFT原理 # (原理)PEFT\n"},{"id":24,"href":"/www6vAIGC/docs/Agent/Communication/MCP/","title":"(原理|实战)MCP +","section":"Communication *","content":"\nMCP # (原理|实战)MCP\n"},{"id":25,"href":"/www6vAIGC/docs/Prompt-Engineering/PromptEngineering/","title":"(原理)Prompt Engineering","section":"Prompt Engineering","content":"\nBasic Prompting [2] # Zero-Shot Prompting [3] # Few-Shot Prompting [3] # CoT [2] # Chain-of-Thought Prompting(CoT) [3] # Few-shot CoT Zero-shot COT\n\u0026ldquo;Let\u0026rsquo;s think step by step\u0026rdquo; Self-Consistency(CoT-SC) [3] # The idea is to sample multiple, diverse reasoning paths through few-shot CoT, and use the generations to select the most consistent answer.\nTree of Thoughts (ToT) # CoT vs. CoT-SC vs. ToT [3] # Tips and Extensions [2] # Self-Ask\nAutomatic Prompt Design [2] # Automatic Chain-of-Thought (Auto-CoT) [3] Six strategies for getting better results[1] # Write clear instructions # 清晰的指令\nProvide reference text # Split complex tasks into simpler subtasks # 复杂任务简单化\rGive the model time to \u0026ldquo;think\u0026rdquo; # 给模型时间去思考\nUse external tools # 使用外部工具\nTest changes systematically # 优点vs 缺点 # 优点 # 简单 容易上手\n缺点 # 上限有限 模型适配 prompt要适配每个模型 参考 # Prompt engineering openai Prompt Engineering paper Prompt Engineering Guide guide Prompt-Engineering-Guide *** git 1xx. 【社区第十三讲】 老刘说NLP线上交流 *** 很全\n1xx. [论文阅读] Prompt Engineering综述\n1xx. The Prompt Landscape langchain\n1xx. CometLLM - suite of LLMOps tools - track and visualize LLM prompts and chains\n1xx. 大模型 PUA 指南：来自 Google Meta Microsoft 等大厂\n1xx. NLP（十三）：Prompt Engineering 面面观\n1xx. prompt-engineering git\n1xx. Chain-of-Thought Prompting 简读 1xx. ChatGPT应用端的Prompt解析：从概念、基本构成、常见任务、构造策略到开源工具与数据集 1xx. AutoPrompt Repo git\n案例 # 运维大模型探索之 Text2PromQL 问答机器人 架构图， 最后两个重点总结 未 "},{"id":26,"href":"/www6vAIGC/docs/Agent/Overview/Agent/","title":"(原理)Agent 架构 +","section":"Overview","content":"\nAgent 架构 # (原理)Agent 架构 "},{"id":27,"href":"/www6vAIGC/docs/Langchain/Langchain/","title":"Langchain","section":"Langchain","content":"\nModules # main modules # Model I/O # Language models [10] LLM Chat Model Embedding Prompts Prompt Template Few-shot example Example Selectors [类比选择] 关键字 相似度 长度 Output parsers function call[2] Retrieval # Document Loaders Text Splitters Retrievers[10] VectorStores index Agent # Plan-and-execute agents Additional modules # Chains # 2大类 Chain interface[Legacy] LangChain Expression Language (LCEL) LCEL is a declarative way to compose chains. Foundational LLM Sequential- SequentialChain Router Transformation Memory [10] # 帮语言模型补充上下文 ConversationBufferMemory ConversationBufferWindowMemory 窗口 ConversationSummaryMemory VectorStoreRetrieverMemory Function Call # from langchain.chains.openai_functions.base import ( create_openai_fn_chain, create_structured_output_chain,[2] ) from langchain.chains.openai_functions.citation_fuzzy_match import ( create_citation_fuzzy_match_chain, ) from langchain.chains.openai_functions.extraction import ( create_extraction_chain, create_extraction_chain_pydantic, ) from langchain.chains.openai_functions.qa_with_structure import ( create_qa_with_sources_chain, create_qa_with_structure_chain, ) from langchain.chains.openai_functions.tagging import ( create_tagging_chain, create_tagging_chain_pydantic, ) 应用[4] # Question \u0026amp; Answering Using Documents As Context[3] Extraction[Kor] Evaluation Querying Tabular Data[sqlite] Code Understanding Interacting with APIs Chatbots Chains [1] [8][9] # chain = load_summarize_chain(llm, chain_type=\u0026#34;stuff\u0026#34;, verbose=True) chain = load_summarize_chain(llm, chain_type=\u0026#34;map_reduce\u0026#34;, verbose=True) chain = load_summarize_chain(llm, chain_type=\u0026#34;refine\u0026#34;, verbose=True) chain = load_qa_chain(llm, chain_type=\u0026#34;map_rerank\u0026#34;, verbose=True, return_intermediate_steps=True) 链类型 整合方法 优缺点 stuff 将所有内容放入一个提示中，输入LLM 简单、廉价、效果好/ 对输入文本有一定token限制 Map_reduce 每个问题和文本块单独给语言模型，并将答案汇总生成最终结果 输入任意数量文本，且并行处理/ 速度慢，费token Refine 迭代处理多个文本，基于前一个文档答案构建下一个答案 用于组合信息，依次构建答案/ 速度慢，费token Map_rerank 每个文档单独调用LLM,并要求返回一个得分，然后选择最高的得分 需要告诉模型评分的规则/ 费token Templates[7] # 参考 # https://github.com/gkamradt/langchain-tutorials\nfunctioncall\nqaOnDoc\nLangChain Cookbook Part 2: Use Cases 10.公开课\nhttps://github.com/kyrolabs/awesome-langchain\nhttps://github.com/Crossme0809/langchain-tutorials\nTemplates *** docs templates webui\n吴恩达短课_LangChain\n精华笔记：吴恩达 x LangChain 《使用LangChain构建与数据对话的聊天机器人》（下）\n一文入门最热的LLM应用开发框架LangChain 未\n大模型LangChain框架基础与使用示例 未\n"},{"id":28,"href":"/www6vAIGC/docs/Context-Engineering/context-engineering/","title":"(Manus)context engineering","section":"Context Engineering","content":" 总结[1] # 参考 # Manus 内部的 Context 工程经验（精校、高亮要点） Manus 创始人手把手拆解：如何系统性打造 AI Agent 的上下文工程？\nContext Engineering for AI Agents: Lessons from Building Manus\n"},{"id":29,"href":"/www6vAIGC/docs/RAG/Overview/RAG/","title":"(综述)RAG +","section":"Overview","content":"\nRAG综述 # (综述)RAG\n"},{"id":30,"href":"/www6vAIGC/docs/Application/gpt/","title":"GPT-工具和应用","section":"Application","content":"\nPlatform # 国外 Poe *** 国内 实战云 gpt3.5 gpt4 ChatGPT使用指南！ *** 灵犀百通 gpt3.5 ChatGpt PLUS 文心一言 Tools \u0026amp; Mix # GPT学习宝典\n聚合 GPT 工具箱 教程 学习资料 极客时间 AIGC 知识库 ***\n聚合 AI工具大全 AI主流工具精选 AI经典项目 AI导航站 应用与变现案例 AI 工具箱 ***\nChatGPT Tutorial 101\n应用 # 思维导图 # albus\n视频 # BibiGPT Youtube tools\n英语 # callannie\n客户端 # ChatGPT 客户端 windows， mac Chrome plugin # WebChatGPT[instatlled]\nAIPRM for ChatGPT[instatlled]\nChatGPT Sidebar 要注册账号, 需要api token\nChatHub [instatlled] chatgpt + new bing ChatHub OpenAI Translator openai-translator 要注册账号, 需要api token\n创业 # GPT-3 Demo 聊天机器人 代码辅助 写作应用 游戏 "},{"id":31,"href":"/www6vAIGC/docs/Prompt-Engineering/PromptingClaude/","title":"(实践)Prompting Claude *","section":"Prompt Engineering","content":" Beginner[1] # Prompt generator [10] # Prompt generator\n提示生成器\nBe clear and direct # Be clear and direct\n清晰直接\nGive Claude a role (system prompts) *** # Give Claude a role (system prompts)\n给 Claude 一个角色（系统提示）\nexample 您是一家世界500强科技公司的总法律顾问。我们正在考虑将这份软件许可协议用于我们的核心数据基础设施： {{CONTRACT}} 分析其潜在风险，重点关注赔偿、责任和知识产权所有权。请给出您的专业意见。\nIntermediate[1] # Use XML tags *** # Use XML tags\n使用 XML 标签\nexample 你是AcmeCorp的财务分析师。为我们的投资者生成Q2财务报告。\nAcmeCorp是一家B2B SaaS公司。我们的投资者重视透明度和可行的见解。\n使用这些数据生成报告：{{SPREADSHEET_DATA}}\n包括以下部分：收入增长、利润率、现金流。 突出优势和需要改进的领域。 使用简洁专业的语气。遵循这个结构： \u0026lt;formatting_example\u0026gt;{{Q1_REPORT}}\u0026lt;/formatting_example\u0026gt;\nLet Claude think (chain of thought) *** # Let Claude think (chain of thought)\n让 Claude 思考（思维链）\nexample 你是一名财务顾问。一位客户想投资10,000美元。他们可以在两个选项中选择：A）一支历史年回报率为12%但波动的股票，或 B）一支保证年回报率6%的债券。客户需要在5年内用这笔钱作为房子的首付。你推荐哪个选项？【请逐步思考。】\nUse examples (multishot) *** # Use examples (multishot)\n使用示例（多样本）\nexample 我们的客服团队被非结构化反馈淹没了。你的任务是为我们的产品和工程团队分析反馈并对问题进行分类。使用这些类别：UI/UX、性能、功能请求、集成、定价和其他。同时评估情感（积极/中性/消极）和优先级（高/中/低）。这里有一个示例：\n输入：新仪表板一团糟！加载需要很长时间，而且我找不到导出按钮。请尽快修复这个问题！ 类别：UI/UX、性能 情感：消极 优先级：高 现在，分析这个反馈：{{FEEDBACK}}\nPrefill Claude’s response # Prefill Claude’s response\n预填充 Claude 的响应\nexample 示例 1：控制输出格式并跳过前言 # Advanced[1] # Chain complex prompts *** # Chain complex prompts\n链接复杂提示\n如何链式提示 # 识别子任务：将任务分解为不同的、连续的步骤。 使用XML构建清晰的交接：使用XML标签在提示之间传递输出。 设定单一任务目标：每个子任务应该有一个明确的单一目标。 迭代：根据Claude的表现改进子任务。 example 事例：分析法律合同\nLong context tips # Long context tips\n长上下文提示\nexample annual_report_2023.pdf {{ANNUAL_REPORT}} competitor_analysis_q2.xlsx {{COMPETITOR_ANALYSIS}} 分析年度报告和竞争对手分析。识别战略优势并推荐第三季度重点关注领域。\n参考 # Anthropic提示工程指南：Prompt Engineering Overview https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview\nhttps://docs.anthropic.com/zh-CN/docs/build-with-claude/prompt-engineering/overview\nAnthropic交互式提示工程教程：Prompt Engineering Interactive Tutorial\nhttps://github.com/anthropics/prompt-eng-interactive-tutorial\n​\tAnthropic\u0026rsquo;s Prompt Engineering Interactive Tutorial\n​\tPrompt Engineering Interactive Tutorial\nhttps://blog.zhexuan.org/archives/Anthropic-Prompt.html prompt-generator # 自动生成首版提示词模板 ​ https://console.anthropic.com/dashboard\n"},{"id":32,"href":"/www6vAIGC/docs/%E5%85%B6%E4%BB%96/self-work/","title":"自己的工作","section":"其他","content":" SFT # SFT（3次） # + (原理\u0026amp;实战) LORA 1次 qwen2.5-7b Unsloth 1次 llama2 deepspeed 1次bloom ‣ xxx\nllama CPT+SFT\nAgent SFT（2次） *** # AgentTuning *** SFT Data # ‣ xxx 模型部署 # vLLM 部署 Qwen lmdeploy-推理部署 书生大模型 "},{"id":33,"href":"/www6vAIGC/docs/Deep-Research/%E5%AE%9E%E7%8E%B0/DeepResearchJina/","title":"(原理|实现){Jina}Deep Research","section":"实现","content":"\nDeep Research(Jina) # (原理|实现)Deep Research(Jina)\n"},{"id":34,"href":"/www6vAIGC/docs/Agent/Platform/DifySandbox/","title":"(实现)Dify sandbox *","section":"Platform *","content":" Security Model # Security Architecture Overview # Syscall Filtering with Seccomp # Python Seccomp Implementation\n实现 # python.go\ntype PythonRunner struct { runner.TempDirRunner } //go:embed prescript.py var sandbox_fs []byte func (p *PythonRunner) Run( code string, timeout time.Duration, stdin []byte, preload string, options *types.RunnerOptions, ) (chan []byte, chan []byte, chan bool, error) { configuration := static.GetDifySandboxGlobalConfigurations() // initialize the environment untrusted_code_path, key, err := p.InitializeEnvironment(code, preload, options) if err != nil { return nil, nil, nil, err } // capture the output output_handler := runner.NewOutputCaptureRunner() output_handler.SetTimeout(timeout) output_handler.SetAfterExitHook(func() { // remove untrusted code os.Remove(untrusted_code_path) }) // create a new process ### 执行python代码的进程 cmd := exec.Command( configuration.PythonPath, untrusted_code_path, LIB_PATH, key, ) cmd.Env = []string{} cmd.Dir = LIB_PATH if configuration.Proxy.Socks5 != \u0026#34;\u0026#34; { cmd.Env = append(cmd.Env, fmt.Sprintf(\u0026#34;HTTPS_PROXY=%s\u0026#34;, configuration.Proxy.Socks5)) cmd.Env = append(cmd.Env, fmt.Sprintf(\u0026#34;HTTP_PROXY=%s\u0026#34;, configuration.Proxy.Socks5)) } else if configuration.Proxy.Https != \u0026#34;\u0026#34; || configuration.Proxy.Http != \u0026#34;\u0026#34; { if configuration.Proxy.Https != \u0026#34;\u0026#34; { cmd.Env = append(cmd.Env, fmt.Sprintf(\u0026#34;HTTPS_PROXY=%s\u0026#34;, configuration.Proxy.Https)) } if configuration.Proxy.Http != \u0026#34;\u0026#34; { cmd.Env = append(cmd.Env, fmt.Sprintf(\u0026#34;HTTP_PROXY=%s\u0026#34;, configuration.Proxy.Http)) } } if len(configuration.AllowedSyscalls) \u0026gt; 0 { cmd.Env = append(cmd.Env, fmt.Sprintf(\u0026#34;ALLOWED_SYSCALLS=%s\u0026#34;, strings.Trim(strings.Join(strings.Fields(fmt.Sprint(configuration.AllowedSyscalls)), \u0026#34;,\u0026#34;), \u0026#34;[]\u0026#34;), ), ) } err = output_handler.CaptureOutput(cmd) if err != nil { return nil, nil, nil, err } return output_handler.GetStdout(), output_handler.GetStderr(), output_handler.GetDone(), nil } func (p *PythonRunner) InitializeEnvironment(code string, preload string, options *types.RunnerOptions) (string, string, error) { if !checkLibAvaliable() { // ensure environment is reversed releaseLibBinary(false) } // create a tmp dir and copy the python script temp_code_name := strings.ReplaceAll(uuid.New().String(), \u0026#34;-\u0026#34;, \u0026#34;_\u0026#34;) temp_code_name = strings.ReplaceAll(temp_code_name, \u0026#34;/\u0026#34;, \u0026#34;.\u0026#34;) /// 把prescript.py中的placeholder都替换掉 script := strings.Replace( string(sandbox_fs), \u0026#34;{{uid}}\u0026#34;, strconv.Itoa(static.SANDBOX_USER_UID), 1, ) script = strings.Replace( script, \u0026#34;{{gid}}\u0026#34;, strconv.Itoa(static.SANDBOX_GROUP_ID), 1, ) if options.EnableNetwork { script = strings.Replace( script, \u0026#34;{{enable_network}}\u0026#34;, \u0026#34;1\u0026#34;, 1, ) } else { script = strings.Replace( script, \u0026#34;{{enable_network}}\u0026#34;, \u0026#34;0\u0026#34;, 1, ) } script = strings.Replace( script, \u0026#34;{{preload}}\u0026#34;, fmt.Sprintf(\u0026#34;%s\\\\n\u0026#34;, preload), 1, ) // generate a random 512 bit key key_len := 64 key := make([]byte, key_len) _, err := rand.Read(key) if err != nil { return \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, err } /// 代码加密 // encrypt the code encrypted_code := make([]byte, len(code)) for i := 0; i \u0026lt; len(code); i++ { encrypted_code[i] = code[i] ^ key[i%key_len] } /// 代码做base64 // encode code using base64 code = base64.StdEncoding.EncodeToString(encrypted_code) // encode key using base64 encoded_key := base64.StdEncoding.EncodeToString(key) code = strings.Replace( script, \u0026#34;{{code}}\u0026#34;, code, 1, ) untrusted_code_path := fmt.Sprintf(\u0026#34;%s/tmp/%s.py\u0026#34;, LIB_PATH, temp_code_name) err = os.MkdirAll(path.Dir(untrusted_code_path), 0755) if err != nil { return \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, err } err = os.WriteFile(untrusted_code_path, []byte(code), 0755) if err != nil { return \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, err } return untrusted_code_path, encoded_key, nil } prescript.py\nimport ctypes import os import sys import traceback # setup sys.excepthook def excepthook(type, value, tb): sys.stderr.write(\u0026#34;\u0026#34;.join(traceback.format_exception(type, value, tb))) sys.stderr.flush() sys.exit(-1) sys.excepthook = excepthook lib = ctypes.CDLL(\u0026#34;./python.so\u0026#34;) lib.DifySeccomp.argtypes = [ctypes.c_uint32, ctypes.c_uint32, ctypes.c_bool] lib.DifySeccomp.restype = None # get running path running_path = sys.argv[1] if not running_path: exit(-1) # get decrypt key key = sys.argv[2] if not key: exit(-1) from base64 import b64decode key = b64decode(key) os.chdir(running_path) {{preload}} lib.DifySeccomp({{uid}}, {{gid}}, {{enable_network}}) code = b64decode(\u0026#34;{{code}}\u0026#34;) def decrypt(code, key): key_len = len(key) code_len = len(code) code = bytearray(code) for i in range(code_len): code[i] = code[i] ^ key[i % key_len] return bytes(code) code = decrypt(code, key) exec(code) "},{"id":35,"href":"/www6vAIGC/docs/FineTuning/Data/Data-Quality/Instruction-Diversity/DataSelfQA/","title":"(原理|实战)Self-QA *","section":"Instruction Diversity","content":"\nSelf-QA[10] # 论文 # SELF-QA: Unsupervised Knowledge Guided Language Model Alignment\n思想 # 知识引导的指令生成Knowledge-Guided Instruction Generation\n指令生成阶段 # 采用语言模型本身来根据无监督的文本生成指令。这种方法使生成的指令具有领域针对性，并与所提供的无监督文本的内容相关。 非结构化的知识，如网页和书籍数据，直接使用。 结构化数据，如表格和知识图谱，在被利用之前需要转换为非结构化文本数据。如通过使用模板填充槽或将每个数据条目与相应的属性名称连接起来来实现。 指令答案生成阶段 # 将生成的指令问题让大模型进行预测，生成答案 Self-QA 实战[11] # SYSTEM_PROMPT = \u0026#34;\u0026#34;\u0026#34; 你是一个能根据提供的文本内容生成QA对的机器人。以下是你的任务要求： 1. 生成尽可能多的QA对。 2. 每个QA对包含一个问题和一个简洁的答案。 3. 答案必须用简体中文。 4. 生成的QA对不能重复。 5. 使用json格式将QA对包裹起来，问题用\u0026#34;question\u0026#34;表示，答案用\u0026#34;answer\u0026#34;表示。 示例格式： [ { \u0026#34;question\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;answer\u0026#34;: \u0026#34;...\u0026#34; }, { \u0026#34;question\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;answer\u0026#34;: \u0026#34;...\u0026#34; } ] 以下是给定的文本内容： \u0026#34;\u0026#34;\u0026#34; 参考 # Self-QA # 10.《第二章 大模型训练与微调研发背后的数据艺术》 LLM大语言模型算法特训 那位科技 ***\nSELF-INSTRUCT， Baize， Evol-instruct， Self-QA， Ultra-chat\nSelf-QA：生成自然语言处理训练数据的实用方法 1xx. 项目实训2024.04.12日志：Self-QA生成问答对\nSELF-QA：无监督知识引导语言模型对齐\nSELF-QA：无监督的知识引导语言模型对齐论文精读\n"},{"id":36,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/framework/RAGchatchat/","title":"(框架)RAG Langchain-Chatchat","section":"framework","content":"\nLangchain-Chatchat 架构 # 组件 本地知识库 Embedding 模型 向量数据库 Prompt Template Langchain-Chatchat # 部署 windows 10 [5] 部署本地， 没显存，卡 Linux [2] 部署 32C125G ，没显存， 推理很慢 Docker 参考 # Langchain-Chatchat master Langchain 与 ChatGLM 等语言模型的本地知识库问答\nLangchain-Chatchat v0.2.4\nlangchain-ChatGLM gitee\nColab for Langchain-Chatchat linux 可以部署 v0.2.6\nlangChain-ChatGLM 尝试，踩坑记录\nLangchain-Chatchat + 阿里通义千问Qwen 保姆级教程 | 次世代知识管理解决方案 Langchain-Chatchat + 通义千问\nwin10 安装 Langchain-Chatchat 避坑指南（2023年9月18日v0.2.4版本，包含全部下载内容！）\n"},{"id":37,"href":"/www6vAIGC/docs/RAG/phase/phaseRAGPostRetrieval/RAGFusion/","title":"(原理|实战)RAG Fusion","section":"(Phase)post-retrieval","content":"\nRAG-Fusion多查询结果融合策略 # 将多个召回查询的结果进行合并[3]\n其思想在于通过生成多个用户查询和重新排序结果来解决RAG固有的约束；利用倒数排序融合（RRF）和自定义向量评分加权，生成全面准确的结果。[2]\n代码 # RAG Fusion git\n参考 # Forget RAG, the Future is RAG-Fusion 失效 使用RAG-Fusion和RRF让RAG在意图搜索方面更进一步\n再谈大模型RAG问答中的三个现实问题：兼看RAG-Fusion多query融合策略、回答引文生成策略及相关数据集概述 二、基于大模型生成能力自动生成引文\n一文详看Langchain框架中的RAG多阶段优化策略：从问题转换到查询路由再到生成优化 *** 原理paper，代码示例\nMulti Query多查询策略， Decomposition问题， [RAG-Fusion]， Step Back， HyDE混合\nrag-from-scratch Repo git\n"},{"id":38,"href":"/www6vAIGC/docs/RAG/phase/phaseRAGPreRetrieval/RAGRouting/","title":"(原理|实战)Query Routing","section":"(Phase)pre-retrival","content":"\n类型[1] # LLM Routers LLM Completion Routers LLM Function Calling Routers Semantic Routers [2] Zero Shot Classification Routers Language Classification Routers Logical and Semantic routing[3] # Logical routing # code from typing import Literal from langchain_core.prompts import ChatPromptTemplate from langchain_core.pydantic_v1 import BaseModel, Field from langchain_openai import ChatOpenAI # Data model class RouteQuery(BaseModel): \u0026#34;\u0026#34;\u0026#34;Route a user query to the most relevant datasource.\u0026#34;\u0026#34;\u0026#34; datasource: Literal[\u0026#34;python_docs\u0026#34;, \u0026#34;js_docs\u0026#34;, \u0026#34;golang_docs\u0026#34;] = Field( ..., description=\u0026#34;Given a user question choose which datasource would be most relevant for answering their question\u0026#34;, ) # LLM with function call llm = ChatOpenAI(model=\u0026#34;gpt-3.5-turbo-0125\u0026#34;, temperature=0) structured_llm = llm.with_structured_output(RouteQuery) # Prompt system = \u0026#34;\u0026#34;\u0026#34;You are an expert at routing a user question to the appropriate data source. Based on the programming language the question is referring to, route it to the relevant data source.\u0026#34;\u0026#34;\u0026#34; prompt = ChatPromptTemplate.from_messages( [ (\u0026#34;system\u0026#34;, system), (\u0026#34;human\u0026#34;, \u0026#34;{question}\u0026#34;), ] ) # Define router router = prompt | structured_llm def choose_route(result): if \u0026#34;python_docs\u0026#34; in result.datasource.lower(): ### Logic here return \u0026#34;chain for python_docs\u0026#34; elif \u0026#34;js_docs\u0026#34; in result.datasource.lower(): ### Logic here return \u0026#34;chain for js_docs\u0026#34; else: ### Logic here return \u0026#34;golang_docs\u0026#34; from langchain_core.runnables import RunnableLambda full_chain = router | RunnableLambda(choose_route) full_chain.invoke({\u0026#34;question\u0026#34;: question}) Semantic routing # code from langchain.utils.math import cosine_similarity from langchain_core.output_parsers import StrOutputParser from langchain_core.prompts import PromptTemplate from langchain_core.runnables import RunnableLambda, RunnablePassthrough from langchain_openai import ChatOpenAI, OpenAIEmbeddings # Two prompts physics_template = \u0026#34;\u0026#34;\u0026#34;You are a very smart physics professor. \\ You are great at answering questions about physics in a concise and easy to understand manner. \\ When you don\u0026#39;t know the answer to a question you admit that you don\u0026#39;t know. Here is a question: {query}\u0026#34;\u0026#34;\u0026#34; math_template = \u0026#34;\u0026#34;\u0026#34;You are a very good mathematician. You are great at answering math questions. \\ You are so good because you are able to break down hard problems into their component parts, \\ answer the component parts, and then put them together to answer the broader question. Here is a question: {query}\u0026#34;\u0026#34;\u0026#34; # Embed prompts embeddings = OpenAIEmbeddings() prompt_templates = [physics_template, math_template] prompt_embeddings = embeddings.embed_documents(prompt_templates) # Route question to prompt def prompt_router(input): # Embed question query_embedding = embeddings.embed_query(input[\u0026#34;query\u0026#34;]) # Compute similarity similarity = cosine_similarity([query_embedding], prompt_embeddings)[0] most_similar = prompt_templates[similarity.argmax()] # Chosen prompt print(\u0026#34;Using MATH\u0026#34; if most_similar == math_template else \u0026#34;Using PHYSICS\u0026#34;) return PromptTemplate.from_template(most_similar) chain = ( {\u0026#34;query\u0026#34;: RunnablePassthrough()} | RunnableLambda(prompt_router) | ChatOpenAI() | StrOutputParser() ) print(chain.invoke(\u0026#34;What\u0026#39;s a black hole\u0026#34;)) 【基于embedding的相似度匹配】\n参考 # Routing in RAG-Driven Applications\nSematic router 让LLM更加快速做出决策 V\nsemantic-router Repo git\nsemantic-router doc\n一文详看Langchain框架中的RAG多阶段优化策略：从问题转换到查询路由再到生成优化\nrag-from-scratch Repo git\nRAG(检索增强） 从入门到精通 路由（routing) V\n"},{"id":39,"href":"/www6vAIGC/docs/Agent/Multi-agent/MultiAgentsPractice/","title":"(实战)LangGraph","section":"Multi-agent *","content":"\nLangGraph [1] # Agent Supervisor # Agent Supervisor Repo git\nMulti Agent Collaboration # Basic Multi-agent Collaboration git\nHierarchical Agent Teams # Hierarchical Agent Teams git\n参考 # LangGraph # LangGraph: Multi-Agent Workflows LangGraph：Multi-Agent 实战 V "},{"id":40,"href":"/www6vAIGC/docs/Agent/Multi-agent/MultiAgentsFail/","title":"Multi-Agent  Fail +","section":"Multi-agent *","content":" Multi-Agent Fail # Multi-Agent Fail\n"},{"id":41,"href":"/www6vAIGC/docs/RAG/Overview/RAGModularRAG/","title":"(原理)Modular RAG +","section":"Overview","content":"\nModular RAG # (原理)Modular RAG\n"},{"id":42,"href":"/www6vAIGC/docs/DocumentAI/MinerU/","title":"MinerU","section":"文档智能","content":" 论文 # 论文地址\nMinerU: An Open-Source Solution for Precise Document Content Extraction\n开源地址\nhttps://github.com/opendatalab/MinerU git\nonline demo\nhttps://www.modelscope.cn/studios/OpenDataLab/MinerU\nOverview # 复杂文档解析 [10] # 【everything2Markdown】\n【边界的地方错的多 】\n【去噪 - 页眉 页脚】\n参考 # 深入拆解 MinerU 解析处理流程\n蚂蚁数科AI Agent 知识工程实践 其他 # 关于目前文档转换的一些误区认识，讨论见社区。 目前说的mineru，ocr用的paddlepaddle，table用的rapd-table，版式分析用的doclayout，公式用的unimernet，阅读顺序用的xycut/ layoutreader，公式检测用的yolo，然后串起来，写了很多postprocess，这就是miner-u，纯开源集成；\n而不是里面说的什么多模态，多模态解析能力，支持多种格式的转换及高精度 OCR，不要信，其难的的是后处理的逻辑。\nocr用来总去，用的还是PaddleOCR。olmOCR，vary，gotOCR2.0这些，都是基于多模态模型微调的方案，没有本质区别。\n"},{"id":43,"href":"/www6vAIGC/docs/RAG/%E6%A1%88%E4%BE%8B/RAGBaichuan/","title":"(原理)RAG Baichuan案例","section":"案例","content":"\nBaichuan RAG[1] # 借鉴了Meta的CoVe技术 自研的TSF（Think-Step Further)技术 猜测其本质应该是对Step-back prompting方法的改良 自研了Baichuan-Text-Embedding向量模型 混合检索 向量检索与稀疏检索并行的 self-Critique 总结[2] # **多轮问答等场景的召回和传统搜索引擎的召回分布还不太一样。**百川借助子问题检索效果更高的特点，对原始复杂问题进行拆解、拓展来解决复杂问题检索质量偏差的问题。 **对于没见过的语料直接用向量检索的结果可能不太理想。**百川在大量语料上利用无监督方法训练embedding模型来优化效果。而行业大模型更倾向于私有的数据，要提升私有数据的训练效果还得继续在私有化数据上训练效果会更佳。 **Query拓展 + 多路召回 + Rerank + self-Critique可能是现阶段比较好的一种RAG方式，但是其也会带来更多成本。**总体思路有点像ReAct[3]系列的进阶版本，其在搜索侧和答案修正侧都做了更多的一些工作来优化实际效果。其缺点是需要多次调用大模型，会带来额外的成本，真实线上是否采用这种策略还有待验证。 参考 # 大模型RAG问答行业最佳案例及微调、推理双阶段实现模式：基于模块化(Modular)RAG自定义RAG Flow\n百川智能RAG方案总结：搜索出生的百川智能大模型RAG爬坑之路\n1xx. LLM/百川Baichuan2-53B搜索增强-开放API\n1xx. 大模型+搜索构建完整技术栈，百川智能用搜索增强给企业定制化下了一剂「猛药」\n1xx. 百川智能RAG方案总结：搜索出生的百川智能大模型RAG爬坑之路\n"},{"id":44,"href":"/www6vAIGC/docs/FineTuning/PEFT/Soft-Prompt/PEFTPtuning/","title":"P-Tuning","section":"Soft Prompt","content":"\nP-Tuning[2] # P-Tuning 的创新之处在于将提示（Prompt）转化为可学习的嵌入层（Embedding Layer） 架构 # 一个关于“The capital of Britain is [MASK]” 示例：\n蓝色是上下文 “Britain” 红色是目标单词 “[MASK]”， 橙色区域是提示词。 传统方式 与 P-Tuning 对比：\n在（a）中，提示生成器只接收离散奖励； 在（b）中，连续的提示嵌入（Prompt Embedding） 和**提示编码器（Prompt Encoder）**以可微的方式进行 优化。 P-Tuning v2[2] # 背景 # 之前的方法在以下两方面有所限制： • 模型规模差异：在大型预训练模型中，Prompt Tuning 和 P-Tuning 能取得与全面微调相似的效果，但在参数较少 的模型上则表现不佳。 • 任务类型差异：无论是 Prompt Tuning 还是 P-Tuning， 在序列标注任务上的表现都较差。\n目的 # P-Tuning v2 旨在使提示调整（Prompt Tuning）在不同规模的预训练模型上，针对各种下游任务都能达到类似全面微调（Fine-tuning）的效果。\n架构 [1] # 在每一层都加入了Prompts tokens 作为输入, 而不是仅仅加在输入层\n总结 # P-tuning 和 Prompt Tuning 仅仅更新第一个Transformer层 Prefix tuning 和 P-Tuning v2 针对每一个Transformer 层进行更新 Prefix tuning 和 P-Tuning 需要重新参数化(PromptEncoder), 而Prompt Tuning 和 P-Tuning v2则不需要 简单将P-Tuning认为是针对 Prompt Tuning的改进, P-Tuning v2 认为是针对 Prefix tuning 的改进. 参考 # 大模型参数高效微调技术原理及实践 pdf 如何高效微调大模型？技术原理与最佳实践揭秘！ V ***\n《3-大模型微调技术揭秘-PEFT》 Ai大模型微调\n"},{"id":45,"href":"/www6vAIGC/docs/RAG/Pattern/Multimodal-RAG/RAGMultimodalPractice/","title":"(实战)多模态 RAG","section":"Multimodal RAG","content":"\n多模态RAG-多向量检索器 [10][11] # semi-structured (tables + text) RAG [20] # 分析pdf中表格\nmulti-modal (text + tables + images) RAG [13] # 分析PDF中图片\nOption 1 [基于CLIP] [23] [30][32][33]\nUse multimodal embeddings (such as CLIP) to embed images and text Retrieve both using similarity search Pass raw images and text chunks to a multimodal LLM for answer synthesis\n{选项1：对文本和表格生成summary，然后应用多模态embedding模型把文本/表格summary、原始图片转化成embedding存入多向量检索器。对话时，根据query召回原始文本/表格/图像。然后将其喂给多模态LLM生成应答结果。}[10] Option 2 [21]\nUse a multimodal LLM (such as GPT4-V, LLaVA, or FUYU-8b) to produce text summaries from images Embed and retrieve text Pass text chunks to an LLM for answer synthesis\n【将图片转成摘要，和其他文本信息整合在文本粒度进行检索】[12]\n{选项2：首先应用多模态大模型（GPT4-V、LLaVA、FUYU-8b）生成图片summary。然后对文本/表格/图片summary进行向量化存入多向量检索器中。当生成应答的多模态大模型不具备时，可根据query召回原始文本/表格+图片summary。}[10] Option 3 [24] [31][34]\nUse a multimodal LLM (such as GPT4-V, LLaVA, or FUYU-8b) to produce text summaries from images Embed and retrieve image summaries with a reference to the raw image Pass raw images and text chunks to a multimodal LLM for answer synthesis 【实际模型输入使用的是图片】\n【图片概要依然是用于检索（GPT-4V，LLaVA，FUYU-8b）】[12]\n{选项3：前置阶段同选项2相同。对话时，根据query召回原始文本/表格/图片。构造完整Prompt，访问多模态大模型生成应答结果。}[10] private multi-modal (text + tables + images) RAG [22] # 组件 # pdf解析\nunstructured store\nMultiVectorRetriever - 元数据+数据 参考 # 实战 # 检索增强生成（RAG）有什么好的优化方案？\nMulti-Vector Retriever for RAG on tables, text, and images ***\n基于多向量检索器的多模态RAG实现：用于表格、文本和图像\nlangchain的multi model RAG-以多模态pdf文件为例子\nMulti-modal RAG on slide decks\n1xx. Using Multi-Modal LLMs page21\nnotebook # Semi_Structured_RAG notebook\nAdvanced-RAG semi_structured_data notebook {半结构化-解析pdf中的表格， 运行没问题，能问表格中的数据}\nSemi_structured_and_multi_modal_RAG notebook\nPrivate Semi-structured and Multi-modal RAG w/ LLaMA2 and LLaVA notebook {多模态- 解析pdf中的图片 运行有问题}\nPrivate Semi-structured and Multi-modal RAG w/ LLaMA2 and LLaVA notebook\nChroma multi-modal RAG notebook\nMulti-modal RAG notebook\ntemplate (失效了) # rag-multi-modal-local\nOpenCLIP(image embedding) + bakllava(answer synthesis) rag-multi-modal-mv-local\nbakllava(image summaries embedding) + bakllava (answer synthesis) rag-chroma-multi-modal\nOpenCLIP(image embedding) + GPT-4V (answer synthesis) rag-gemini-multi-modal\nOpenCLIP(image embedding) + Gemini(answer synthesis) rag-chroma-multi-modal-multi-vector\nGPT-4V(image summaries embedding) + GPT-4V (answer synthesis) llamaindex # 1xx. 朴素多模态RAG如何实现？兼看RAG上下文过滤方案FILCO及202402大模型早报 1xx. Advanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\n1xx. Multimodal RAG pipeline with LlamaIndex and Neo4j\n1xx. neo4j_llama_multimodal.ipynb git\n"},{"id":46,"href":"/www6vAIGC/docs/FineTuning/Instruct-Tuning/InstructTuningSurvey/","title":"(Survey)Instruct Tuning","section":"Instruct Tuning","content":"\n参考 # 1xx. 大语言模型指令微调综述 一篇关于LLM指令微调的综述\n1xx. [论文]大语言模型指令调优综述\n1xx. Paper：《Instruction Tuning for Large Language Models: A Survey—大型语言模型的指令调优的综述》翻译与解读\n1xx. Instruction Tuning for Large Language Models: A Survey git\n【前面大部分是Instruct-Tuning， 中间一部分是Multi-modality Instruction Tuning】\n"},{"id":47,"href":"/www6vAIGC/docs/RAG/Pattern/Agentic-RAG/RAGSelfReflective/","title":"(原理|实战)Self-Reflective RAG","section":"Agentic RAG","content":"\nCognitive Architecture [2] # Cognitive architectures for RAG [1] CRAG # 论文 # Corrective Retrieval Augmented Generation Figure 2\n实现[10] # Corrective-RAG (CRAG) is a strategy for RAG that incorporates self-reflection / self-grading on retrieved documents.\nIn the paper here, a few steps are taken:\nIf at least one document exceeds the threshold for relevance, then it proceeds to generation Before generation, it performs knowledge refinement This partitions the document into \u0026ldquo;knowledge strips\u0026rdquo; It grades each strip, and filters our irrelevant ones If all documents fall below the relevance threshold or if the grader is unsure, then the framework seeks an additional datasource It will use web search to supplement retrieval We will implement some of these ideas from scratch using LangGraph:\nLet\u0026rsquo;s skip the knowledge refinement phase as a first pass. This can be added back as a node, if desired. If any documents are irrelevant, let\u0026rsquo;s opt to supplement retrieval with web search. We\u0026rsquo;ll use Tavily Search for web search. Let\u0026rsquo;s use query re-writing to optimize the query for web search. Self-RAG # 论文 # SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION Figure 1\n原理 [20] # Self-RAG 则是更加主动和智能的实现方式，主要步骤概括如下：\n判断是否需要额外检索事实性信息（retrieve on demand），仅当有需要时才召回 平行处理每个片段：生产prompt+一个片段的生成结果 使用反思字段(Reflection tokens)，检查输出是否相关，选择最符合需要的片段； 再重复检索 生成结果会引用相关片段，以及输出结果是否符合该片段，便于查证事实。 实现[21] # Self-RAG is a strategy for RAG that incorporates self-reflection / self-grading on retrieved documents and generations.\nIn the paper, a few decisions are made:\nShould I retrieve from retriever, R - Input: x (question) OR x (question), y (generation) Decides when to retrieve D chunks with R Output: yes, no, continue Are the retrieved passages D relevant to the question x - Input: (x (question), d (chunk)) for d in D d provides useful information to solve x Output: relevant, irrelevant Are the LLM generation from each chunk in D is relevant to the chunk (hallucinations, etc) - Input: x (question), d (chunk), y (generation) for d in D All of the verification-worthy statements in y (generation) are supported by d Output: {fully supported, partially supported, no support The LLM generation from each chunk in D is a useful response to x (question) - Input: x (question), y (generation) for d in D y (generation) is a useful response to x (question). Output: {5, 4, 3, 2, 1} We will implement some of these ideas from scratch using LangGraph.\n参考 # Self-Reflective RAG with LangGraph ***\nOpenAI\u0026rsquo;s Bet on a Cognitive Architecture\n1xx. 写的太通透了！大模型自省式 RAG 与 LangGraph 的实践！\nCRAG # Corrective RAG (CRAG) langgraph git 1xx. 【社区第十三讲】 老刘说NLP线上交流\nSelf-RAG # NLP（廿一）：从 RAG 到 Self-RAG —— LLM 的知识增强 ***\nSelf-RAG langGraph git\n1xx. original implementation of Self-RAG\n"},{"id":48,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Planning/COT/","title":"(原理)COT","section":"Planning","content":"\nCoT[4] # CoT(Chain of Thought)\nCoT-SC(Self Consistency) ToT(Tree of Thoughts) 分为了Thought Decomposition，Thought Generator，State Evaluator，Search algorithms\nGoT(Graph of Thoughts)\nAoT(Algorithm of Thoughts)\n参考 # 2023年能够解决复杂问题的思维链技术：Cot，ToT，GoT，AoT 1xx. CoT-Reasoning-Survey 1xx. 大模型COT思维链推理的几个关键问题：从评测基准、结构变体到增强方案的系统综述 1xx. 大模型思维链推理的综述：进展、前沿和未来\n"},{"id":49,"href":"/www6vAIGC/docs/Application/NL2SQL/survey/","title":"(survey)NL2SQL","section":"NL2SQL","content":" 参考 # Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL *** A Survey on Employing Large Language Models for Text-to-SQL Tasks *** NL2SQL_Handbook NL2SQL（文本到 SQL）技术，https://github.com/HKUSTDial/NL2SQL_Handbook，里面有常用方案。感兴趣的可关注。 *** "},{"id":50,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/RAGPractice/","title":"(实战)RAG","section":"实战 *","content":"\nData processing[17] # 长文本 变成 QA pair\n规则匹配 利用LLM抽取 人工处理 医疗问答RAG[20] # 架构 # chuck # 段落 句子 token\n数据格式 # {\u0026ldquo;id\u0026rdquo;: xxx, \u0026ldquo;病情描述\u0026rdquo;: \u0026ldquo;xxx\u0026rdquo;, \u0026ldquo;治疗方案\u0026rdquo;: \u0026ldquo;xxx\u0026rdquo; }\n改写query # HyDE RAG Fusion -\u0026gt; Generate Similar query 用户的查询不精准，要扩充query, 用大模型改写 召回模型 # bert模型\nsbert 2个bert模型，共享参数，s1,s2向量化后做相似度计算 速度快 相似度 欧式距离 在百万语料上训练 语料格式\n[s1][s2] 0 - 无关 [s1][s2] 1-类似 根据query, 召回id和value整条记录\n排序模型 # bert模型 1个bert模型 速度慢 格式 query[sep]s2 -\u0026gt; 经过softmax，产生2分类，0-1 也要训练 同召回模型训练方式 索引方式 # 树索引 知识图谱的索引 大模型 # 综合归纳的作用 参考 # xxx # \u0026laquo;大模型结合 RAG 构建客服场景自动问答系统\u0026raquo; NVIDIA大模型日系列活动 医疗问答 # 基于百万语料的医疗RAG项目 v "},{"id":51,"href":"/www6vAIGC/docs/Langchain/Retrievers/","title":"Retrievers","section":"Langchain","content":"\nLangchain Retrievers[10] # MultiQueryRetriever # The MultiQueryRetriever automates the process of prompt tuning by using an LLM to generate multiple queries from different perspectives for a given user input query.\nContextual compression # Ensemble Retriever # The EnsembleRetriever takes a list of retrievers as input and ensemble the results of their get_relevant_documents() methods and rerank the results based on the Reciprocal Rank Fusion algorithm. The most common pattern is to combine a sparse retriever (like BM25) with a dense retriever (like embedding similarity), because their strengths are complementary. It is also known as “hybrid search”.\nMultiVector Retriever # The methods to create multiple vectors per document include: - Smaller chunks: split a document into smaller chunks, and embed those (this is ParentDocumentRetriever). - Summary: create a summary for each document, embed that along with (or instead of) the document. - Hypothetical questions: create hypothetical questions that each document would be appropriate to answer, embed those along with (or instead of) the document.\nParent Document Retriever # chunks of data\nSelf-querying # This allows the retriever to not only use the user-input query for semantic similarity comparison with the contents of stored documents but to also extract filters from the user query on the metadata of stored documents and to execute those filters.\nLangchian Retriever[10] # Name Index Type Uses an LLM When to Use Description Vectorstore Vectorstore No If you are just getting started and looking for something quick and easy. This is the simplest method and the one that is easiest to get started with. It involves creating embeddings for each piece of text. ParentDocument Vectorstore + Document Store No If your pages have lots of smaller pieces of distinct information that are best indexed by themselves, but best retrieved all together. This involves indexing multiple chunks for each document. Then you find the chunks that are most similar in embedding space, but you retrieve the whole parent document and return that (rather than individual chunks). Multi Vector Vectorstore + Document Store Sometimes during indexing If you are able to extract information from documents that you think is more relevant to index than the text itself. This involves creating multiple vectors for each document. Each vector could be created in a myriad of ways - examples include summaries of the text and hypothetical questions. Self Query Vectorstore Yes If users are asking questions that are better answered by fetching documents based on metadata rather than similarity with the text. This uses an LLM to transform user input into two things: (1) a string to look up semantically, (2) a metadata filer to go along with it. This is useful because oftentimes questions are about the METADATA of documents (not the content itself). Contextual Compression Any Sometimes If you are finding that your retrieved documents contain too much irrelevant information and are distracting the LLM. This puts a post-processing step on top of another retriever and extracts only the most relevant information from retrieved documents. This can be done with embeddings or an LLM. Time-Weighted Vectorstore Vectorstore No If you have timestamps associated with your documents, and you want to retrieve the most recent ones This fetches documents based on a combination of semantic similarity (as in normal vector retrieval) and recency (looking at timestamps of indexed documents) Multi-Query Retriever Any Yes If users are asking questions that are complex and require multiple pieces of distinct information to respond This uses an LLM to generate multiple queries from the original one. This is useful when the original query needs pieces of information about multiple topics to be properly answered. By generating multiple queries, we can then fetch documents for each of them. Ensemble Any No If you have multiple retrieval methods and want to try combining them. This fetches documents from multiple retrievers and then combines them. Long-Context Reorder Any No If you are working with a long-context model and noticing that it\u0026rsquo;s not paying attention to information in the middle of retrieved documents. This fetches documents from an underlying retriever, and then reorders them so that the most similar are near the beginning and end. This is useful because it\u0026rsquo;s been shown that for longer context models they sometimes don\u0026rsquo;t pay attention to information in the middle of the context window. 参考 # retrievers "},{"id":52,"href":"/www6vAIGC/docs/FineTuning/%E5%AE%9E%E8%B7%B5/FineTuningWhen/","title":"(原理)Fine-Tuning 时机","section":"实践 *","content":"\n何时进行微调[1] # 语言模型（LLM）可以通过至少两种方式学习新知识：权重更新（例如预训练或微调）或提示（例如检索增强生成，RAG）。模型的权重就像长期记忆，而提示就像短期记忆。这个OpenAI Cookbook给出了一个有用的比喻：当你对模型进行微调时，就像是在离考试还有一周的时候准备复习。当你通过提示（例如检索）向提示中插入知识时，就像是在有开放笔记的考试中。\n基于这一点，不建议使用微调来教授LLM新的知识或事实回忆；OpenAI的John Schulman在一次讲话中指出，微调可能会增加虚构。微调更适合教授专门的任务，但应与提示或RAG相对比。正如这里所讨论的，对于具有丰富示例和/或缺乏上下文学习能力的LLM来说，微调对于定义明确的任务可能是有帮助的。这篇Anyscale博客很好地总结了这些观点：微调是为形式而非事实[3]。\nwhat [4] # 这是一个很好的问题。我大致将微调类比为人的专业知识：\n用文字描述一个任务 ~= 零样本提示 给出解决任务的示例 ~= 少样本提示 允许人们练习任务 ~= 微调 考虑到这个比喻，令人惊奇的是我们有了可以仅通过提示就能在许多任务上达到高水平准确性的模型，但我也预计达到顶级性能可能需要微调，特别是在具有明确定义的具体任务的应用中，在这些任务中我们可以收集大量数据并在其上进行“练习”。\n这可能是一个需要牢记的粗略图景。小型模型无法进行上下文学习，并且从提示工程中受益甚少，但根据任务的难度，仍然有可能将它们微调为表现良好的专家。\n需要注意的是，所有这些都还是非常新颖的。\nCommon use cases[2] # 微调可以改善结果的一些常见用例包括：\n设定风格、语气、格式或其他定性因素 提高生成所需输出的可靠性 纠正无法按照复杂提示要求执行的问题 以特定方式处理许多边缘情况 执行难以用提示清晰表达的新技能或任务 从较高层面来看，这些情况下微调更容易实现“展示而非告诉”的效果。在接下来的部分中，我们将探讨如何为微调设置数据以及各种示例，这些示例中微调改善了基线模型的性能。\n参考 # Using LangSmith to Support Fine-tuning colab LANGCHAIN_API_KEY\nFine-tuning openai ***\nFine tuning is for form, not facts ***\nAndrej Karpathy twitter\n"},{"id":53,"href":"/www6vAIGC/docs/FineTuning/PEFT/FineTuningPEFT/","title":"(实战)PEFT 概述","section":"PEFT *","content":"\nHuggingface PEFT中的任务[1] # class TaskType(str, enum.Enum):\rSEQ_CLS = \u0026#34;SEQ_CLS\u0026#34; # 3. 序列分类任务\rSEQ_2_SEQ_LM = \u0026#34;SEQ_2_SEQ_LM\u0026#34; # 2. 条件生成任务\rCAUSAL_LM = \u0026#34;CAUSAL_LM\u0026#34; # 1. 因果语言建模任务\rTOKEN_CLS = \u0026#34;TOKEN_CLS\u0026#34; # 4. Token 分类任务\rQUESTION_ANS = \u0026#34;QUESTION_ANS\u0026#34;\rFEATURE_EXTRACTION = \u0026#34;FEATURE_EXTRACTION\u0026#34; 1. 因果语言建模任务（Causal Language Modeling） # 因果语言建模任务（CLM），在这种建模方法中，模型试图预测给定上下文中的下一个单词，该上下文通常包括在当前单词之前的所有单词。\n2. 条件生成任务（Conditional Generation） # 条件生成任务（Conditional Generation），根据给定的输入（可能是文本、图片等）生成符合条件的输出。 条件生成的应用包括但不限于机器翻译、文本摘要、图像描述等。这些任务通常需要模型在输入和输出之间建立复杂的映射关系。\n因果语言建模任务 vs. 条件生成任务 因果语言建模主要关注于生成连贯、自然的文本，而条件生成关注于生成满足特定条件或任务要求的文本。这两种建模方法在某些场景下可能会互相使用和结合，以实现更复杂的自然语言处理任务。\n3. 序列分类任务（Sequence Classification） # 序列分类（Sequence Classification），对整个句子进行分类。如: 获取评论的情绪，检测电子邮件是否为垃圾邮件，确定句子在语法上是否正确或两个句子在逻辑上是否相关等\n4. Token 分类任务（Token Classification） # Token 分类任务（Token Classification），对句子中的每个词进行分类。如: 识别句子的语法成分（名词、动词、形容词）或命名实体（人、地点、组织）。\n参考 # 大模型参数高效微调技术实战（一）-PEFT概述 LLM微调实战 李国东 "},{"id":54,"href":"/www6vAIGC/docs/Application/VectorStore/","title":"向量数据库","section":"Application","content":"\n向量数据库 # 国产\nMilvus Tencent zilliz cloud 国外\nPinecone FAISS [ANN] Chroma Weaviate 向量数据库-索引方式 [7] # 向量的相似度算法[3] # Cosine Similarity * 余弦 Dot Product * Squared Euclidean (L2-Squared) * 欧式距离 Manhattan (L1 Norm or Taxicab Distance) * Hamming * ANN 比较[4] # Similarity Metric Vector properties considered Euclidean distance Magnitudes and direction Cosine similarity Only direction Dot product similarity Magnitudes and direction 参考 # 云原生向量数据库Milvus扫盲，看完这篇就够了 云原生向量数据库Milvus（二）-数据与索引的处理流程、索引类型及Schema Distance Metrics in Vector Search Vector Similarity Explained xxx xxx 向量数据库（第 1 部分）：每个数据库有何不同？ 1xx. 微信向量检索分析一体化数仓探索：OLAP For Embedding *** 1xx. Meta向量数据库Faiss介绍\n"},{"id":55,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Tool-use/FunctionCall/","title":"(原理|实战) [OpenAI]Function Call","section":"Tool use","content":"\nFunction Call # 调用顺序 [0] [1][2] # Function Calling 整个功能的调用顺序大致如下 声明函数：定义当前函数的名称，描述，以及对应的参数信息，并请求对应的接口； 解析函数参数：接受对应的接口返回，并解析对应的函数参数信息； 执行函数：根据对应的参数信息调用本地函数； 上报结果：将本地函数执行的结果上报给 Chat 接口； 代码 [2] # goal # The goal of the OpenAI Function APIs is to more reliably return valid and useful function calls than a generic text completion or chat API.\n参考 # 大模型开发(十一)：Chat Completions模型的Function calling功能详解\n如何使用Chat Completions接口的函数调用功能\nOpenAI开发系列（十一）：Function calling功能的实际应用流程与案例解析 代码 流程图 代码 git\nOpenAI开发系列（十三）：利用Function calling功能开发基于大模型的实时天气查询助手 未\nOpenAI开发系列（十二）：Function calling功能的流程优化与多轮对话实现 未\n"},{"id":56,"href":"/www6vAIGC/docs/Agent/Overview/AgentGuide/","title":"(原理) Agent Guide +","section":"Overview","content":"\nAgent Guide # (原理) Agent Guide\n"},{"id":57,"href":"/www6vAIGC/docs/Agent/Communication/MCPArch/","title":"(原理)MCP 架构","section":"Communication *","content":" MCP 架构 [1] # 公网/内网级的权限控制 用户态的权限控制 工具快速接入能力 长工具列表优化 参考 # 1xx. Agent工程能力思考记录\n"},{"id":58,"href":"/www6vAIGC/docs/Agent/Communication/MCPManyTools/","title":"(原理|实现)MCP 大量工具调用 +","section":"Communication *","content":" MCP大量工具调用 # MCP-Zero \u0026amp; BigTool\n"},{"id":59,"href":"/www6vAIGC/docs/Deep-Research/%E5%AE%9E%E7%8E%B0/DeepresearchGoogle/","title":"(Google)Deep Research","section":"实现","content":"\n(Google)Deep Research # (Google)Deep Research\n"},{"id":60,"href":"/www6vAIGC/docs/FineTuning/PEFT/Soft-Prompt/PEFTPtuningPractice/","title":"(实战)PEFT P-Tuning","section":"Soft Prompt","content":"\n最佳实践[1] # 要看losss, 也要看业务的loss 生成模型常用的评价方法 BLEU 能评估流畅度** 结果都是流畅的前提下，ROUGE 反应参照句中多少内容被生成的句子包含（召回） 垂直模型 stf之后失去通用能力 要有通用能力, 需要pre-train和STF中都融入通用的语料 每个模型的学习率lr不一样 chatglm的学习率 LR=2e-2 学习率 # 改的特别大 模型训练的时候会震荡 改的特别小 模型训练的时候会收敛非常慢 参考 # 《13-基于 ChatGLM2的 Fine-tuning 实战》 AI 大模型全栈工程师培养计划 2期 train_pt2.sh git 基于法律文本的chatglm的p-tuning train_pt2.sh git 基于法律文本的chatglm-2的P-tuning v2 课件 bili有相关的总结的视频 "},{"id":61,"href":"/www6vAIGC/docs/FineTuning/%E5%AE%9E%E8%B7%B5/FineTuningBert/","title":"Fine Tuning-Bert","section":"实践 *","content":"\n基于bert的二分类 # 代码 - 全参FT,非PEFT import datasets from datasets import load_dataset from datasets import load_metric from transformers import AutoTokenizer, AutoModel from transformers import AutoModelForSequenceClassification from transformers import TrainingArguments from transformers import Trainer import transformers from transformers import DataCollatorWithPadding from sklearn.metrics import f1_score import torch import numpy as np import os import torch.nn as nn SEED=42 # ALBERT是一种压缩过的BERT MODEL_NAME = \u0026#34;albert-base-v2\u0026#34; DATASET_NAME = \u0026#34;glue\u0026#34; # 一组NLP评测任务 DATASET_TASK = \u0026#34;mrpc\u0026#34; # MRPC 是其中一个子任务 -- Microsoft Research Paraphrase Corpus # 在Bert的基础上加了一个线性分类器 class MyClassifier(torch.nn.Module): def __init__(self, backbone): super().__init__() self.bert_encoder = backbone self.linear = torch.nn.Linear(768, 2) def compute_loss(self, logits, labels): loss_fct = nn.CrossEntropyLoss() return loss_fct(logits, labels) def forward(self, input_ids, attention_mask,labels=None): output = self.bert_encoder(input_ids=input_ids, attention_mask=attention_mask) output = output.last_hidden_state[:, 0, :] output = self.linear(output) if labels is not None: loss = self.compute_loss(output, labels) return loss, output return output # 加载数据集对应的评估方法 glue_metric = datasets.load_metric(DATASET_NAME, DATASET_TASK) def compute_metrics(eval_pred): logits, labels = eval_pred predictions = np.argmax(logits, axis=-1) return glue_metric.compute(predictions=predictions, references=labels) # 加载数据集 raw_datasets = load_dataset(DATASET_NAME,DATASET_TASK) # 训练集 raw_train_dataset = raw_datasets[\u0026#34;train\u0026#34;] # 验证集 raw_valid_dataset = raw_datasets[\u0026#34;validation\u0026#34;] columns = raw_train_dataset.column_names # 设置随机种子 transformers.set_seed(SEED) # 定义tokenizer tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) # 定义数据处理函数，把原始数据转成input_ids, attention_mask, labels def process_fn(examples): inputs = tokenizer(examples[\u0026#34;sentence1\u0026#34;], examples[\u0026#34;sentence2\u0026#34;], truncation=True, max_length=128) examples[\u0026#34;input_ids\u0026#34;] = inputs[\u0026#34;input_ids\u0026#34;] examples[\u0026#34;attention_mask\u0026#34;] = inputs[\u0026#34;attention_mask\u0026#34;] examples[\u0026#34;labels\u0026#34;] = examples[\u0026#34;label\u0026#34;] return examples tokenized_train_dataset = raw_train_dataset.map( process_fn, batched=True, remove_columns=columns ) tokenized_valid_dataset = raw_valid_dataset.map( process_fn, batched=True, remove_columns=columns ) # 定义数据校准器（自动生成batch） collater = DataCollatorWithPadding( tokenizer=tokenizer, return_tensors=\u0026#34;pt\u0026#34;, ) # 定义模型 -- 其实Transformer可以直接用AutoModelForSequenceClassification #model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2) # 我手工写了分类器层，为了方便大家理解什么叫在Transformer上面做分类任务 backbone = AutoModel.from_pretrained(MODEL_NAME) model = MyClassifier(backbone) # 定义训练参数 training_args = TrainingArguments( output_dir=\u0026#34;./output\u0026#34;, # checkpoint保存路径 evaluation_strategy=\u0026#34;steps\u0026#34;, # 每N步做一次eval overwrite_output_dir=True, num_train_epochs=1, # 训练epoch数 per_device_train_batch_size=8, # 每张卡的batch大小 gradient_accumulation_steps=4, # 累加几个step做一次参数更新 per_device_eval_batch_size=8, # evaluation batch size logging_steps=20, # 每20步eval一次 save_steps=20, # 每20步保存一个checkpoint learning_rate=2e-5, # 学习率 warmup_ratio=0.1, # 预热（可选） ) # 定义训练器 trainer = Trainer( model=model, # 待训练模型 args=training_args, # 训练参数 data_collator=collater, # 数据校准器 train_dataset=tokenized_train_dataset, # 训练集 eval_dataset=tokenized_valid_dataset, # 验证集 compute_metrics=compute_metrics, # 评价指标 ) # 禁用wandb（与huggingface.co同步的机制） os.environ[\u0026#34;WANDB_DISABLED\u0026#34;] = \u0026#34;true\u0026#34; # 开始训练 trainer.train() 参考 # Bert fine-tuning 二分类\n"},{"id":62,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/framework/RAGQanything/","title":"(框架) Qanything","section":"framework","content":"\nQAnything # Arch[1] # 索引（indexing） 通过Embedding为每一个文本块生成一个向量表示，用于计算文本向量和问题向量之间的相似度。创建索引将原始文本块和Embedding向量以键值对的形式存储，以便将来进行快速和频繁的搜索。\n检索（Retrieval） 使用Embedding模型将用户输入问题转换为向量，计算问题的Embedding向量和语料库中文本块Embedding向量之间的相似度，选择相似度最高的前K个文档块作为当前问题的增强上下文信息。\n生成（Generation） 将检索得到的前K个文本块和用户问题一起送进大模型，让大模型基于给定的文本块来回答用户的问题。\n1st Retrieval（embedding）[1] # Bcembedding模型 [3]\n中英双语和跨语种能力 多领域覆盖 Embedding 可以给出一个得分，但是这个得分描述的更多的是相似性。Embedding本质上是一个双编码器，两个文本在模型内部没有任何信息交互。只在最后计算两个向量的余弦相似度时才进行唯一一次交互。所以Embedding检索只能把最相似的文本片段给你，没有能力来判断候选文本和query之间的相关性。但是相似又不等于相关。\n【embedding -\u0026gt; 相似性】\n2nd Retrieval（rerank）[1] # Rerank [3]\nRerank本质是一个Cross-Encoder的模型。Cross-Encoder能让两个文本片段一开始就在BERT模型各层中通过self-attention进行交互。\n【rerank -\u0026gt; 相关性】\n参考 # QAnything # QAnything Repo git xxx 有道QAnything背后的故事：关于RAG的一点经验分享 V\n有道QAnything背后的故事\u0026mdash;关于RAG的一点经验分享 文字版\n[公众号有其他文章] 1xx. 前沿重器[45] RAG开源项目Qanything源码阅读1-概述+服务\n"},{"id":63,"href":"/www6vAIGC/docs/Agent/Multi-agent/AgentAutogen/","title":"(原理\u0026实战)AutoGen +","section":"Multi-agent *","content":"\nAutoGen # (原理\u0026amp;实战)AutoGen\n"},{"id":64,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/RAGFailure/","title":"(Work)RAG 故障点 +","section":"实战 *","content":"\nRAG 故障点 # RAG 故障点\n"},{"id":65,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/RAGOptimize/","title":"RAG 优化 *","section":"实战 *","content":"\n朴素RAG Embedding # Embedding 召回方案及局限性[1] # 召回精度低 粒度过粗 不支持条件查询/统计 不能替代信息提取 解决方案 # 问题理解——准确识别用户意图(传统NLP) [2]\n基于关键词Embedding的入库和搜索 [2]\n关键词提取 实现信息抽取（Information Extraction，IE） 实体关系三元组抽取(RE, Relation Extraction ) 命名实体识别(NER, Name-Entity Recognition) 事件抽取(EE, Event Extraction) 基于 LLM 提取 [不推荐] 结果不准确、开销也大 传统 NLP 方法提取[推荐] 名词短语提取与整合 依存分析 成分句法分析 总结 从完整语句的 Embedding，切换为关键词 Embedding： 优势 相比传统 Embedding，大幅提升召回精准度。 使用传统 NLP 在专项问题处理上，相比 LLM 提供更好的精度和性能。 知识库存储选型\nVector Store 分片: 区分层级结构 Relational Database Graph Database 图数据检索 行业问答[3] # 挑战 # 版面复杂多样 文本分块 存在知识点被分割、不完整的情况。 多因素影响内容召回效果 例如：文档内容相似度高(专业文档细分领域、版本迭代等)； 通用的向量相似度算法效果不好(问题与问题匹配 VS问题与答案匹配)； 召回率受文档库增大而降低 优化 # 向量化上的优化\n训练目标优化为提升Query与段落的相关性，使得问题和相关段落的语义向量表示更接近，训练模型有sbert，cosent等 关键信息上的优化\n在文档内容的信息压缩上，进行文本关键词和摘要的提取 从完整语句的Embedding，切换为关键词Embedding 参考 # RAG探索之路的血泪史及曙光 腾讯 Embedding, Retrieval\nLLM+Embedding构建问答系统的局限性及优化方案 基于关键词Embedding的入库和搜索的流程图, 结合传统nlp任务 1xx. 基于大语言模型构建知识问答系统\n再看业界大模型行业问答的困难及若干业界实践：兼看智能客服常用路线及多场景prompt 问题 优化\n1xx. 大模型RAG问答研发真实图鉴：一周出Demo，半年用不好，缝补之路漫漫 1xx. 大模型行业落地实践的一些总结和观点：大模型行业问答落地中的现实挑战以及潜在的缓解策略 《DataFunCon2023深圳站-20231125-刘焕勇-大模型行业问答的现实挑战及潜在的缓解策略》 pdf\nxxx # 1xx. 再看RAG在真实金融文档问答场景的实践方案：SMP2023 金融大模型挑战赛的两种代表实现思路\n1xx. 构建企业级 RAG 系统的高级指南 [译]\n"},{"id":66,"href":"/www6vAIGC/docs/FineTuning/Data/DataSFTScaling/","title":"(原理)SFT Scaling","section":"Data","content":"\n论文 # 论文地址 《When Scaling Meets LLM Fine-tuning: The Effect of Data, Model and Fine-tuning Method》 摘要[1] # 这篇论文研究了大型语言模型（LLMs）的微调（finetuning）问题，尤其是在不同规模因素下的微调性能。作者探讨了包括LLM模型大小、预训练数据大小、新微调参数大小和微调数据大小在内的多个因素，并考虑了两种微调方法：全模型微调（FMT）和参数高效微调（PET，包括prompt tuning和LoRA）。研究发现LLM微调遵循基于功率的乘法联合规模法则，LLM模型规模的增加对微调性能的提升大于预训练数据规模的增加，而PET参数规模的增加通常效果不佳。此外，微调方法的选择高度依赖于具体任务和微调数据。\n【 功率的乘法联合规模法则: 微调数据数量 \u0026lt;\u0026ndash;\u0026gt; xxx】\n【模型大小(标题里的Model ) \u0026gt; 预训练数据(标题里的Data), PET参数(标题里的Fine-tuning Method) 无效】\n【微调方法的选择高度依赖于具体任务和微调数据】\n实验方法[1] # 实验基于两组预训练的双语LLMs（英语\u0026amp;德语，英语\u0026amp;中文），模型大小从1B到16B。作者在WMT机器翻译（英语-德语、英语-中文）和多语言摘要（英语、德语、法语和西班牙语）任务上进行了大规模研究，最多使用20M微调示例。实验设置包括：\n下游任务：选择机器翻译和多语言摘要作为微调的下游任务。 LLMs和预训练：采用解码器仅Transformer模型，使用修改后的UL2目标进行训练。 微调设置：研究了三种微调方法（FMT、Prompt和LoRA），并探索了四种不同的规模因素。 评估：使用基于token级别的困惑度（PPL）选择最佳检查点进行评估，并使用BLEURT和RougeL评估生成质量。 结论[1] # 提出了一个乘法联合规模法则来描述微调数据大小和其他规模因素之间的规模关系。 LLM模型规模的增加对微调性能的提升大于预训练数据规模的增加。 PET参数规模的增加对于LoRA和Prompt的效果有限，且有时甚至会导致反向规模效应。 微调方法的选择对于下游任务来说并不简单，需要根据任务特性和微调数据的可用性来决定。 微调可能会提高模型对相关任务的零样本泛化能力，尤其是当基础LLM较大时，Prompt和LoRA通常比FMT表现得更好。 作者指出，尽管研究提供了有价值的见解，但也存在一些局限性，如联合规模法则主要基于封闭生成任务的实证结果，缺乏理论基础。未来的工作将扩展到多模态LLMs，探索微调数据质量的影响，并考虑开放和创造性的生成任务以及微调的多任务设置。\n重要结论[2] # 作者们探讨了大型语言模型（LLMs）在微调（finetuning）过程中不同规模因素对性能的影响。以下是论文的一些重要结论及其对“SCALING”概念的解释：\n乘法联合缩放法则：作者提出了一个基于乘法的联合缩放法则（multiplicative joint scaling law），用于描述微调数据大小与其他缩放因素（如LLM模型大小、预训练数据大小、PET参数大小）之间的关系。这个法则表明，微调性能与这些因素的乘法组合有关，而不是简单的加法关系。 模型大小对微调的影响：研究发现，增加LLM模型的大小对微调性能的提升比增加预训练数据的大小更为显著。这表明在有限资源下，优先考虑扩大模型规模而不是数据规模，可能会带来更好的微调效果。 参数高效微调（PET）的局限性：尽管PET方法（如prompt tuning和LoRA）旨在通过优化少量参数来提高性能，但研究发现增加PET参数的大小对于微调性能的提升效果有限，有时甚至会出现反向缩放现象。 任务和数据依赖性：微调的缩放特性高度依赖于具体任务和数据。这意味着没有一种通用的最优微调方法，选择哪种微调方法需要根据下游任务的特性和可用的微调数据量来决定。 微调对零样本泛化能力的影响：尽管微调通常是为了提高特定任务的性能，但研究发现，基于LLM的微调仍然可以促进对相关任务的零样本泛化能力。特别是PET方法在保留模型的泛化能力方面表现更好。 微调数据量的临界点：论文中还讨论了不同微调方法之间的临界点，即在特定的微调数据量下，一种方法可能比另一种方法表现得更好。这个临界点会随着任务和模型大小的不同而变化。 这些结论对理解LLM微调过程中的“SCALING”具有重要意义。它们揭示了不同规模因素如何相互作用以及它们对微调性能的共同影响，为在实际应用中选择和优化微调策略提供了理论依据。通过这些发现，研究者和实践者可以更好地理解在特定条件下如何有效地缩放和配置他们的模型以获得最佳性能。\n参考 # 请帮我读篇论文，详细的写出摘要，实验方法，结论 kimi 请帮我读篇论文，论文有哪些重要的结论？ 这些结论是如何解释题目中的SCALING的？ kimi 1xx. 值得一看的大模型预训练数据选择策略总结：兼读20240229大模型进展早报\n《When Scaling Meets LLM Finetuning: The Effect of Data， Model and Finetuning Method»\n"},{"id":67,"href":"/www6vAIGC/docs/DocumentAI/DocumentAI/","title":"文档智能","section":"文档智能","content":"\n文档理解 两种范式[1, 10] # pipeline(OCR) # ERNIElayout [1] LayoutLM系列 [1] 端到端(OCR-free) # 基于小模型的OCR-free微调方案\nDonut 基于大模型的OCR-FREE微调方案\nLLaVAR [12] TextMonkey [11] mPLUG-DocOwl1.5 [20]\nDocOwl1.5由mPLUG-Owl2初始化，使用ViT/L-14作为视觉编码器，并使用带有模态自适应模块的7B大模型作为解码器。 每个子图像由ViT/L-14编码为1,024个特征，然后由H-Reducer缩减为256个特征。 TextMonkey [20]\n为了减少图像特征的冗余，继承了Qwen-VL中的图像重采样器，在每个窗口中都会使用。 文档版式分析数据集[10] # 参考 # 老刘-分享 值得一看的文档理解前沿方案及版式分析开源数据：三种模式、九大数据集 Monkey\nMonkey Demo LLaVAR：增强的视觉指令微调\nLLaVAR: Enhanced Visual Instruction Tuning for Text-rich Image Understanding 1xx. 加速 Document AI (文档智能) 发展\n加速 Document AI (文档智能) 发展\n1xx. 阿里面向企业数字化的文档智能技术与应用\n其他 # 也看跨模态大模型遇见文档理解：mPLUG-DocOwl1.5及TextMonkey方案中的数据工程 "},{"id":68,"href":"/www6vAIGC/docs/DocumentAI/Table/","title":"表格","section":"文档智能","content":" 表格处理[1] # 长表格 处理\n分成两半各自处理\n事后做检测，根据页眉页脚做合并， 对边界的处理 RapidTable [2] # MinerU 中的表格识别使用了RapidTable RapidTable 使用了以下4中模型 class ModelType(Enum): PPSTRUCTURE_EN = \u0026#34;ppstructure_en\u0026#34; # PaddleOCR PPSTRUCTURE_ZH = \u0026#34;ppstructure_zh\u0026#34; # PaddleOCR SLANETPLUS = \u0026#34;slanet_plus\u0026#34; # PaddleX UNITABLE = \u0026#34;unitable\u0026#34; ppstructure(PaddleOCR)[3] # 表格识别主要包含三个模型 单行文本检测-DB 单行文本识别-CRNN 表格结构和cell坐标预测-SLANet 具体流程图如下\n参考 # 蚂蚁数科AI Agent知识工程实践 Datafun https://github.com/RapidAI/RapidTable\nhttps://github.com/opendatalab/MinerU ppstructure/table 1xx. RAG实战系列，如何针对word文档中的表格进行问答，解决跨页表格问题 v\n1xx. 将图片或PDF中复杂的表格数据转成纯文本输入大模型，如何保持表格文字的排版布局不变？ v\n"},{"id":69,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Tool-use/AgentTuning/","title":"(实战)Agent Tuning","section":"Tool use","content":"\n基于微调的Agent - Function Call[1][2] # 基座模型\ninternLM 微调框架\nxtuner Agent Tuning[3] # 基座模型\nYi-6B Datasets 微调框架\nLLama-Factory 环境准备 # # source code git clone -b v0.7.1 \u0026lt;https://github.com/hiyouga/LLaMA-Factory.git\u0026gt; git switch -c v0.7.1 cd LLaMA-Factory # package 安装 conda create -n llama_factory python=3.10 conda activate llama_factory pip install llmtuner==0.5.1 # 环境变量 export CUDA_VISIBLE_DEVICES=0 # 使用第一块 GPU export USE_MODELSCOPE_HUB=1 # 使用魔搭社区下载渠道 # 阿里云必须加这句，不然页面会报异常 $ export GRADIO_ROOT_PATH=/${JUPYTER_NAME}/proxy/7860/ # 启动 python -m llmtuner.webui.interface 训练流程 # # flash-attn 安装 pip install flash-attn --no-build-isolation pip install modelscope -U 训练脚本 # 训练轮数 1.0 CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \\\\ --stage sft \\\\ --do_train True \\\\ --model_name_or_path 01ai/Yi-6B \\\\ --finetuning_type lora \\\\ --template default \\\\ --flash_attn True \\\\ --dataset_dir data \\\\ --dataset glaive_toolcall,alpaca_gpt4_en,alpaca_gpt4_zh,oaast_sft_zh \\\\ --cutoff_len 1024 \\\\ --learning_rate 5e-05 \\\\ --num_train_epochs 1.0 \\\\ --max_samples 8000 \\\\ --per_device_train_batch_size 4 \\\\ --gradient_accumulation_steps 4 \\\\ --lr_scheduler_type cosine \\\\ --max_grad_norm 1.0 \\\\ --logging_steps 5 \\\\ --save_steps 100 \\\\ --warmup_steps 0 \\\\ --lora_rank 8 \\\\ --lora_dropout 0.1 \\\\ --lora_target all \\\\ --output_dir saves/Yi-6B/lora/yi-agent-6b \\\\ --fp16 True \\\\ --plot_loss True 训练配置 训练结果 效果展示\n工具调用 - 查询天气\n【1个epoch好像有点问题】\nTuning # xtuner 实战 4【补充】用 MS-Agent 数据集 赋予 LLM 以 Agent 能力 (4)XTuner 大模型单卡低成本微调实战 V 单卡 3 小时训练专属大模型 Agent：基于 LLaMA Factory 实战 AgentTuning # 1xx. 基于llama7B的文本嵌入模型ANGLE：兼看Agent微调数据的生成方案 AgentTuning\n1xx. LLM之Agent（五）| AgentTuning：清华大学与智谱AI提出AgentTuning提高大语言模型Agent能力\n1xx. AgentTuning解读\nAgentTuning 实战 # 1xx. 2024年大模型Agent tuning关键技术Fireact, Agent-FLAN, AgentOhana, Agent LUMOS, STE, ETO,MoE, DebateGPT等\n1xx. Agent-FLAN 技术报告——社区翻译版 1xx. LLM 大模型学习必知必会系列(九)：Agent微调最佳实践，用消费级显卡训练属于自己的Agent！\n"},{"id":70,"href":"/www6vAIGC/docs/Agent/Overview/AgentCategory/","title":"(原理)Agent 分类[有趣|有用]","section":"Overview","content":"\n有趣的AI：更像人的AI # 好看的皮囊 多模态 # 多模态理解能力\n多模态数据端到端预训练的模型 Gemini 工程化 projection layer 直接用文本去粘接 encoder、decoder 和文本大模型 eg【自己动手做出Gemini演示视频的效果】 多模态生成能力\n视频生成 Live2D，3D 模型 DeepFake 录制一个真人视频， 把视频中的人脸换成指定的人脸照片 Image Animation 给定一张照片，随后根据这张照片生成一系列的对应视频 Video Diffusion 对物理世界的建模 成本最高 有趣的灵魂 # 个性\n基于prompt 完整地刻画出一个人物的历史、个性、记忆和性格 长文本 基于微调的 agent 更关键的还是数据 对话性语料 \u0026amp; 事实性语料 第一步，我们先用对话性语料去微调他的个性和说话风格 第二步，再去把事实性语料进行数据清洗后，基于各种角度提问，生成这个人物第一人称口吻的回答，这叫做数据增强 慢思考与记忆\n组件 记忆、情感、任务规划、工具 长期记忆 事实性的记忆 总结 文本总结 MemGPT RAG 和信息压缩 长上下文 长上下文 结合持久化 KV Cache 成本还是太高 【eg. 文本总结 + RAG】 程序性的记忆 few-shot 微调 短期来看仍然是效果最好的路线 有用的AI：更像工具的AI # 大模型基础能力 # 复杂任务的规划和分解 遵循复杂指令 自主使用工具 减少幻觉 1P-3P 产品法则 # 分类\n个人助理类 商业智能类 OpenAI 的 1P-3P 产品法则\n只要一两个人（1P）开发的产品就自己（first Party）做 1P 产品例子 导游 企业 ERP 助手 大模型采集数据 手机语音助手 RPA（机器人流程自动化） 腾讯的AppAgent 视觉方案 会议和生活记录器 需要三个人（3P）以上开发的产品就让第三方（third Party）做 解决复杂任务和使用工具 # 慢思考 思维链 思维链是非常自然的一种慢思考的模式 复杂任务的规划和分解 用多步的网络搜索去回答难题 AI 需要能够按照流程调用工具 工具使用属于过程记忆，使用场景和条件不是语言可以明确描述的 使用 fine-tuning 方法告诉模型一些工具使用的样例，甚至在预训练时就加入 工具使用可以用代码形式表达，因此属于代码生成能力 使用RAG方法获取到工具使用的代码 参考 # 1xx. AI Agent 应该更有趣还是更有用？ ***\n"},{"id":71,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Planning/AgentPlanAndExecute/","title":"(Work|实战)Plan\u0026Execute,ReWOO","section":"Planning","content":"\nPlan-and-execute [0] # 原理\nFigure 2 - 基于prompt [1] 代码\nplan [2] Planning Step Re-Plan Step 问题\n冗余的提示和重复的执行 -\u0026gt; ReWOO ReWOO [0] # 原理\nAbstract [10] 增强语言模型（ALM）将大型语言模型（LLM）的推理能力与允许知识检索和执行操作的工具相结合。现有的ALM系统以交错的方式触发LLM的思考过程，同时从这些工具中获取观察结果。具体而言，LLM推理过程中会调用外部工具，然后在获取工具响应后停止，基于之前的响应令牌来决定下一步的操作。这种范式虽然直观且易于实现，但常常由于冗余的提示和重复的执行而导致计算复杂度极高。本研究首次解决了这些挑战，提出了一种模块化的范式ReWOO（无观察推理），将推理过程与外部观察结果分离，从而显著减少了令牌的消耗。 Figure 1 [10] Planner里有格式化的#E Figure 2 [10] 代码 [11]\nExecutor-tool_execution() -\u0026gt; 状态机 问题\n是否可以并行？-\u0026gt; LLMCompiler LLMCompiler # 原理\nAbstract [20] LLM的多函数调用能力催生了基于LLM的软件开发，使其能够解决更复杂的问题。然而，当前的多函数调用方法通常需要针对每个函数进行顺序推理和执行，这可能导致较高的延迟、成本以及不准确的行为。为了解决这个问题，我们引入了LLMCompiler，它可以并行执行函数，以高效地编排多函数调用。LLMCompiler借鉴了经典编译器的原理，在LLM中使用三个组件来简化并行函数调用：（i）LLM规划器，制定执行策略和依赖关系；（ii）任务获取单元，分派和更新函数调用任务；（iii）执行器，以并行方式执行这些任务。通过LLMCompiler，用户可以指定工具以及可选的上下文示例，LLMCompiler会自动计算函数调用的优化编排。重要的是，LLMCompiler可以与LLaMA-2等开源模型以及OpenAI的GPT模型一起使用。 Figure 2 [20] 代码 [21]\nPlanner Task Fetching Unit Joiner 参考 # Plan-and-execute # LangGraph：Plan-Execute Agents 实战 V Plan-and-Execute Agents *** Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models Figure 2 plan-and-execute git ReWOO # ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models Reasoning without Observation git\nReWoo Agent框架代码实现 V\n1xx. ReWOO: 高效增强语言模型中解偶观测和推理 LLMCompiler # An LLM Compiler for Parallel Function Calling LLMCompiler "},{"id":72,"href":"/www6vAIGC/docs/Langchain/LangchainAgent/","title":"Langchain  Agent","section":"Langchain","content":"\nLangchain Agent # Conversational OpenAI assistants OpenAI functions OpenAI Multi Functions Agent OpenAI tools OpenAI parallel function calling (a.k.a. tool calling) ReAct ZeroShotReactAgent Self-ask with search Structured tool chat Langchain Apps # rag-chroma-private [2] # 本地 部署 This template performs RAG with no reliance on external APIs. It utilizes Ollama the LLM, GPT4All for embeddings, and Chroma for the vectorstore.\nresearch-assistant [3][4] # This template implements a version of \u0026ldquo;GPT Researcher\u0026rdquo; that you can use as a starting point for a research agent.\nLangGraph[5] # 参考 # Langchain Apps Project Code LangChain Agents 保姆级教程 | 动画演示 讲清 核心模块 Agents | Code 讲解 | Demo 演示 \u0026ldquo;Research Assistant\u0026rdquo;: Exploring UXs Besides Chat Building a Research Assistant from Scratch LangGraph gpt-researcher "},{"id":73,"href":"/www6vAIGC/docs/Agent/Practice/AgentOpt/","title":"(Survey) Agent 优化 +","section":"Practice","content":"\nAgent 优化 # (Survey) Agent 优化\n"},{"id":74,"href":"/www6vAIGC/docs/Agent/Practice/AgentPractice/","title":"(实战)Agent","section":"Practice","content":"\nAssistant API [3] # Assistant API功能介绍 # 从功能实现层面来说，Assistant API是截至目前最完整、性能最强大的AI应用开发API，具体功能如下：\n首先，Assistant API前所未有的能够调用OpenAI各模型的各项能力，包括可以调用Chat系列模型（即GPT系列模型）完成文本对话、调用DALL·E 3进行绘图、调用GPT-4-vision进行图像识别、以及调用Text-to-Speech模型进行语音转文字等，并且支持在一轮对话中调用不同模型； 其次，Assistant API还内置了代码解释器功能（Code interpreter）和海量文本信息提取功能（Knowledge retrieval）同时也一如既往支持借助Function calling进行模型功能层面拓展，此外，非常重要的是，Assistant API还支持在一轮对话中调用多个工具； 其三，此外对于开发者非常友好的一点是，Assistant API最小运行单元为持久化的线程对象（persistent Threads），因此在实际运行Assistant API时，不仅能可以精确控制每一步的执行过程，同时persistent Threads也会保留每轮对话的核心信息，并且当超出模型接收信息最大上下文限制时能够自动删除早期信息，从而实现对模型短期记忆的合理管理； 其四，Assistant API还能够直接连接OpenAI在线文档库，即如果用户将外部文档保存在OpenAI云空间内，则可以在调用Assistant API时实时访问文档库中的任意文件，甚至可以在不同线程中调用不同的文档。而在借助Assistant API的Knowledge retrieval功能，则可以让大模型实时获取这些文件信息，并且合理管理短期记忆； 实战 # Lagent \u0026amp; AgentLego[4] # 参考 # Assistant API详解与Agent开发实战-九天Hector\nLagent \u0026amp; AgentLego 智能体应用搭建\nLagent：轻量级智能体框架\nAgentLego：组装智能体“乐高”\n1xx. 使用Qwen-Agent将上下文记忆扩展到百万量级\n"},{"id":75,"href":"/www6vAIGC/docs/RAG/Overview/RAGPerformance/","title":"(原理)Advanced RAG +","section":"Overview","content":"\nAdvanced RAG # (原理)Advanced RAG\n"},{"id":76,"href":"/www6vAIGC/docs/Prompt-Engineering/PromptCode/","title":"(原理)[Prompting]Coding","section":"Prompt Engineering","content":"\n工具 # Copilot *** - 收费 AWS CodeWhispter Cursor *** tabnine 免费 Code Llama - 开源 代码相关-简单任务 [1] # 注释\n你作为一名程序员，请解释一下下面这段代码\n防御性编程 请为这段代码增加防御性编程的功能\n写单元测试\n时间复杂度 time complexity 这段代码的时间复杂度是多少\n流程图 画出redis master和slave之间同步的流程图\nWriting shell script\nWriting git commands 一个分支中的代码合并到另一个分支中\nImprove code\nHow do i improve this code? fruits = [\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;] newlist = [] for x in fruits: if \u0026#34;a\u0026#34; in x: newlist.append(x) print(newlist) Translating Code 代码转换 Convert this Python code to Javascript 请把下面这段python代码转换成Java代码 代码相关- 繁琐工作 [1] # Building API\nI need an API built with express.js to return the list of products. Each product should have attributes like ID, title, description, price and imageUrl modify the code and retrieve the products from a MongoDB database use TypeScript in this code Generate this API using Python and FastAPI Generating Dummy Data\nGenerate dummy data for a table called customers. Each customer should have an ID, first name, last name and city. I don\u0026rsquo;t need a Javascript. Just give the data. Create a Python class for storing these objects. SQL\nwrite a SQL query to generate a table called products with these columns： ID（int） title（string） category(int) write a query to retrieve the top 5 customers in Shanghai Revise this query and join the customers table with the orders table to find out how much each cumster has spent. Then pick the top 5 who have spent the most. 正则 [2]\nCronJob [2]\nK8s\n运维 Ops [4] # 编程语言 vs 自然语言 # 语言类型 执行原理 C++语言 C++语言 \u0026ndash;\u0026gt; 编译器/链接器 \u0026ndash;\u0026gt; 既定任务 Java语言 Java语言 \u0026ndash;\u0026gt; 编译器/虚拟机 \u0026ndash;\u0026gt; 既定任务 Python语言 Python语言 \u0026ndash;\u0026gt; 解释器 \u0026ndash;\u0026gt; 既定任务 人类自然语言 人类自然语言 \u0026ndash;\u0026gt; LLMs \u0026ndash;\u0026gt; 各种后端组件 \u0026ndash;\u0026gt; 既定任务 参考 # 【ChatGPT】面向程序员的ChatGPT使用教程38种方式来提升生产力 V GitHub Copilot 实践课 03, 04, 06 AICoder git ChatGPT 帮我跑了一个完整的 DevOps 流水线，离了个大谱\u0026hellip; Gin on K8s git PromptOps Top 20 ChatGPT Prompts For Software Developers 未 "},{"id":77,"href":"/www6vAIGC/docs/Deep-Research/%E5%AE%9E%E7%8E%B0/DeepresearchLanggraph/","title":"(Langgraph)Deep Research","section":"实现","content":"\n(Langgraph)Deep Research # (Langgraph)Deep Research\n"},{"id":78,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/framework/RAGRAGflow/","title":"(框架)RAGflow +","section":"framework","content":"\nRAGflow # RAGflow\n"},{"id":79,"href":"/www6vAIGC/docs/RAG/Overview/RAGEval/","title":"RAG 评估","section":"Overview","content":"\n1xx. 如何利用RAGAs评估RAG系统的好坏\n使用LangChain和RAGAS对RAG系统进行自动有效评估\n1xx. 一次搞懂RAG评估，三个角度LangChain，LlamaIndex，RAGAS\nRAG评估资料大全 RAG评估指标：两种视角理解评估指标\nRAG Evaluation\nRAG evaluation with RAGAS\n1xx. 再看大模型RAG检索增强如何评估：RAGAS开源自动化评估框架\n1xx. 大模型RAG检索增强问答如何评估：噪声、拒答、反事实、信息整合四大能力评测任务探索 "},{"id":80,"href":"/www6vAIGC/docs/RAG/phase/phaseRAGPostRetrieval/RAGRerank/","title":"(原理|实战)RAG Rerank","section":"(Phase)post-retrieval","content":"\nReranker [22] # A reranking model — also known as a cross-encoder — is a type of model that,given a query and document pair, will output a similarity score.\n产品 # BGE Ranker [20] # 交叉编码器将对查询和答案实时计算相关性分数，这比**向量模型(即双编码器)**更准确，但比向量模型更耗时。 因此，它可以用来对嵌入模型返回的前k个文档重新排序。 我们在多语言数据上训练了交叉编码器，数据格式与向量模型相同，因此您可以根据我们的示例 轻松地对其进行微调。\nBCE[24] # 中文效果比BGE好[老刘说nlp]\n优秀的组合 [21] # OpenAI + CohereRerank Voyage + big-reranker-large\n参考 # BGE Reranker transformers二次开发——bge-reranker模型微调流程 V RAG 再添新利器！智源开源最强检索排序模型 BGE Re-Ranker v2.0 提升RAG——选择最佳Embedding和重新排名模型 Boosting RAG: Picking the Best Embedding \u0026amp; Reranker models\nRerankers and Two-Stage Retrieval *** 文中的第二阶段就是指Reranker\nyoudao RerankerModal BCE\n1xx. 一文详看Langchain框架中的RAG多阶段优化策略：从问题转换到查询路由再到生成优化 rag-from-scratch Repo git\n"},{"id":81,"href":"/www6vAIGC/docs/Agent/Practice/AgentChallenge/","title":"(原理)Agent Challenge","section":"Practice","content":"\n问题和局限性 [4] # 记忆召回问题\n只是做简单的 embedding 相似性召回，很容易发现召回的结果不是很好\n错误累积问题\n探索效率问题\n中途引入人工的判断干预和反馈输入\n任务终止与结果验证\n模型 agent 的工作如何终止也是一个挑战\n挑战 [8] # 如何让 agent 选择合适的工具 # Toolformer - fine tune Gorilla - retrieval，fine tune\n【solution: SFT or RL】 不必要的工具使用 # “Human Input”也写成一种工具，让模型来主动发起对人类的提问\nHuman as a tool\n【solution: human-in-the-loop】\nAgent 返回的格式不稳定 # 这里常见的做法是让 LLM 按照 json 这类常见的 schema 来返回，一般稳定性会高一些（相比“Action:”这种）。\n此外自动修复重试也很实用，可以利用 LangChain 里的 output parsers 来帮助完成。\n【solution: json output】\n记住之前的操作，避免重复 # AutoGPT - retrieval 结合近期操作记录\n【solution: memory】\n处理超长的 observation # 需要用一些工具从中提取有用信息，或者放到外部存储中再借助 retrieval 来使用。\n专注于目标 # 简单的做法是在 prompt 结尾处再把目标加上，引起 agent 的注意。\n另外像 BabyAGI，HuggingGPT 这种把 planning 和 execution 分开的做法也是很有用。拆分的比较细的任务往往步骤比较短，也不容易丢失目标。\n结果评估 # 评估最终结果是否正确 过程的细化评估 选择的中间步骤是否正确。 生成 action 的 input 是否正确。 生成的步骤序列是否合理高效。\n【 eval 】 参考 # AutoGPT与LLM Agent解析 *** LLM 全栈开发指南补遗 Agents ***\nHarrison Chase: Agents *** 1xx. LLM Agent 现状和一些思考 （202401）\n当前 Agent 的缺陷和挑战\n1xx. Agent开发者坦白：窘境中前行\n"},{"id":82,"href":"/www6vAIGC/docs/FineTuning/Data/DataSelection/","title":"(原理)Data Selection","section":"Data","content":"\nIFD[1] # 三个步骤 Learning from Brief Experience 利用少量进行进行模型初学 Evaluating Based on Experience 利用初学模型计算原始数据中所有IFD指标 算法 条件回答分数（ Conditioned Answer Score，CAS） 直接答案分数（Direct Answer Score，DAS） 指令跟随难度（Instruction-Following Difficulty，IFD）分数 Retraining from Self-Guided Experience 利用樱桃数据进行模型重训练 MoDS[2] # 质量筛选 采用OpenAssistant的reward-model-debertav3-large-v2模型（一个基于DeBERTa架构设计的奖励模型）对数据进行质量打分。\n多样性筛选 为了避免所选质量数据高度相似，通过K-Center-Greedy算法进行数据筛选，在最大化多样性的情况下，使指令数据集最小。 在该步骤中，采用BERT模型为指令数据生成句向量来计算不同数据之间的距离。\n必要性筛选\nDEITA [3] # 复杂性评分 # 复杂性评估的方法 Random Selection：随机选择样本。 Instruction Length：按照指令的长度计算复杂性。 Perplexity：通过预训练模型计算回复的困惑度作为复杂性指标，困惑值越大意味着数据样本越难。 Direct Scoring：利用ChaGPT给指令的复杂性打分。 Instruction Node：利用ChatGPT将指令转换成语义树，通过树的节点数作为复杂性指标。 Instag Complexity：利用ChatGPT对部分数据进行打标签，再训练一个Llama模型，再利用训练后的Llama模型对全量数据预测，标签越多说明数据约复杂。 IFD：指令跟随难度作为复杂性指标。 DEITA评估复杂性的方法，主要先对一个小规模种子数据集（2k）进行数据复杂性扩展，再利用ChatGPT对扩展数据进行打分，并训练一个Llama1-7B的模型，最后利用训练后的模型对数据的打分作为复杂性评估指标。\n质量评分 # 质量评估的方法有 Random Selection：随机选择样本。 Response Length：采用输出长度作为质量评估指标。 Direct Scoring：利用ChatGPT直接评估对特定指令输出结果的准确性。 DEITA评估质量的方法，与评估复杂性方法一致。先对一个小规模种子数据集（2k，与复杂性数据一致）进行数据质量扩展，再利用ChatGPT对扩展数据进行打分并训练一个Llama1-7B的模型，最后利用训练后的模型对数据的打分作为质量评估指标。\n数据质量扩展，通过特殊的提示词利用ChatGPT对数据的回复部分进行改写，主要是增强回复的有用性、相关性、丰富深度、创造力和提供额外的细节描述。\n多样性筛选 # 多样性筛选方法，首先将数据池中的数据按照复杂性和质量的综合得分（复杂性分数*质量分数）进行降序排序； 然后按顺序逐个取出样本数据x ，计算x 与筛选池中相邻最近的样本之间距离值，其中，数据利用Llama1-13B模型进行向量表征，距离计算采用余弦相似度。 如果距离值小于 r时，认为该样本与筛选池中数据相似程度不高，可以纳入筛选池；否则不纳入筛选池。当筛选池中样本数达到规定样本个数，完成多样性筛选。\n参考 # 如何从数据集中自动识别高质量的指令数据-IFD指标的使用\n《From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning》\nChatLaw就这么训的\n高质量指令数据筛选方法-MoDS\n《MoDS: Model-oriented Data Selection for Instruction Tuning》\n质量筛选， 多样性筛选，必要性筛选\nDEITA-大模型指令微调的数据高效筛选方法\n1xx. DEITA：融合复杂度、质量、多样性的高效数据筛选\n复杂度、质量、多样性\n1xx. 值得一看的大模型预训练数据选择策略总结：兼读20240229大模型进展早报 《A Survey on Data Selection for Language Models》\n"},{"id":83,"href":"/www6vAIGC/docs/FineTuning/PEFT/Soft-Prompt/PromptTuningPractice/","title":"(实战)PromptTuning","section":"Soft Prompt","content":"\n参考 # 大模型参数高效微调技术实战（二）-Prompt Tuning 大模型参数高效微调技术原理综述（二）-BitFit、Prefix Tuning、Prompt Tuning peft_prompt_tuning_clm.ipynb\n"},{"id":84,"href":"/www6vAIGC/docs/Application/NL2SQL/chatBI-Ant/","title":"(蚂蚁)chatbi","section":"NL2SQL","content":"\n【难点 大量的术语、黑话、经验逻辑】\n【数据库理解 - 保底】\n【业务逻辑 - 摸高】\n【 第三步是必须的 sqllinking - 要用ES 倒排 召回相关的 表， 列， UDF ， 单元格\n单元格链接 - 让大模型看到 fund_type = ‘混合型’ 】\n参考 # 蚂蚁数科AI Agent 知识工程实践 "},{"id":85,"href":"/www6vAIGC/docs/Prompt-Engineering/Prompt/","title":"(原理)[Prompting]How to use","section":"Prompt Engineering","content":"\n乔哈里沟通视窗-4 象限 # 你不知道，GPT知道 # 1、元问题：我想了解xxxx，我应该向你问哪些问题？\n2、请给我列出xxx领域/行业相关的，最常用的50个概念，并做简单解释。如果有英文缩写，请给出完整的英文解释。\n3、请详细介绍一下elon musk的主要生平事迹。请详细介绍一下tesla这家企业的发展历程。\n你知道，GPT也知道 # 检验认知： 1、对于xxx主题/技能，你认为哪些是我必须理解和掌握的核心要点？\n2、我理解的xxx是这样的，你觉得我的理解对吗？\n3、我对xxx有一些想法，你能帮我批判性地分析一下这些想法的优点和缺点吗？\n4、我正在考虑xxx的决定，你能帮我分析一下可能的结果和影响吗？\n扩充认知：\n1、我知道xxx的概念，我想知道更多关于xxx的信息。\n2、我在xxx问题上遇到困难，你能提供一些可能的解决方案或建议吗？\n3、我想要深入学习xxx，你能推荐一些进阶的学习资源或学习路径吗？\n4、我想要在xxx领域有所创新，你能提供一些启发或想法吗？\n5、我想在xxx领域提升自己，你能根据最新的研究和趋势给我一些建议吗？\n6、我正在考虑学习xxx，你能给我一些关于这个领域未来发展的观点吗？\n7、（背景信息xxx），我要做关于xxx的研究，我认为原因是，还有其他可能的原因吗？给出一些可能的研究假设。\n8、我是一个xx新手，马上要采访这个行业的资深大佬，我应该向他请教哪些有价值的问题？\n你知道，GPT不知道 # 介绍背景现象之后可以向gpt发问，你怎么看待这种现象？可能的原因有哪些？这会对xxx产生什么样的影响？你觉得xxx应该怎么做？\n你和GPT都不知道 # 如果xxx，这对社会会产生什么影响？\n达克效应 # 检验自己认知/能力水平提问句式 # 1、为了测试我对xxx的理解程度，你会问我什么问题来检验我的水平，最少10个。\n2、我是xx领域的专家，你会问我哪些问题来检验我的专业水平？\n3、追问一句，这些我都懂，还有更专业更细更深的问题吗？\n4、你问我答的游戏\n扩展自己能力边界的提问句式我已经很精通xxx了，我想知道我是否还有需要学习的地方？然后不停的问，还有呢还有呢？\n知道做到 # 让GPT完成具体任务\n1、我想做xxx，你能给我提供什么帮助？\n2、我想要你做xxx，我应该给你输入什么信息？\n3、直接下指令\n角色关系 # 模拟虚拟人物 模拟名人 模拟一段关系 模拟多个具体的人 模拟多类人 通用 # 沟通模式 # prompt = 定义角色+背景信息+任务目标+输出要求\n归纳 # 使用markdown格式写富爸爸穷爸爸的思维导图，以代码格式输出 以脑图的方式归纳上文 请用提纲的方式来归纳上文 请用简练的列提纲的方式来归纳上文 思维链 # 没啥用 # 请用简单的语句来归纳上文，归纳的语句可以生成脑图\n请用金字塔思维的方式来简单的归纳上文\nPrompt - How to use # Learn Prompting *** **\nChatgpt ShortCut ChatGPT Shortcut Awesome ChatGPT Prompts\nsnackprompt.com ***\nflowgpt ***\nprompthero\npublicprompts\nhttps://learningprompt.wiki/ prompt 学习教程\nPrompt 大全\n提示指令库 汇总\n参考 # 学完这个视频，简历加一条：熟练掌握ChatGPT解决复杂问题｜ChatGPT使用教程 ***\n"},{"id":86,"href":"/www6vAIGC/docs/RAG/Pattern/KG-RAG/RAGKG/","title":"RAG KG","section":"KG-RAG","content":"\nVector+KG RAG[15][16] # RAG 多跳问题 # 参考 # RAG 多跳问题 # 1xx. Knowledge Graphs \u0026amp; LLMs: Multi-Hop Question Answering\n知识图谱和 LLM：多跳问答-腾讯云开发者社区-腾讯云\nLLMs之KG-RAG：KG-RAG/GraphRAG(基于知识图谱的RAG系统)的简介(可以解决多跳问题/同时支持结构化和非结构化数据查询)、经验技巧、案例应用之详细攻略-CSDN博客\n1xx. MultiHop-RAG：多跳查询的基准检索增强生成_rag多跳查询-CSDN博客\nLLM+KG 知识图谱 # Enhanced QA Integrating Unstructured Knowledge Graph Using Neo4j and LangChain\nUsing a Knowledge Graph to implement a DevOps RAG application\n1xx. 大模型辅助图谱构建的4个策略对比：兼看大模型与知识图谱结合的3个综述 "},{"id":87,"href":"/www6vAIGC/docs/RAG/Overview/RAGSFT/","title":"RAG vs SFT","section":"Overview","content":"\nRAG vs FT[1] # RAG vs 微调[场景] # 动态数据：RAG\n模型能力定制：微调\n幻觉：RAG \u0026gt; 微调\n可解释性：RAG\n成本：RAG\n依赖通用能力：RAG\n​ 微调会有灾难性的遗忘\n延迟：微调 ​ rag的流程长\n智能设备：微调 【rag和微调可以一起使用】\n应用 Case # A: 投资理财规划师 [用RAG]\n处理动态数据：RAG 很强的对话能力：RAG 金融能力：微调 × B: 金融信息抽取Bot [用微调]\n很强的抽取能力：微调 [特定的能力] 金融能力 C: 销售机器人 [用RAG+微调]\n多轮对话/动态：RAG 销售技巧/语气：微调 RAG vs FT [2] # todo: 有中文翻译的图片\n参考 # 大模型项目选择RAG还是微调：三个案例 v 大模型项目选择RAG还是微调：八个判断依据 v\n#1《Retrieval-Augmented Generation for Large Language Models: A Survey》\n面向大语言模型的检索增强生成技术：综述 [译] 翻译\nLLM之RAG理论（二）| RAG综述论文详解\n同济大学发布最新检索增强(RAG)的LLM生成技术综述\n面向大模型的检索增强生成（RAG）综述\n​ 大语言模型的检索增强生成 (RAG) 方法\nLLM知识增强：RAG\u0026amp;微调？微软给出部分答案 microsoft RAG 或 Fine Tume - 为您的用例选择正确方法的权威指南 "},{"id":88,"href":"/www6vAIGC/docs/Prompt-Engineering/PromptingGrok/","title":"(原理)Grok 提示框架","section":"Prompt Engineering","content":" Grok 提示框架 # 看看Gork的提示词5种Prompt框架，充分发挥 Grok 的潜力：\nR-T-F（角色 - 任务 - 格式） T-A-G（任务 - 行动 - 目标） B-A-B（之前 - 之后 - 桥梁） C-A-R-E（背景 - 行动 - 结果 - 示例） R-I-S-E（角色 - 输入 - 步骤 - 期望） 参考 # Grok 提示框架（Grok Prompt Frameworks）\n"},{"id":89,"href":"/www6vAIGC/docs/Deep-Research/%E5%AE%9E%E7%8E%B0/OpenManus/","title":"(实现)OpenManus *","section":"实现","content":" OpenManus # (实现)OpenManus\n"},{"id":90,"href":"/www6vAIGC/docs/Agent/Platform/Dify-deploy/","title":"(实践)Dify 生产部署 *","section":"Platform *","content":"\n参考 # 【深度】企业 AI 落地实践（四）：如何构建端到端的 AI 应用观测体系\n"},{"id":91,"href":"/www6vAIGC/docs/Deep-Research/%E5%AE%9E%E7%8E%B0/researchSystem/","title":"(实践)Research system[Anthropic]","section":"实现","content":" “Research”功能架构概览[1] # Prompt engineering and evaluations for research agents[1] # 在开发过程中，他们总结了8个多智能体系统的设计原则：\n像智能体一样思考\n用模拟和可视化工具观察智能体决策，及时发现和修正失败模式，理解提示词对行为的影响。\n教会主控智能体如何分工\n主智能体需为每个子智能体分配清晰目标、输出格式、工具指引和任务边界，避免重复或遗漏。\n根据任务复杂度分配资源\n在提示词中嵌入“规模规则”：简单任务用少量智能体和工具调用，复杂任务用更多资源，防止资源浪费或过度投入。\n工具设计与选择至关重要\n工具接口要像人机界面一样清晰，描述明确，避免误用。智能体需先评估所有可用工具，匹配用户意图选择最合适的工具。\n让智能体自我改进\n利用大模型自身能力优化提示词和工具描述，通过“工具测试智能体”不断发现和修正工具使用中的问题。\n先广后深\n搜索策略应先用宽泛查询探索全局，再逐步聚焦细节，避免一开始就陷入死胡同。\n引导思考过程\n通过“扩展思考模式”让智能体显式规划、评估和调整策略，提升适应性和推理能力。\n并行工具调用极大提升效率\n主智能体和子智能体都应并行调用工具，显著缩短研究时间，提升覆盖面和深度。\n以及评测与工程化的6条实践经验：\n结果导向评测：关注最终结果是否正确，而非过程是否完全按预设执行。 LLM 自动评测结合人工检查：用大模型自动打分，人工补充发现边界问题，快速迭代优化。 状态管理与错误恢复：智能体需持久化状态，优雅处理错误，不能简单重启。 灰度部署与升级：采用渐进式部署，避免影响正在运行的智能体。 长对话上下文管理：用摘要、外部记忆等机制防止上下文溢出。 子智能体直接产出结构化结果：如代码、报告等，减少信息损失和 Token 消耗。 Cookbook提示示例：https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents/prompts\n智能体的有效评估 # todo\n生产可靠性与工程挑战 # todo\n参考 # Anthropic谈如何构建生产级多智能体系统 How we built our multi-agent research system 原文\n1xx. [LangGraph] gemini 开源全栈 deep research 及 Anthropic multi-agent research system 导读 https://github.com/chunhuizhang/prompts_for_academic/blob/main/deepresearch/multi-agent research system.ipynb\n1xx. 一文读懂 Claude Research：多智能体系统如何重塑复杂任务处理？\n"},{"id":92,"href":"/www6vAIGC/docs/Agent/Practice/Agent12Factor/","title":"Agent 12-Factor +","section":"Practice","content":"\nAgent 12-Factor # Agent 12-Factor\n"},{"id":93,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Tool-use/AgentToolGorilla/","title":"(Work)[SFT]Gorilla","section":"Tool use","content":"\n论文 # 论文地址 Gorilla: Large Language Model Connected with Massive APIs\n开源地址 gorilla git\n方法论[1] # 数据集收集 # API文档\nHuggingFace平台托管和提供了约203,681个模型。然而，其中许多模型的文档质量较差，缺乏依赖项，模型卡中没有信息等问题。 为了筛选出质量较好的模型，从每个领域选择了前20个模型。考虑了多模态数据领域的7个领域，CV领域的8个领域，NLP领域的12个领域，音频领域的5个领域，表格数据领域的2个领域和强化学习领域的2个领域。 经过筛选，从HuggingFace获得了总共925个模型。从TensorFlow Hub获得了801个模型，并从Torch Hub获得了95个模型。 这些模型的信息被转换为JSON对象，其中包含了领域（domain）、框架（framework）、功能（functionality）、API名称（api_name）、API调用（api_call）、API参数（api_arguments）、环境要求（environment_requirements）、示例代码（example_code）、性能（performance）和描述（description）等字段。 选择这些字段是为了将其泛化到机器学习领域之外的其他领域，包括RESTful API调用。 总而言之，通过筛选和整理，从HuggingFace、TensorFlow Hub和Torch Hub等平台获取了总共1,645个模型的信息，并将其以JSON对象的形式进行了记录和描述。这些信息包括模型的领域、框架、功能、API调用示例、性能等，以便在机器学习和其他领域中使用和参考。 指令生成 （Instruction Generation ）\n在self-instruct范例[42]的指导下，使用GPT-4生成了合成指令数据。 提供了三个上下文示例和一个参考API文档，要求模型生成调用API的真实世界用例。 明确指示模型在创建指令时不要使用任何API名称或提示。 为每个三个模型中心构建了六个示例（指令-API对），共计18个点，这些数据是手动生成或修改的。 对于1,645个API数据点中的每一个，从相应的六个指令示例中随机选择3个，生成总共10个指令-API对。 强调只需要使用GPT-4生成指令，可以与开源替代方案（如LLaMA、Alpaca等）进行交换。 总而言之，通过使用GPT-4生成指令，并结合上下文示例和参考API文档，在每个模型中心构建了六个示例，共计18个点。这些示例被用于生成1,645个API数据点中的每一个的指令-API对，生成总共10个对应关系。与开源替代方案相比，GPT-4的指令生成功能被应用在这个过程中。 Gorilla # 带有约束的API调用（API Call with Constraints）\nAPI调用通常具有固有的约束，这些约束要求LLM不仅理解API调用的功能，还要根据不同的约束参数对调用进行分类。 机器学习API调用中常见的约束集是参数大小和准确性的下限。这些约束要求LLM能够根据提示理解和回答问题，例如根据提示选择参数少于10M的图像分类模型，并且至少保持70%的ImageNet准确率。 对LLM来说，理解和推理出请求中嵌入的各种约束是一个巨大的挑战。LLM需要细致地理解用户的功能描述，并能够正确地处理伴随这些调用的复杂约束。 这个挑战凸显了在实际API调用中对LLM的复杂要求。仅仅理解API调用的基本功能是不够的，模型还必须能够应对伴随这些调用的约束，如参数大小和准确性要求。 总而言之，在机器学习API调用中，LLM面临着理解和处理约束的挑战。除了理解API调用的基本功能外，LLM还需要能够识别和满足伴随调用的约束要求，如参数大小和准确性的下限。这需要模型具备更细致的理解和推理能力，以满足实际API调用的复杂需求。 参考 # Gorilla：与大规模API相连的大型语言模型 *** 1xx. Gorilla：链接海量API的大型语言模型 V 1xx. 大猩猩（Gorilla）🦍，连接大量 API 的大型语言模型，能成为未来AI应用的核心么？ ***\n1xx. Gorilla: Large Language Model Connected with Massive APIs 1xx. Gorilla blog\n"},{"id":94,"href":"/www6vAIGC/docs/Application/NL2SQL/opensource/","title":"(开源)NL2SQL","section":"NL2SQL","content":" 参考 # 1xx. 大模型再总结及ChatSQL实践案例分享：大模型训练数据及工具的5张脑图总结及ChatSQL开源项目实现解析 *\n1xx. 大模型Text2SQL主流数据集及可用实践项目：兼看利用大模型进行5W1H新闻要素提取 问题2:关于Text2sql当前的可用项目及数据集\nhttps://github.com/eosphoros-ai/Awesome-Text2SQL/\nChatbi # supersonic 腾讯音乐 *** DB-GPT 阿里 *** https://github.com/Canner/WrenAI WrenAI：开源Text-to-SQL引擎让 SQL触手可及，数据分析的“GPT”时刻来了？ https://github.com/vanna-ai/vanna\n开源 Text-to-SQL 工具哪家强？Vanna 让 SQL 小白也能轻松玩转数据分析！ https://github.com/defog-ai/sqlcoder * https://github.com/Dataherald/dataherald * https://github.com/zwq2018/Data-Copilot 汇总 # https://github.com/eosphoros-ai/Awesome-Text2SQL/\n"},{"id":95,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Tool-use/AgentToolformer/","title":"(Work)[SFT]Toolformer","section":"Tool use","content":"\n论文 # 论文地址 Toolformer: Language Models Can Teach Themselves to Use Tools\n开源地址 Implementation of Toolformer git\nToolformer[1] # 🔑关键词和摘要 Keywords: Large-scale PLMs, Tool Learning xxx 驱动语言模型去使用简单的模型来调用外部的工具 Toolformer通过语言模型的方法去决定去调用哪些API，传入哪些参数 Tooformer是在自监督层面执行的，只需要对每个API的语言描述 ⚙️研究设计和结论 方法 Toolformer调用示例：xxx 关键要素： 模型对工具的使用应该是自监督的，这样可以省去很大的标注开销 模型应该自行地去决定在何时间，用何方法来调用工具 方法概要： 受到in-context learning的启发，给定少量的人写的关于API的描述，让模型去自行生成潜在API调用的语言建模数据 构建一个自监督的Loss函数，让模型来决定哪些API的调用有助于它的语言建模的预测 方法细节： xxx 给定一个纯文本数据集，构建出一个带有API调用的数据集，然后在此数据集上做微调 第一步：使用in-context learning来生成大量的潜在可能的API调用 第二步：执行这些API，返回得到结果 第三步：检查返回的结果是否有助于语言模型的预测，过滤掉其他的API API调用采样 给每一个API来撰写提示来鼓励模型使用这些API，例如QA的提示是 xxx 对于文本的每一个位置，如果这个位置是（即API调用的开始）的概率大于一个阈值，则将此位置保留到一个集合I中 对于集合I中的每一个位置，通过模型生成最多m个API调用，并且以结尾（如果生成的调用没有以结尾，直接舍去） API执行 去执行所有的API调用，返回文本序列 API过滤 构建自监督的语言模型的loss函数 第一个的含义：进行API的调用，并且使用API结果的Loss 第二个的含义：空字符串的Loss和调用API但不返回结果Loss的最小值 这时我们希望模型使用API并且返回结果对语言建模有帮助，且帮助很明显-\u0026gt;前者的loss显著比后者小 微调和推理 在经过如上操作后，就可以得到带有API调用的数据集，然后将模型在上面进行微调 当模型在解码阶段输出\u0026quot;-\u0026gt;\u0026ldquo;符号时，意味着需要调用API了，调用得到返回结果然后拼接上去 实验 模型：GPT-J （67亿参数） 原始数据：CCNet 知识探测任务LAMA Toolformer可以大幅超过之前的方法，甚至是GPT-3等大模型 数学数据集 问答 这里即使是Toolformer也无法超越GPT-3，可见预训练规模可以囊括更多知识 模型规模的影响 模型的参数量到一定规模后才拥有使用工具的能力 📚论文贡献 优点 将语言模型使用外部工具的进行很自然的结合 不需要标注大量数据，使用自监督的方法进行学习 缺点 工具无法交互，也无法链式使用（每个API调用都是独立的） 定义的工具尚且有限，扩展工具则需要用模型标注新的数据 随着基础模型zero-shot能力的增强，这种需要构建数据并且fine-tune的做法可能会比较麻烦 OpenBMB BMTools: https://github.com/OpenBMB/BMTools 参考 # 清华博士带你搞懂大模型自学工具使用（Toolformer)【论文速读】 V 有思维导图\n1xx. 使LLM善假于物: Toolformer 1xx. Prompt Engineering 1xx. Toolformer and Tool Learning（LLMs如何使用工具） "},{"id":96,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Tool-use/AgentTool/","title":"(Work)Agent-Tools","section":"Tool use","content":"\n论文 # 论文地址 Tool Learning with Foundation Models\n开源地址 ToolLearningPapers git\n分类[1] # Tool-augmented vs. Tool-oriented [kimi 总结] # Tool-augmented Learning（工具增强学习）:\n这种学习方式指的是在基础模型（如大型预训练语言模型）的基础上，通过引入外部工具来增强模型的能力。这些工具可以是任何可以被模型通过某种接口调用的系统或服务，例如搜索引擎、数据库、API等。 工具增强学习的核心在于模型利用这些工具来获取额外的信息或执行特定的任务，从而弥补模型自身知识和能力的不足。 例如，一个语言模型可能通过调用天气API来获取最新的天气信息，或者通过搜索引擎来找到相关问题的答案。 Tool-oriented Learning（面向工具的学习）:\n面向工具的学习则更多地关注于模型如何学习和理解如何使用这些工具。这不仅仅是调用工具API那么简单，而是涉及到模型对工具的深入理解和策略性使用。 在这种学习模式下，模型可能需要学习如何组合使用多个工具，或者在复杂任务中动态调整对工具的使用策略，以实现更高效的问题解决。 例如，模型可能需要学习如何在规划一次旅行时，先后调用地图API、航班搜索API和酒店预订API，同时还要根据用户反馈和环境变化动态调整计划。 总的来说，Tool-augmented Learning 强调的是通过外部工具来扩展模型的能力，而 Tool-oriented Learning 则更侧重于模型对工具使用的学习和优化。两者都是工具学习（Tool Learning）的重要组成部分，但在实际应用中可能会有不同的实现方式和关注点。\nTool-augmented Learning # Toolformer\n{% post_link \u0026lsquo;gptAgentToolformer\u0026rsquo; %} Tool-oriented Learning # ToolMaker[10] CREATOR[11] ToolLLM [12] Visual ChatGPT[13] HuggingGPT[13] Gorilla {% post_link \u0026lsquo;gptAgentToolGorilla\u0026rsquo; %} 参考 # 大模型工具学习权威综述，BMTools 背后的论文！ 1xx. 清华发布工具学习框架，让ChatGPT操控地图、股票查询，贾维斯已来？\n1xx. 回顾大模型在工具使用上的技术总结：兼看图检索增强生成方案-GRAG 《Tool Learning with Large Language Models: A Survey》\n问题2:关于大模型使用工具的调研整理\n1xx. 一篇大模型Agent工具使用全面研究综述\n《Tool Learning with Large Language Models: A Survey》\nxxx # LLM能够自己制作工具了：详解Large Language Models as Tool Makers\nTHUNLP成员领读EMNLP大模型工具创造新框架“CREATOR” V 有思维导图\n《TOOLLLM: FACILITATING LARGE LANGUAGE MODELS TO MASTER 16000+ REAL-WORLD APIS》\nTOOLLLM：让大型语言模型掌握真实世界的API ToolBench git\n论文阅读：ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs\n{% post_link \u0026lsquo;gptAgentMultimodal\u0026rsquo; %} self\nOthers # 《Augmented Language Models》\n1xx. Augmented Language Models（增强语言模型）\n1xx. 增强语言模型（ALM）之综述篇\n"},{"id":97,"href":"/www6vAIGC/docs/FineTuning/PEFT/Lora/PEFTQLora/","title":"(原理|实战) QLoRA *","section":"Lora","content":"\n💡 QAT 4 bit NormalFloat(NF4) 量化 双量化 技术原理 [1] # 使用一种新颖的高精度技术将预训练模型量化为 4 bit，然后添加一小组可学习的低秩适配器权重，这些权重通过量化权重的反向传播梯度进行微调。\nQLoRA提出了两种技术实现高保真 4 bit微调——4 bit NormalFloat(NF4) 量化和双量化。\n4bit NormalFloat（NF4）：对于正态分布权重而言，一种信息理论上最优的新数据类型，该数据类型对正态分布数据产生比 4 bit整数和 4bit 浮点数更好的实证结果。 双量化：对第一次量化后的那些常量再进行一次量化，减少存储空间。 分页优化器: 使用此功能为优化器状态（Optimizer）分配分页内存，然后在 GPU 内存不足时将其自动卸载到 CPU 内存，并在优化器更新步骤需要时将其加载回 GPU 内存。 实验证明，无论是使用16bit、8bit还是4bit的适配器方法，都能够复制16bit全参数微调的基准性能。这说明，尽管量化过程中会存在性能损失，但通过适配器微调，完全可以恢复这些性能。\n总结 # QLoRA [189] quantizes the weights of LLMs into 4-bit and subsequently employs LoRA [224] in BF16 for each 4-bit weight matrix to fine-tune the quantized model. QLoRA allows for the efficient fine-tuning of a 65B parameter LLM on one GPU with only 30GB of memory.\n老刘 # QLoRA通过结合NF4量化（一种考虑权重分布的4位量化）、双重量化（进一步压缩量化常数）和LoRA（只训练少量适配器参数）来实现高效微调。其核心优势在于，它显著降低了存储模型权重所需的内存，并且在反向传播（梯度计算和参数更新）期间，冻结的基础模型权重保持低精度（NF4）状态，从而大幅减少了训练过程中的显存占用，使得在有限的硬件资源（如单个GPU）上微调非常大的模型成为可能。\n实战 [10] # QLoRA 微调[llama3] # 基于 4/8 比特 Bitsandbytes/HQQ/EETQ 量化进行指令监督微调[推荐]\nllamafactory-cli train examples/train_qlora/llama3_lora_sft_otfq.yaml 基于 4/8 比特 GPTQ 量化进行指令监督微调\nllamafactory-cli train examples/train_qlora/llama3_lora_sft_gptq.yaml 基于 4 比特 AWQ 量化进行指令监督微调\nllamafactory-cli train examples/train_qlora/llama3_lora_sft_awq.yaml 💡 LoRA和QLoRA 能在量化过的模型上微调\nQLoRA 微调[LLaMA-65B] [11] # 参数 # 大模型参数高效微调技术原理综述（五）-LoRA、AdaLoRA、QLoRA 1xx. [大模型微调技术] LoRA、QLoRA、QA-LoRA 原理笔记\n1xx. 大模型实操 | LoRA、QLoRA微调大模型实战技巧分享，含常见QA解答！\n实战 # LLaMA-Factory examples\n高效微调技术QLoRA实战，基于LLaMA-65B微调仅需48G显存，真香\n先是训练llama-7b, 再是训练llama-65b. qlora git\n1xx. 4bits_training\n【手把手带你实战HuggingFace Transformers-低精度训练篇】4bit量化与QLoRA模型训练 v 原理+实战\n"},{"id":98,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Memory/AgentMemory/","title":"Agent  Memory +","section":"Memory","content":"\nMemory # Memory\n"},{"id":99,"href":"/www6vAIGC/docs/FineTuning/Data/Data-Quality/Instruction-Quality/DataSFTQuality/","title":"(原理)LIMA, LESS","section":"Instruction Quality","content":"\nLIMA [1][kimi] # LIMA（Less Is More for Alignment）的实验通过一系列设计精良的步骤来探究数据质量、多样性以及数量对模型性能的影响，从而得出了提高数据质量和增加提示多样性比单纯增加数据量更能提升模型性能的结论。以下是实验方法的关键步骤：\n精心策划的微调数据：LIMA模型在1000个精心策划的提示和回复上进行了微调，这些数据被设计为模拟真实用户与AI助手的交互。\n消融实验：通过消融实验，研究者们观察了在增加数据量的同时不增加提示多样性时，模型性能的提升是否有限；而在优化数据质量时，性能是否有显著提升。\n数据构造：研究者从Stack Exchange、wikiHow和Pushshift Reddit数据集收集数据，并进行了质量和多样性的控制。这些数据集被用来构造训练样本，以确保输入的多样性和输出的一致性。\n质量与多样性的对比：研究者比较了经过质量过滤的Stack Exchange数据和同质化的wikiHow数据对模型性能的影响。结果显示，更多样化的Stack Exchange数据在性能上优于同质化的wikiHow数据。 【多样化】\n数量的对比：研究者对从Stack Exchange抽取的指数级增加的训练集进行了测试，发现训练集的翻倍并没有改善响应质量，从而说明单纯增加数据量并不一定能提升性能。【数量】\n质量控制的实验：研究者还比较了未经过任何质量或风格过滤的Stack Exchange数据集与经过过滤的数据集上训练的模型性能，发现过滤后的数据集上训练的模型性能更优。【质量】\n人类评估：为了评估LIMA模型的性能，研究者进行了人类偏好研究，将LIMA的输出与其他几个基线模型的输出进行比较，并让人群工作者选择他们更喜欢的输出。\n通过这些实验步骤，LIMA的研究得出了数据质量和提示多样性对于提升模型性能的重要性远超过单纯增加数据量的结论。这些发现支持了“浅层对齐假说”，即模型在预训练阶段已经学习到了几乎所有知识和能力，而微调过程主要是学习与人类交互的风格和格式。\n总结 [1]\n消融实验显示，当扩大数据量而不同时扩大提示多样性时，收益会大大减少，而在优化数据质量时，收益会大大增加 【数量 \u0026lt;\u0026ndash;\u0026gt; 多样性 质量】\nLESS 核心思想 [10] # 通过仅给出少数体现特定能力的示例，从大量指令数据集中有效地选择5%有影响力的数据用于目标指令微调，结果优于全量数据集进行微调，并且所选子集在不同模型参数规模和不同模型系列中仍然普遍有效。\nLESS[10][kimi] # LESS（Selecting Influential Data for Targeted Instruction Tuning）的实验方法和相应的结论如下：\n实验方法： # 热身训练（Warmup Training）：使用LoRA（Low-Rank Adaptation）技术对预训练模型进行热身训练，以适应特定的数据分布。\n梯度数据存储（Gradient Data Store）：构建了一个具有投影低维梯度特征的梯度数据存储，该存储可以重复用于不同的目标任务。\n数据选择算法：利用数据存储和算法选择与体现特定能力的少数示例最相似的训练数据点。?\n模型训练：使用选择的数据子集来训练目标模型。\n评估：在不同的下游任务上评估LESS选择的数据子集的性能，包括MMLU、TYDIQA和BBH数据集。\n结论： # LESS的有效性：LESS在不同的模型中都是有效的，能够在多个评估数据集上提高性能。\n数据子集的性能：使用LESS选择的5%的数据通常优于使用完整数据集进行训练的结果。这表明完整数据集可能包含与特定目标任务无关或有害的数据点。\n数据的可转移性：使用较小模型选择的数据可以提高较大模型和不同模型系列的性能，证明了LESS选择的数据具有高度的可转移性。\n与其他方法的比较：LESS是唯一一致有效的方法，相较于其他基线方法（如随机选择、BM25、DSIR、RDS）表现出更好的性能。\n计算成本：LESS的计算成本较高，但由于其有效性，这一成本是合理的。\n定性分析：LESS选择的数据能够体现预期下游应用所需的推理技能，而不是仅仅基于表面形式线索。\n局限性：LESS需要热身训练阶段，这增加了计算负载。此外，使用补全Token的平均梯度可能导致性能问题。还有，最小化验证损失并不总能提高任务性能，且数据选择中的线性度假设是LESS的一个限制。\n总体而言，LESS通过选择与目标任务高度相关的数据点，能够在指令微调中实现高效的性能提升，尽管存在一些局限性和计算成本。\n【总结: 少量有质量的数据 优于 全量数据 】 【数据选择算法】\n参考 # LIMA # 大模型微调究竟需要多少数据：从三个现有代表工作看几组结论及一点思考 指令格式的多样性 《LIMA: Less Is More for Alignment》 《MAYBE ONLY 0.5% DATA IS NEEDED》 1xx. 【论文笔记】LIMA: Less Is More for Alignment\nLESS # LESS：仅选择5%有影响力的数据优于全量数据集进行目标指令微调 1xx. LESS 实践：用少量的数据进行目标指令微调\n"},{"id":100,"href":"/www6vAIGC/docs/FineTuning/Data/DatasetSFTList/","title":"(List)SFT数据集","section":"Data","content":"\nSFT数据集[1][2] # 参考 # 大模型再总结及ChatSQL实践案例分享：大模型训练数据及工具的5张脑图总结及ChatSQL开源项目实现解析 1、通用指令微调数据\n开源SFT数据集整理\n"},{"id":101,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Reflection/AgentReflection/","title":"Reflection Agent *","section":"Reflection","content":"\nReAct # 论文 # 论文地址\nReAct: Synergizing Reasoning and Acting in Language Models\n开源地址\nReAct git\nProject page\nReAct: Synergizing Reasoning and Acting in Language Models\n实现[1] # import json import sys folder = \u0026#39;./prompts/\u0026#39; prompt_file = \u0026#39;prompts_naive.json\u0026#39; with open(folder + prompt_file, \u0026#39;r\u0026#39;) as f: prompt_dict = json.load(f) webthink_examples = prompt_dict[\u0026#39;webthink_simple6\u0026#39;] instruction = \u0026#34;\u0026#34;\u0026#34;Solve a question answering task with interleaving Thought, Action, Observation steps. Thought can reason about the current situation, and Action can be three types: (1) Search[entity], which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it will return some similar entities to search. (2) Lookup[keyword], which returns the next sentence containing keyword in the current passage. (3) Finish[answer], which returns the answer and finishes the task. Here are some examples. \u0026#34;\u0026#34;\u0026#34; webthink_prompt = instruction + webthink_examples Reflexion # 论文 # 论文地址 Reflexion: Language Agents with Verbal Reinforcement Learning\n开源地址 reflexion git\n如图所示，Reflexion框架包含四个组成部分：\nActor: Actor由LLM担任，主要工作是基于当前环境生成下一步的动作。 Evaluator: Evlauator主要工作是衡量Actor生成结果的质量。就像强化学习中的Reward函数对Actor的执行结果进行打分。 Self-reflexion：Self-reflexion一般由LLM担任，是Reflexion框架中最重要的部分。它能结合离散的reward信号(如success/fail)、trajectory等生成具体且详细语言反馈信号，这种反馈信号会储存在Memory中，启发下一次实验的Actor执行动作。相比reward分数，这种语言反馈信号储存更丰富的信息，例如在代码生成任务中，Reward只会告诉你任务是失败还是成功，但是Self-reflexion会告诉你哪一步错了，错误的原因是什么等。 Memory：分为短期记忆(short-term)和长期记忆(long-term)。在一次实验中的上下文称为短期记忆，多次试验中Self-reflexion的结果称为长期记忆。类比人类思考过程，在推理阶段Actor会不仅会利用短期记忆，还会结合长期记忆中存储的重要细节，这是Reflexion框架能取得效果的关键。 实现[10] # Initial responder import datetime actor_prompt_template = ChatPromptTemplate.from_messages( [ ( \u0026#34;system\u0026#34;, \u0026#34;\u0026#34;\u0026#34;You are expert researcher. Current time: {time} 1. {first_instruction} 2. Reflect and critique your answer. Be severe to maximize improvement. 3. Recommend search queries to research information and improve your answer.\u0026#34;\u0026#34;\u0026#34;, ), MessagesPlaceholder(variable_name=\u0026#34;messages\u0026#34;), ( \u0026#34;user\u0026#34;, \u0026#34;\\n\\n\u0026lt;system\u0026gt;Reflect on the user\u0026#39;s original question and the\u0026#34; \u0026#34; actions taken thus far. Respond using the {function_name} function.\u0026lt;/reminder\u0026gt;\u0026#34;, ), ] ).partial( time=lambda: datetime.datetime.now().isoformat(), ) initial_answer_chain = actor_prompt_template.partial( first_instruction=\u0026#34;Provide a detailed ~250 word answer.\u0026#34;, function_name=AnswerQuestion.__name__, ) | llm.bind_tools(tools=[AnswerQuestion]) validator = PydanticToolsParser(tools=[AnswerQuestion]) first_responder = ResponderWithRetries( runnable=initial_answer_chain, validator=validator ) Revision revise_instructions = \u0026#34;\u0026#34;\u0026#34;Revise your previous answer using the new information. - You should use the previous critique to add important information to your answer. - You MUST include numerical citations in your revised answer to ensure it can be verified. - Add a \u0026#34;References\u0026#34; section to the bottom of your answer (which does not count towards the word limit). In form of: - [1] https://example.com - [2] https://example.com - You should use the previous critique to remove superfluous information from your answer and make SURE it is not more than 250 words. \u0026#34;\u0026#34;\u0026#34; # Extend the initial answer schema to include references. # Forcing citation in the model encourages grounded responses class ReviseAnswer(AnswerQuestion): \u0026#34;\u0026#34;\u0026#34;Revise your original answer to your question. Provide an answer, reflection, cite your reflection with references, and finally add search queries to improve the answer.\u0026#34;\u0026#34;\u0026#34; references: list[str] = Field( description=\u0026#34;Citations motivating your updated answer.\u0026#34; ) revision_chain = actor_prompt_template.partial( first_instruction=revise_instructions, function_name=ReviseAnswer.__name__, ) | llm.bind_tools(tools=[ReviseAnswer]) revision_validator = PydanticToolsParser(tools=[ReviseAnswer]) revisor = ResponderWithRetries(runnable=revision_chain, validator=revision_validator) 总结 # 【ReAct 和 Reflexion 实现主要靠 prompt 工程】\n参考 # ReAct # hotpotqa.ipynb Reflexion # reflexion.ipynb git 【论文阅读】Reflexion: 大模型如何从错误经验中学习？ 1xx. Reflection Agents\nLangGraph：Reflection Agents 实战 V\n1xx. Reflexion: 带言语强化学习的语言智体\nxxx # Agent四大范式 | CRITIC：吴恩达力推Agent设计范式\nPractice # Translation Agent: Agentic translation using reflection workflow\n"},{"id":102,"href":"/www6vAIGC/docs/FineTuning/Data/Data-Quality/Instruction-Complexity/DataWizard/","title":"(原理)Wizard","section":"Instruction Complexity","content":"\nWizard 方法 # 自动指令数据进化 [1] # 1）指令进化\nIn-Depth Evolving 提示 [深度] 五种类型的提示来增强指令 增加约束 + 深化 + 具体化 + 增加推理步骤 + 复杂化输入 核心部分 In-Depth Evolving的提示的核心部分是 \u0026ldquo;你的目标是将一个给定的提示改写成更复杂的版本，使那些著名的人工智能系统（如ChatGPT和GPT4）更难处理。但改写后的提示必须是合理的，能被人理解，并能被人回应\u0026rdquo; In-Breadth Evolving提示 [广度] 目的 旨在提高主题覆盖率、技能覆盖率和整体数据集的多样性 2）响应生成\n3）消除进化 即过滤未能进化的指令\n参考 # 质量-\u0026gt; 多样性, 复杂度 # 如何构造复杂多样的微调指令数据：WizardLM复杂指令构造思想与实验分析工作总结 WizardLM git "},{"id":103,"href":"/www6vAIGC/docs/Agent/Platform/AgentList/","title":"(List)Agent 产品 平台","section":"Platform *","content":"\n应用 # 分类 [10][11][12] # Action agents\nFunction Call ReACT Simulation agents 生成式智能体， CAMEL， Generative Agents\nAutomomous Agent AutoGPT， BabyAGI, AutoGen MetaGPT ChatDev\n跨模态Agents HuggingGPT\nHuggingGPT # BabyAGI [AIGC] # Plan-and-execute agents The planning is almost always done by an LLM. The execution is usually done by a separate agent (equipped with tools).\nAutoGPT[10] # AutoGPT 的核心逻辑是一个 Prompt Loop，步骤如下\nAutoGPT 会基于一定策略自动组装 Command Prompt，这些首次会包含用户输入的 Name, Role和Goals Command Prompt 的目标不是为了拿到最终结果，而是通过 GPT Chat API(Thinking 的过程)返回下一步的 Command (包含name和arguments, 如browser_website(url = \u0026quot;www.baidu.com\u0026quot;) ) 这些 Command 都是可扩展的，每一种命令代表一种外部能力(比如爬虫、Google搜索，也包括GPT的能力)，通过这些 Command 调用返回的 Result 又会成为到 Command Prompt 的组成元素， 回到第 1 步往复循环，直到拿到最终结果结果（状态为“compelete”） Platform[20] # 字节 Coze[21,22] # 优势: 有RAG，结构化数据\n劣势: 只能发布到飞书，微信\n百度 AppBuilder # Dify # 参考 # 1xx. 「Agent」通俗易懂地聊聊AI Agent（附66个开源+44个闭源Agent项目）\n1xx. 主流Agent框架及金融Agent-FinRobot：兼看面向实体增强的细粒度实体描述知识库项目 Agent-FinRobot 基于autogen 实现\nxxx # 2023年新生代大模型Agents技术,ReAct,Self-Ask,Plan-and-execute,以及AutoGPT, HuggingGPT等应用 *** 论文+代码 公开课 公开课 Platform # AgentBuilder 中小企业如何选择：coze、dify、appbuilder、毕晟 V COZE：中小企业均可0门槛创建业务agent V 利用Coze 实现吴恩达的4种 AI Agent 设计模式 产品 \u0026amp;调研 # 1xx. 2024 年最完整的 AI Agents 清单来了，涉及 13 个领域，上百个 Agents！ 开源 闭源 ***\n1xx. 全球AI Agent大盘点，大语言模型创业一定要参考的60个AI智能体\n1xx. 大模型时代的APP\u0026ndash;2024年 AI Agent行业报告 ***\nmodelscope-agent AgentFabric # 1xx. LLM 大模型学习必知必会系列(十)：基于AgentFabric实现交互式智能体应用,Agent实战-腾讯云开发者社区-腾讯云\n1xx. modelscope-agent/apps/agentfabric at master · modelscope/modelscope-agent\n1xx. Modelscope Agent实操（一）：0代码创建、发布并分享一个专属Agent\n1xx. 从agentfabric开始体验魔搭Agent\n1xx. 社区供稿 | GLM-4适配ModelScope-Agent最佳实践\n"},{"id":104,"href":"/www6vAIGC/docs/FineTuning/Data/Task-composition/DatasetSFT/","title":"(原理)SFT 数据组合 *","section":"Task composition","content":"\n论文 # 论文地址 《HOW ABILITIES IN LARGE LANGUAGE MODELS ARE AFFECTED BY SUPERVISED FINE-TUNING DATA COM- POSITION》\nkeyword: SFT 数据组合 问题[1] # 1、推理、编码和通用能力如何随SFT数据量而变化？\n2、在SFT中结合三种能力时是否存在性能冲突？\n3、导致性能冲突的关键因素是什么？\n4、不同的SFT策略对组合数据有什么影响？\n实验结果[1] # 1、不同的能力表现出不同的扩展模式，在数据量相同的情况下，较大的模型通常表现出更优越的性能。\n2、随着数据量的持续增加，数学推理和代码生成能力也在不断提高，一般能力则是在样本数达到一千左右时才得到提升，且提升速度较慢。\n3、在数据量较低的情况下，数据组合会带来各种能力的提高，而在数据量较高的情况下，能力则会发生冲突。\n4、组成数据量会影响性能，而组成比例的影响则微乎其微。\n【模型大小】\n【数据数量】\n【数据数量 \u0026lt;\u0026ndash;\u0026gt; 多样性】？\n【组成比例】\n问题2 在SFT中结合三种能力时是否存在性能冲突？[kimi][paper] # 问题2 探讨的是在监督式微调（Supervised Fine-Tuning, SFT）中结合推理、编码和通用能力时是否存在性能冲突。\n结论： # 性能冲突的存在：在高资源设置下，即当SFT数据集混合使用时，不同能力领域（如数学推理、编码和通用对齐能力）之间会发生性能冲突。然而，在低资源设置下，混合数据源能够提升性能。 性能冲突与资源量的关系：随着数据量的增加，特定任务的性能可能会因为其他任务的存在而下降。这表明在数据量较大时，不同任务之间可能会相互干扰，导致性能冲突。 模型大小对性能的影响：随着模型大小的增加，在低资源设置下，数学和通用能力的性能提升更加明显。 问题3 导致性能冲突的关键因素是什么？[kimi][paper] # 在SFT（监督式微调）中结合推理、编码和通用能力时，导致性能冲突的关键因素包括：\n数据组成和比例：当不同能力领域的数据混合在一起进行SFT时，如果数据量充足，来自其他领域的数据可能会被视为噪声，从而影响特定领域的性能。 模型大小：较大的模型在相同数据量下通常表现更好，并且在低资源设置下对于数学和通用能力的性能增益更大。 训练策略：多任务学习虽然能够保留专业能力，但对通用能力的伤害最大；而顺序训练和混合顺序训练虽然保留了通用能力，但会丢失太多的专业能力。 数据量与能力的关系：数学推理和编码能力随着数据量的增加而持续提高，而通用能力在大约一千个样本后趋于平稳。 任务特性差异：推理和编码任务需要复杂的逻辑来分解任务指令和处理非语言和符号特征，而对齐人类意图则需要多样性和理解模糊的人类指令。 相应的结论包括：\n在低资源设置下，混合数据源可以提高性能，但在高资源设置下，可能会导致性能下降。 数据量直接影响力能表现，而数据比例的影响不显著。 提出的双阶段混合微调（DMT）策略有效地减轻了多任务学习中的性能冲突和顺序训练中的灾难性遗忘，实现了通用与专业能力之间的平衡。 这些结论强调了在SFT阶段理解和解决数据组成问题对于全面提高LLMs（大型语言模型）的能力至关重要。\n参考 # SFT微调的数据组合及训练策略如何影响大模型性能：4个经典问题及实验结论分享 1xx. 再看大模型微调与应用：3大行业18个开源垂直微调模型、微调数据、工具资源及有趣的AIGC应用集合 二 三\n1xx. 也谈大模型研发中的微调数据规模评估与质量问题：数据规模大小的影响评估、数据主要问题及清洗项目\n1xx. 也谈微调数据质量、多样性规模对大模型性能的影响与评估方案：Belle项目开源实验工作报告介绍\n"},{"id":105,"href":"/www6vAIGC/docs/FineTuning/PEFT/Lora/PEFTLora/","title":"(实战) Lora +","section":"Lora","content":"\nLora 实战 # (实战) Lora "}]