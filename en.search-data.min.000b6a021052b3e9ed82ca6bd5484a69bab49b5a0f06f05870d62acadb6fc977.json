[{"id":0,"href":"/www6vAIGC/docs/Agent/Communication/MCPSurvey/","title":"(ç»¼è¿°)MCP +","section":"Communication *","content":"\nMCP ç»¼è¿° # (ç»¼è¿°)MCP\n"},{"id":1,"href":"/www6vAIGC/docs/Prompt-Engineering/Prompting101/","title":"(åŸç†) è°·æ­Œ Prompting guide 101 *","section":"Prompt Engineering","content":" å››ä¸ªæ ¸å¿ƒè¦ç´  # 1. Personaï¼ˆè§’è‰²ï¼‰ # å®šä¹‰ï¼šä½¿ç”¨è€…èº«ä»½/èŒä¸šå®šä½ï¼Œå†³å®šAIçš„å›åº”è§†è§’\nå…³é”®ä½œç”¨ï¼š\nå¸®åŠ©AIç†è§£ç”¨æˆ·çš„ä¸“ä¸šèƒŒæ™¯å’Œéœ€æ±‚å±‚æ¬¡ ä½¿è¾“å‡ºå†…å®¹æ›´ç¬¦åˆç‰¹å®šè§’è‰²çš„æ€ç»´æ–¹å¼å’Œè¡¨è¾¾ä¹ æƒ¯ åº”ç”¨ç¤ºä¾‹ï¼š\nè¡Œæ”¿æ”¯æŒï¼š\u0026ldquo;You are a program manager in [industry]\u0026quot;ï¼ˆé¡¹ç›®ç®¡ç†è€…èº«ä»½ï¼‰ å¸‚åœºè¥é”€ï¼š\u0026ldquo;I am a PR manager at [company name]\u0026quot;ï¼ˆå…¬å…³ç»ç†èº«ä»½ï¼‰ æŠ€æœ¯å²—ä½ï¼š\u0026ldquo;As the CIO at [company]\u0026quot;ï¼ˆé¦–å¸­ä¿¡æ¯å®˜èº«ä»½ï¼‰ æœ€ä½³å®è·µï¼š\nä½¿ç”¨æ˜ç¡®èŒç§°ï¼ˆå¦‚\u0026quot;executive assistant\u0026rdquo;ï¼‰ è¡¥å……è¡Œä¸šå±æ€§ï¼ˆå¦‚\u0026quot;in the personal care industry\u0026rdquo;ï¼‰ éœ€ä¿æŒè§’è‰²ä¸€è‡´æ€§ï¼ˆåŒä¸€ä¼šè¯ä¸­ä¸å®œåˆ‡æ¢è§’è‰²ï¼‰ 2. Taskï¼ˆä»»åŠ¡ï¼‰ # å®šä¹‰ï¼šéœ€è¦AIå®Œæˆçš„å…·ä½“å·¥ä½œæŒ‡ä»¤\nå…³é”®ä½œç”¨ï¼š\næ˜ç¡®æ“ä½œç±»å‹ï¼ˆç”Ÿæˆ/æ€»ç»“/åˆ†æ/ä¼˜åŒ–ç­‰ï¼‰ ç•Œå®šè¾“å‡ºå†…å®¹çš„èŒƒå›´ä¸æ·±åº¦ åº”ç”¨ç¤ºä¾‹ï¼š\nå†…å®¹ç”Ÿæˆï¼š\u0026ldquo;Draft an executive summary email\u0026rdquo;ï¼ˆèµ·è‰é‚®ä»¶ï¼‰ æ•°æ®åˆ†æï¼š\u0026ldquo;Identify trends in customer feedback\u0026rdquo;ï¼ˆè¶‹åŠ¿åˆ†æï¼‰ æµç¨‹ä¼˜åŒ–ï¼š\u0026ldquo;Create a budget tracker for business travel\u0026rdquo;ï¼ˆåˆ›å»ºæ¨¡æ¿ï¼‰ æœ€ä½³å®è·µï¼š\nå¿…é¡»åŒ…å«åŠ¨è¯ï¼ˆå¦‚generate/summarize/analyzeï¼‰ æ˜ç¡®æ“ä½œå¯¹è±¡ï¼ˆé‚®ä»¶/è¡¨æ ¼/æŠ¥å‘Šç­‰ï¼‰ åˆ†å±‚é€’è¿›ï¼ˆä¸»ä»»åŠ¡â†’å­ä»»åŠ¡ï¼‰ 3. Contextï¼ˆä¸Šä¸‹æ–‡ï¼‰ # å®šä¹‰ï¼šä»»åŠ¡ç›¸å…³çš„èƒŒæ™¯ä¿¡æ¯ä¸çº¦æŸæ¡ä»¶\nå…³é”®ä½œç”¨ï¼š\næä¾›å¿…è¦çš„ä¸šåŠ¡åœºæ™¯ä¿¡æ¯ ç¡®ä¿è¾“å‡ºå†…å®¹çš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§ åº”ç”¨ç¤ºä¾‹ï¼š\nè¡Œä¸šèƒŒæ™¯ï¼š\u0026ldquo;newly formed team of content marketers\u0026rdquo;ï¼ˆå›¢é˜Ÿæ„æˆï¼‰ æ•°æ®æ¥æºï¼š\u0026ldquo;based on @[Product Launch Notes]\u0026quot;ï¼ˆå¼•ç”¨æ–‡ä»¶ï¼‰ é™åˆ¶æ¡ä»¶ï¼š\u0026ldquo;within 10-minute walk of the hotel\u0026rdquo;ï¼ˆåœ°ç†é™åˆ¶ï¼‰ æœ€ä½³å®è·µï¼š\nä½¿ç”¨å ä½ç¬¦åŠ¨æ€å¼•ç”¨ï¼ˆ[industry]/[date]ç­‰ï¼‰ å…³è”Workspaceæ–‡ä»¶ï¼ˆ@fileè¯­æ³•è°ƒç”¨äº‘ç«¯æ–‡æ¡£ï¼‰ è¯´æ˜ç‰¹æ®Šè¦æ±‚ï¼ˆå¦‚åˆè§„/éšç§é™åˆ¶ï¼‰ 4. Formatï¼ˆæ ¼å¼ï¼‰ # å®šä¹‰ï¼šæœŸæœ›çš„è¾“å‡ºç»“æ„ä¸å‘ˆç°æ–¹å¼\nå…³é”®ä½œç”¨ï¼š\nè§„èŒƒå†…å®¹ç»„ç»‡é€»è¾‘ æé«˜ä¿¡æ¯å¯è¯»æ€§å’Œå®ç”¨æ€§ åº”ç”¨ç¤ºä¾‹ï¼š\nç»“æ„åŒ–æ•°æ®ï¼š\u0026ldquo;Put it in a table format\u0026rdquo;ï¼ˆè¡¨æ ¼æ ¼å¼ï¼‰ è§†è§‰å‘ˆç°ï¼š\u0026ldquo;Create an image of a trade show booth\u0026rdquo;ï¼ˆå›¾åƒç”Ÿæˆï¼‰ æ–‡æœ¬è§„èŒƒï¼š\u0026ldquo;Limit to bullet points\u0026rdquo;ï¼ˆè¦ç‚¹åˆ—è¡¨ï¼‰ æœ€ä½³å®è·µï¼š\næ˜ç¡®æ ¼å¼ç±»å‹ï¼ˆé‚®ä»¶/æŠ¥å‘Š/å›¾è¡¨ç­‰ï¼‰ æŒ‡å®šå†…å®¹å±‚çº§ï¼ˆæ ‡é¢˜/æ®µè½/é¡¹ç›®ç¬¦å·ï¼‰ è®¾ç½®é‡åŒ–æŒ‡æ ‡ï¼ˆå¦‚\u0026quot;3 different icebreaker activities\u0026rdquo;ï¼‰ ç»¼åˆåº”ç”¨æ¡ˆä¾‹ # åœºæ™¯ï¼šè¡Œæ”¿åŠ©ç†åˆ¶å®šå·®æ—…è¡Œç¨‹\næç¤ºè¯ç»“æ„ï¼š\n\u0026quot;I am an executive assistant. Create a 2-day business trip itinerary in [location] during [dates]. Include breakfast/dinner options within 10-minute walk of [hotel], and one entertainment option. Put it in a table.\u0026quot;\nè¦ç´ æ‹†è§£ï¼š\nPersonaï¼šExecutive assistantï¼ˆè§’è‰²å®šä½ï¼‰ Taskï¼šCreate itineraryï¼ˆæ ¸å¿ƒä»»åŠ¡ï¼‰ Contextï¼šBusiness trip + location/time constraintsï¼ˆåœºæ™¯é™åˆ¶ï¼‰ Formatï¼šTable with specified columnsï¼ˆè¡¨æ ¼å‘ˆç°ï¼‰ ä¼˜åŒ–å»ºè®® # è¿­ä»£ä¼˜åŒ–ï¼šé€šè¿‡\u0026quot;Make this a power prompt\u0026quot;æŒ‡ä»¤è®©AIä¼˜åŒ–åŸå§‹æç¤º åŠ¨æ€å¼•ç”¨ï¼šä½¿ç”¨@fileè¯­æ³•è°ƒç”¨äº‘ç«¯æ–‡æ¡£å¢å¼ºä¸Šä¸‹æ–‡å…³è”æ€§ åˆ†å±‚æç¤ºï¼šå¤æ‚ä»»åŠ¡åˆ†è§£ä¸º\u0026quot;ä¸»æç¤ºâ†’ç»†åŒ–æç¤ºâ†’æ ¼å¼è°ƒæ•´\u0026quot;å¤šè½®å¯¹è¯ è¯­æ°”æ§åˆ¶ï¼šé€šè¿‡\u0026quot;formal/casual/upbeat\u0026quot;ç­‰å½¢å®¹è¯è°ƒæ•´è¾“å‡ºè¯­è°ƒ æ–‡æ¡£å¼ºè°ƒï¼Œæœ‰æ•ˆæç¤ºçš„å¹³å‡é•¿åº¦çº¦21è¯ï¼ˆå«å…³é”®ä¸Šä¸‹æ–‡ï¼‰ï¼Œè€Œç”¨æˆ·åˆå§‹å°è¯•å¾€å¾€ä¸è¶³9è¯ï¼Œå»ºè®®é€šè¿‡è¿™å››ä¸ªè¦ç´ çš„ç³»ç»Ÿåº”ç”¨æå‡æç¤ºè´¨é‡ã€‚\nå‚è€ƒ # Prompting Guide 101 æ›´åå‘å„è¡Œå„ä¸šçš„æç¤ºæ¡ˆä¾‹å’Œå®è·µï¼Œ å›´ç»• Personaï¼ˆè§’è‰²ï¼‰ã€Taskï¼ˆä»»åŠ¡ï¼‰ã€Contextï¼ˆä¸Šä¸‹æ–‡ï¼‰ã€Formatï¼ˆæ ¼å¼ï¼‰å››è¦ç´ å±•å¼€ï¼š ã€è…¾è®¯å…ƒå® ç”Ÿæˆ æ ¹æ®æ–‡æ¡£å†…å®¹ï¼Œå›´ç»•\u0026quot;Personaï¼ˆè§’è‰²ï¼‰ã€Taskï¼ˆä»»åŠ¡ï¼‰ã€Contextï¼ˆä¸Šä¸‹æ–‡ï¼‰ã€Formatï¼ˆæ ¼å¼ï¼‰\u0026ldquo;å››ä¸ªæ ¸å¿ƒè¦ç´ çš„è§£æå¦‚ä¸‹ï¼šã€‘\n"},{"id":2,"href":"/www6vAIGC/docs/Agent/Platform/Dify/","title":"(å®ç°)Dify *","section":"Platform *","content":" Dify # ä»é›¶å¼€å§‹å­¦ Dify-ç³»ç»Ÿæ¶æ„\nä»é›¶å¼€å§‹å­¦ Dify- å·¥ä½œæµ(Workflow)ç³»ç»Ÿæ¶æ„\nä»é›¶å¼€å§‹å­¦ Dify - ä¸€æ–‡ææ‡‚ Dify æ¶ˆæ¯é˜Ÿåˆ—ä¸ä»»åŠ¡è°ƒåº¦çš„è®¾è®¡ç²¾é«“\n"},{"id":3,"href":"/www6vAIGC/docs/Deep-Research/%E5%AE%9E%E7%8E%B0/DeepResearch/","title":"(åŸç†\u0026å®æˆ˜)Deep Research","section":"å®ç°","content":"\nDeep Research # (åŸç†\u0026amp;å®æˆ˜)Deep Research\n"},{"id":4,"href":"/www6vAIGC/docs/FineTuning/%E5%AE%9E%E8%B7%B5/FineTuningBestPractice/","title":"(æœ€ä½³å®è·µ)SFT  +","section":"å®è·µ *","content":"\nSFT BestPractice # SFT BestPractice\n"},{"id":5,"href":"/www6vAIGC/docs/RAG/Pattern/RAGPattern/","title":"(åŸç†) RAG Pattern *","section":"Pattern","content":"\n7 ç§ RAG æ¨¡å¼ # Naive RAG æ˜¯æœ€åŸºç¡€çš„æ¶æ„ï¼ŒåŒ…å«ç®€å•çš„æ–‡æ¡£æ£€ç´¢ã€å¤„ç†å’Œç”Ÿæˆå“åº”çš„æµç¨‹ Retrieve-and-rerank åœ¨åŸºç¡€ RAG ä¸Šå¢åŠ äº†é‡æ’åºæ­¥éª¤ï¼Œå¯ä»¥ä¼˜åŒ–æ£€ç´¢ç»“æœçš„ç›¸å…³æ€§ Multimodal RAG èƒ½å¤Ÿå¤„ç†å›¾åƒç­‰å¤šç§ç±»å‹çš„æ•°æ®ï¼Œä¸ä»…é™äºæ–‡æœ¬ Graph RAG åˆ©ç”¨å›¾æ•°æ®åº“å¢å¼ºçŸ¥è¯†è¿æ¥ï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£æ–‡æ¡£é—´çš„å…³ç³» Hybrid RAG ç»“åˆäº†å¤šç§æŠ€æœ¯çš„ä¼˜åŠ¿ï¼ŒåŒ…å«å›¾ç»“æ„å’Œä¼ ç»Ÿæ£€ç´¢æ–¹æ³• Agentic RAG Router ä½¿ç”¨ AI Agent æ¥è·¯ç”±å’Œå¤„ç†æŸ¥è¯¢ï¼Œå¯ä»¥é€‰æ‹©æœ€é€‚åˆçš„å¤„ç†è·¯å¾„ Agentic RAG Multi-Agent ä½¿ç”¨å¤šä¸ªä¸“é—¨çš„ AI Agent ååŒå·¥ä½œï¼Œå¯ä»¥è°ƒç”¨ä¸åŒçš„å·¥å…·ï¼ˆå¦‚å‘é‡æœç´¢ã€ç½‘é¡µæœç´¢ã€Slackã€Gmail ç­‰ï¼‰ æ ¸å¿ƒç»„ä»¶ # åµŒå…¥æ¨¡å‹ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡è¡¨ç¤º ç”Ÿæˆæ¨¡å‹ï¼šè´Ÿè´£æœ€ç»ˆçš„å†…å®¹ç”Ÿæˆ é‡æ’åºæ¨¡å‹ï¼šä¼˜åŒ–æ£€ç´¢ç»“æœçš„ç›¸å…³æ€§ å‘é‡æ•°æ®åº“ï¼šå­˜å‚¨å’Œæ£€ç´¢å‘é‡åŒ–çš„å†…å®¹ æç¤ºæ¨¡æ¿ï¼šè§„èŒƒåŒ–çš„æŸ¥è¯¢å¤„ç†æ¨¡æ¿ AI Agentï¼šæ™ºèƒ½å†³ç­–å’Œä»»åŠ¡åè°ƒ å‚è€ƒ # RAG æ¶æ„å›¾è§£ï¼šä»åŸºç¡€åˆ°é«˜çº§çš„7ç§æ¨¡å¼\nRAG æ¶æ„å›¾è§£ï¼šä»åŸºç¡€åˆ°é«˜çº§çš„7ç§æ¨¡å¼ x\n"},{"id":6,"href":"/www6vAIGC/docs/RAG/Pattern/KG-RAG/graphRAG/","title":"GraphRAG +","section":"KG-RAG","content":"\nGraphRAG # GraphRAG\n"},{"id":7,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/RAGBestPractice/","title":"(Work)RAG æœ€ä½³å®è·µ +","section":"å®æˆ˜ *","content":" æœ€ä½³å®è·µ # Best Practices\n"},{"id":8,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/RAG-ant/","title":"(èš‚èš)RAG","section":"å®æˆ˜ *","content":" Arch # æœ€é‡è¦ â†’ æ–‡æ¡£é¢„å¤„ç† ç¦»çº¿çŸ¥è¯†åŠ å·¥ pipeline # ã€pipelineã€‘\nçŸ¥è¯†æŠ½å–ä¸ç”Ÿæˆ # ã€ chunk - markdown çš„chunkã€‘\nã€è¦ç´  æ ‡ç­¾ã€‘\nã€markdown - chunking å™¨\nå±‚çº§çŸ¥è¯†ä¿ç•™ï¼Œ chunkå®Œåæ˜¯å¼ å›¾ã€‘\nqueryç†è§£ # ã€æ¨ç†æ¨¡å‹ - å¤§ç¯‡å¹…çš„æ„å›¾ç†è§£ ã€‘\nå‚è€ƒ # èš‚èšæ•°ç§‘ AI AgentçŸ¥è¯†å·¥ç¨‹å®è·µ datafun "},{"id":9,"href":"/www6vAIGC/docs/RAG/Pattern/Agentic-RAG/AgenticRAG/","title":"(åŸç†|å®æˆ˜)Agentic RAG +","section":"Agentic RAG","content":"\nAgentic RAG # (åŸç†|å®æˆ˜)Agentic RAG\n"},{"id":10,"href":"/www6vAIGC/docs/RAG/phase/phaseRAGIndex/RAGIndex/","title":"(åŸç†) Index +","section":"(Phase)index","content":"\nIndex # (åŸç†) Index\n"},{"id":11,"href":"/www6vAIGC/docs/RAG/phase/phaseRAGIndex/RAGChunk/","title":"(åŸç†|å®æˆ˜) Chunk +","section":"(Phase)index","content":"\nChunk # (åŸç†|å®æˆ˜) Chunk\n"},{"id":12,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Planning/AgentPlanning/","title":"Agent Planning","section":"Planning","content":"\nTypes[1] # ä»»åŠ¡åˆ†è§£\nå¤šè®¡åˆ’é€‰æ‹©\nå¤–éƒ¨è§„åˆ’å™¨è¾…åŠ©è§„åˆ’\nåæ€å’Œæç‚¼[20]\nè®°å¿†å¢å¼ºè§„åˆ’\nä»»åŠ¡åˆ†è§£ # ReACT èŒƒå¼ [2] æŠŠèåˆäº†Reasoningå’ŒActingçš„ä¸€ç§èŒƒå¼ï¼Œæ¨ç†è¿‡ç¨‹æ˜¯æµ…æ˜¾æ˜“æ‡‚ï¼Œä»…ä»…åŒ…å«thought-action-observationæ­¥éª¤ï¼Œå¾ˆå®¹æ˜“åˆ¤æ–­æ¨ç†çš„è¿‡ç¨‹çš„æ­£ç¡®æ€§ï¼Œä½¿ç”¨ReActåšå†³ç­–ç”šè‡³è¶…è¿‡äº†å¼ºåŒ–å­¦ä¹ .\nchain-of-thoughtæ¨ç†-é—®é¢˜ äº‹å®å¹»æƒ³ï¼ˆfact hallucinationï¼‰å’Œé”™è¯¯ä¼ é€’ï¼ˆerror propagationï¼‰ Plan-and-execute agents [2] æœ¬è´¨ä¸Šæ˜¯å…ˆè®¡åˆ’å†æ‰§è¡Œï¼Œå³å…ˆæŠŠç”¨æˆ·çš„é—®é¢˜åˆ†è§£æˆä¸€ä¸ªä¸ªçš„å­ä»»åŠ¡ï¼Œç„¶åå†æ‰§è¡Œå„ä¸ªå­ä»»åŠ¡ï¼Œæœ€ååˆå¹¶è¾“å‡ºå¾—åˆ°ç»“æœ\nPatterns # Self-ask [2] Self-askæ˜¯ä¸€ç§follow-upçš„ä½¿ç”¨èŒƒå¼ï¼Œä»…ä»…åŒ…å«follow-up, immediate answeræ­¥éª¤ï¼Œè‡³äºfollow-upå¤šå°‘ä¸ªstepï¼Œå®Œå…¨ç”±å®ƒè‡ªå·±å†³å®šï¼Œä¼°è®¡è¿™å°±æ˜¯Self-askçš„åå­—çš„ç”±æ¥ã€‚ å‚è€ƒ # ã€ŠUnderstanding the planning of LLM agents: A surveyã€‹\nå¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“è§„åˆ’èƒ½åŠ›ç»¼è¿°: åˆ†ç±»ã€ä»»åŠ¡åˆ†è§£ã€é€‰æ‹©ã€åæ€ã€è®°å¿†å¢å¼º ç¿»è¯‘\nAgentå››å¤§èŒƒå¼ | ç»¼è¿°ï¼šå…¨é¢ç†è§£Agentå·¥ä½œåŸç†\n2023å¹´æ–°ç”Ÿä»£å¤§æ¨¡å‹AgentsæŠ€æœ¯,ReAct,Self-Ask,Plan-and-execute,ä»¥åŠAutoGPT, HuggingGPTç­‰åº”ç”¨ *** è®ºæ–‡+ä»£ç \n{% post_link \u0026lsquo;gptAgentReflection\u0026rsquo; %} self\n1xx. AI Agentè§„åˆ’èƒ½åŠ›å…¨é¢æ‹†è§£\n1xx. å¼•é¢†è¯­è¨€æ™ºèƒ½ï¼šä»æ€ç»´é“¾æ¨ç†åˆ°è¯­è¨€æ™ºèƒ½ä½“çš„æ¢ç´¢æŒ‡å— [è¯‘] paper\n1xx. 2023å¹´å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“è§„åˆ’æŠ€æœ¯(LLM Agent Planning)ç ”ç©¶è¿›å±•æ±‡æ€»\n"},{"id":13,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/framework/RAGFramework/","title":"RAG Framework","section":"framework","content":"\næ¡†æ¶ [0] # ragflow\nQAnything\nlangchainchat\nFastGPT\nLangChain\nLlamaIndex\nlangchain4j\nGPT-RAG\nUnstructured\nQuivr\nDify\nVerba\ndanswer\nå‚è€ƒ # å¤§æ¨¡å‹RAGé—®ç­”ç ”å‘çœŸå®å›¾é‰´ï¼šä¸€å‘¨å‡ºDemoï¼ŒåŠå¹´ç”¨ä¸å¥½ï¼Œç¼è¡¥ä¹‹è·¯æ¼«æ¼« 1xx. å¤§æ¨¡å‹RAGé—®ç­”å¼€æºæ¡†æ¶çš„ä¸¤ä¸ªé£å‘:å…¼çœ‹å¤§æ¨¡å‹å®‰å…¨çš„å­¦æœ¯è¯„æµ‹ RAGFlow - å¼•å…¥æ–‡æ¡£ç†è§£åŠæº¯æºæœºåˆ¶ QAnything - ä¼˜åŒ–embeddding+å¬å›ä¾§æ–¹å‘çš„\n1xx. LlamaHub\nMix and match our Data Loaders and Agent Tools to build custom RAG apps or use our LlamaPacks as a starting point for your retrieval use cases.\n1xx. FlashRAGï¼šå¯èƒ½æ˜¯æœ€å…¨çš„ã€æœ€å¿«æ­å»ºRAGçš„å¼€æºæ¡†æ¶ "},{"id":14,"href":"/www6vAIGC/docs/RAG/phase/phaseRAGPreRetrieval/QueryRewrite/","title":"(åŸç†|å®æˆ˜)Query Rewrite","section":"(Phase)pre-retrival","content":"\nQuery rewrite # query rewrite [1][2] # è®ºæ–‡ä½¿ç”¨LLMé‡å†™ç”¨æˆ·æŸ¥è¯¢ï¼Œè€Œä¸æ˜¯ç›´æ¥ä½¿ç”¨åŸå§‹ç”¨æˆ·æŸ¥è¯¢è¿›è¡Œæ£€ç´¢ã€‚ å› ä¸ºå¯¹äºLLM è€Œè¨€ï¼ŒåŸå§‹æŸ¥è¯¢ä¸å¯èƒ½æ€»æ˜¯æœ€ä½³æ£€ç´¢ç»“æœï¼Œå¯ä»¥è®©LLMé‡å†™æŸ¥è¯¢ã€‚ Repo git ã€é—®é¢˜çš„å¤šæ ·åŒ–ã€‘ Transformation-å¤šæ ·æ€§ # Step Back # Step Backé—®ç­”å›é€€ç­–ç•¥ [3] # Step Backé—®ç­”å›é€€ï¼Œé¦–å…ˆæç¤ºLLMæå‡ºä¸€ä¸ªå…³äºé«˜çº§æ¦‚å¿µæˆ–åŸåˆ™çš„é€šç”¨åé€€é—®é¢˜ï¼Œå¹¶æ£€ç´¢æœ‰å…³å®ƒä»¬çš„ç›¸å…³äº‹å®ï¼Œä½¿ç”¨æ­¤åŸºç¡€æ¥å¸®åŠ©å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\nStep-back Prompting [1][2] # è®ºæ–‡ä½¿ç”¨é€€ä¸€æ­¥æç¤ºï¼Œä½¿ç”¨LLMç”Ÿæˆ\u0026quot;åé€€\u0026quot;(Step back prompting)é—®é¢˜ã€‚ ä½¿ç”¨æ£€ç´¢æ—¶ï¼Œ\u0026ldquo;åé€€\u0026quot;é—®é¢˜å’ŒåŸå§‹é—®é¢˜éƒ½ä¼šè¢«ç”¨æ¥è¿›è¡Œæ£€ç´¢ï¼Œç„¶åè¿™ä¸¤ä¸ªç»“æœéƒ½ä¼šè¢«ç”¨æ¥ä½œä¸ºè¯­è¨€æ¨¡å‹å›å¤çš„åŸºç¡€ã€‚ Repo git ã€é—®é¢˜çš„æŠ½è±¡åŒ–ã€‘ Transformation-æŠ½è±¡åŒ– # HyDE # HyDEæ··åˆç­–ç•¥[3] # LLMå°†é—®é¢˜è½¬æ¢ä¸ºå›ç­”é—®é¢˜çš„å‡è®¾æ–‡æ¡£ã€‚ä½¿ç”¨åµŒå…¥çš„å‡è®¾æ–‡æ¡£æ£€ç´¢çœŸå®æ–‡æ¡£ï¼Œå‰ææ˜¯doc-docç›¸ä¼¼æ€§æœç´¢å¯ä»¥äº§ç”Ÿæ›´å¤šç›¸å…³åŒ¹é…ã€‚\nHyDE At a high level, HyDE is an embedding technique that takes queries, generates a hypothetical answer, and then embeds that generated document and uses that as the final example. Transformation-å…·ä½“åŒ– # å‚è€ƒ # çŸ¥è¯†å›¾è°±ç”¨äºç»†ç²’åº¦å¤§æ¨¡å‹å¹»è§‰è¯„ä¼°ï¼šå…¼è®ºLangchain-RAGé—®ç­”ä¸­çš„é—®é¢˜æ”¹å†™èŒƒå¼ RAG: rewrite , Step back, fusion\nQuery Transformations\nä¸€æ–‡è¯¦çœ‹Langchainæ¡†æ¶ä¸­çš„RAGå¤šé˜¶æ®µä¼˜åŒ–ç­–ç•¥ï¼šä»é—®é¢˜è½¬æ¢åˆ°æŸ¥è¯¢è·¯ç”±å†åˆ°ç”Ÿæˆä¼˜åŒ– *** åŸç†paperï¼Œä»£ç ç¤ºä¾‹\nMulti Queryå¤šæŸ¥è¯¢ç­–ç•¥ï¼Œ Decompositioné—®é¢˜ï¼ŒRAG-Fusionï¼Œ Step Backï¼Œ HyDEæ··åˆ\nrag-from-scratch Repo git\nRAG(æ£€ç´¢å¢å¼ºï¼‰ ä»å…¥é—¨åˆ°ç²¾é€š è™šæ‹Ÿæ–‡æ¡£åµŒå…¥ï¼ˆHyde) V\n1xx. ä¸šç•Œæ€»ç»“ï½œæœç´¢ä¸­çš„Queryç†è§£ ***\n1xx. æ™ºèƒ½æ‰©å……æœºå™¨äººçš„â€œæ ‡å‡†é—®â€åº“ä¹‹Queryç”Ÿæˆ\nLLMä¹‹RAGå®æˆ˜ï¼ˆäºŒåå…«ï¼‰| æ¢ç´¢RAG queryé‡å†™\né«˜çº§RAGæ£€ç´¢ä¸­çš„äº”ç§æŸ¥è¯¢é‡å†™ç­–ç•¥\n"},{"id":15,"href":"/www6vAIGC/docs/RAG/phase/phaseRAGPreRetrieval/QueryTransformation/","title":"(åŸç†|å®æˆ˜)Query Transformation","section":"(Phase)pre-retrival","content":"\nQuery Transformation # Multi Queryå¤šæŸ¥è¯¢ç­–ç•¥[3] # è¯¥æ–¹æ³•ä»å¤šä¸ªè§’åº¦é‡å†™ç”¨æˆ·é—®é¢˜ï¼Œä¸ºæ¯ä¸ªé‡å†™çš„é—®é¢˜æ£€ç´¢æ–‡æ¡£ï¼Œè¿”å›æ‰€æœ‰æŸ¥è¯¢çš„å”¯ä¸€æ–‡æ¡£ã€‚\nDecompositioné—®é¢˜åˆ†è§£ç­–ç•¥[3] # Answer recursivelyè¿­ä»£å¼å›ç­” åœ¨é—®é¢˜åˆ†è§£çš„åŸºç¡€ä¸Šï¼Œé€æ­¥è¿­ä»£å‡ºç­”æ¡ˆï¼Œå°†ä¸Šä¸€æ­¥é—®é¢˜çš„ç­”æ¡ˆï¼Œä¸ä¸‹ä¸€æ­¥éª¤çš„ç­”æ¡ˆè¿›è¡Œæ‹¼æ¥ï¼Œé€å…¥å¤§æ¨¡å‹è¿›è¡Œé—®ç­”\nAnswer individually ä¹Ÿå¯ä»¥è®©æ¯ä¸ªsubqueryåˆ†åˆ«è¿›è¡Œå¤„ç†ï¼Œç„¶åå¾—åˆ°ç­”æ¡ˆï¼Œç„¶åå†æ‹¼æ¥æˆä¸€ä¸ªQA pairsppromptæœ€ç»ˆå½¢æˆç­”æ¡ˆã€‚\nå‚è€ƒ # xxx\nxxx\nä¸€æ–‡è¯¦çœ‹Langchainæ¡†æ¶ä¸­çš„RAGå¤šé˜¶æ®µä¼˜åŒ–ç­–ç•¥ï¼šä»é—®é¢˜è½¬æ¢åˆ°æŸ¥è¯¢è·¯ç”±å†åˆ°ç”Ÿæˆä¼˜åŒ– *** åŸç†paperï¼Œä»£ç ç¤ºä¾‹\n[Multi Queryå¤šæŸ¥è¯¢ç­–ç•¥ï¼Œ Decompositioné—®é¢˜]ï¼Œ RAG-Fusionï¼Œ Step Backï¼Œ HyDEæ··åˆ\nrag-from-scratch Repo git\n"},{"id":16,"href":"/www6vAIGC/docs/RAG/Pattern/Multimodal-RAG/RAGMultimodal/","title":"(Survey)å¤šæ¨¡æ€ RAG +","section":"Multimodal RAG","content":"\nå¤šæ¨¡æ€ RAG # (Survey)å¤šæ¨¡æ€ RAG\n"},{"id":17,"href":"/www6vAIGC/docs/FineTuning/Data/Data-Quality/Instruction-Diversity/SelfInstruct/","title":"(åŸç†)SELF-INSTRUCT+","section":"Instruction Diversity","content":"\nSELF-INSTRUCT # (åŸç†)SELF-INSTRUCT\n"},{"id":18,"href":"/www6vAIGC/docs/Agent/Multi-agent/MultiAgents/","title":"(åŸç†)Multi-Agents +","section":"Multi-agent *","content":"\nMulti-Agents åŸç† # (åŸç†)Multi-Agents\n"},{"id":19,"href":"/www6vAIGC/docs/FineTuning/Instruct-Tuning/InstructTuning/","title":"(åŸç†)Instruct Tuning","section":"Instruct Tuning","content":"\nIn Context Learning ( ICL ) ä¸Šä¸‹æ–‡å­¦ä¹  # in context learningï¼Œå¤§æ„æ˜¯åœ¨prompt learningçš„åŸºç¡€ä¸Šï¼Œå°†å°‘é‡æœ‰æ ‡ç­¾æ ·æœ¬èå…¥promptã€‚ ä¸Šå›¾çš„ICLæ¨¡å‹å¯ä»¥ç†è§£æˆæœ‰ç›‘ç£ã€æ— è®­ç»ƒçš„å°æ ·æœ¬å­¦ä¹ ã€‚ ä½†å¹¶éæ‰€æœ‰ICLéƒ½ä¸è®­ç»ƒã€‚æ¯”å¦‚ä¸‹å›¾å³ä¸Šè§’çš„FLANå°±æ˜¯ç”¨instruction tuningè®­ç»ƒå‚æ•°çš„ã€‚ FLANï¼Œæ—¢å±äº in context learningï¼Œä¹Ÿå±äº instruction learning Instruction Learning [1] # Instruct Tuning- # FLANv1, FLANv2 instructGPT # chatGPT # Instruction Tuning # å¯¹äºå·²æœ‰çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œç»§ç»­åœ¨å¤šé¡¹ä»»åŠ¡ï¼ˆBã€Cã€Dç­‰ï¼‰ä¸Šåšè®­ç»ƒï¼Œåœ¨å…¶ä»–ä»»åŠ¡ï¼ˆAï¼‰ä¸Šåšé¢„æµ‹ã€‚è™½ç„¶ä¾ç„¶æ²¡è§è¿‡ä»»åŠ¡Aï¼Œä½†æ˜¯æ ¹æ®å¯¹Bã€Cã€Dç­‰çš„è®­ç»ƒï¼Œå¯¹Açš„æ•ˆæœæœ‰æ‰€æå‡ï¼› [1]\nInstruct Tuning æœ¬è´¨ä¸Šä¹Ÿæ˜¯Prompt Tuning [2]\nç ”ç©¶äº†ç¼©æ”¾å¯¹æŒ‡ä»¤å¾®è°ƒçš„å½±å“ [3] ä¸å¾®è°ƒæŒ‡ä»¤çš„ä»»åŠ¡æ•°é‡æœ‰å…³ï¼Œä»»åŠ¡æ•°é‡è¶Šå¤šæ•ˆæœè¶Šå¥½ ä¸æ¨¡å‹çš„å¤§å°æœ‰å…³ï¼Œæ¨¡å‹è¶Šå¤§æ•ˆæœè¶Šå¥½\nPrompt vs. Instruction Tuning [4] Promptæ˜¯å»æ¿€å‘è¯­è¨€æ¨¡å‹çš„è¡¥å…¨èƒ½åŠ›ï¼Œæ¯”å¦‚ç»™å‡ºä¸ŠåŠå¥ç”Ÿæˆä¸‹åŠå¥ã€æˆ–è€…åšå®Œå½¢å¡«ç©ºï¼Œéƒ½è¿˜æ˜¯åƒåœ¨åšlanguage modelä»»åŠ¡. è€ŒInstruction Tuningåˆ™æ˜¯æ¿€å‘è¯­è¨€æ¨¡å‹çš„ç†è§£èƒ½åŠ›ï¼Œé€šè¿‡ç»™å‡ºæ›´æ˜æ˜¾çš„æŒ‡ä»¤/æŒ‡ç¤ºï¼Œè®©æ¨¡å‹å»ç†è§£å¹¶åšå‡ºæ­£ç¡®çš„action Prompt tuningéƒ½æ˜¯é’ˆå¯¹ä¸€ä¸ªä»»åŠ¡çš„ï¼Œæ¯”å¦‚åšä¸ªæƒ…æ„Ÿåˆ†æä»»åŠ¡çš„prompt tuningï¼Œç²¾è°ƒå®Œçš„æ¨¡å‹åªèƒ½ç”¨äºæƒ…æ„Ÿåˆ†æä»»åŠ¡ï¼Œè€Œç»è¿‡Instruction Tuningå¤šä»»åŠ¡ç²¾è°ƒåï¼Œå¯ä»¥ç”¨äºå…¶ä»–ä»»åŠ¡çš„zero-shot\nInstruction Tuning æŒ‡ä»¤å¾®è°ƒ [4]\nSelf Instruction Alpaca = LLaMA + Intruction Tuning [2] Limitation of instruction finetuning [2] # é—®é¢˜1. å¼€æ”¾æ€§é—®é¢˜ é—®é¢˜2. çœ‹å›¾\nå‚è€ƒ # å„ç§tuningçš„ç®€å•é€»è¾‘è§£é‡Š\nç¬¬ä¹è¯¾ï¼šInstruct Tuning *** V\nFLANv2ï¼šå¤§æ¨¡å‹æŒ‡ä»¤å¾®è°ƒå¿…çœ‹è®ºæ–‡\nInstruction Tuningï½œè°·æ­ŒQuoc V.Leå›¢é˜Ÿæå‡ºåˆä¸€ç²¾è°ƒèŒƒå¼\n1xx. June 2023, A Stage Review of Instruction Tuning\n1xx. ã€LLMç³»åˆ—ä¹‹FLAN-T5/PaLMã€‘Scaling Instruction-Finetuned Language Models\n1xx. å¦‚ä½•ä¼˜åŒ–å¤§æ¨¡å‹çš„In-Context Learningæ•ˆæœï¼Ÿ\n1xx. Instruction Tuningï¼ˆFLANã€instructGPTã€chatGPTï¼‰\n"},{"id":20,"href":"/www6vAIGC/docs/FineTuning/PEFT/Soft-Prompt/PromptTuning/","title":"(åŸç†)Prompt Tuning","section":"Soft Prompt","content":"\nNPLèŒƒå¼ [1] # Prompt Tuning [2] # ğŸ”” Prompt Tuning ğŸ”— æ–‡ç« ï¼šThe Power of Scale for Parameter-Efficient Prompt Tuning (EMNLP 2021) https://aclanthology.org/2021.emnlp-main.243/ ğŸ”‘å…³é”®è¯å’Œæ‘˜è¦ Keywords: Large-scale PLMs, Parameter-efficient Tuning, Prompt Tuning æ‘˜è¦ Promptå˜æˆå¯å­¦ä¹ çš„å‘é‡ï¼Œå›ºå®šPLMï¼Œå¾®è°ƒPromptæ¥é€‚é…ä¸‹æ¸¸ä»»åŠ¡ PLMå‚æ•°è§„æ¨¡è¶Šå¤§ï¼ŒPrompt Tuningçš„æ€§èƒ½å’Œå…¨å‚æ•°å¾®è°ƒè¶Šæ¥è¿‘ è¿™ç§åŸºäºSoft Promptçš„Prompt Tuningæ–¹æ³•å¯ä»¥çœ‹ä½œæ˜¯Prefix Tuningçš„ç®€åŒ–ç‰ˆæœ¬ï¼ˆåªåŠ åœ¨è¾“å…¥ä¸Šï¼‰ âš™ï¸ç ”ç©¶è®¾è®¡å’Œç»“è®º æ–¹æ³• æ¨¡å‹ç¤ºæ„å›¾ï¼šxxx æ¨¡å‹åŸºæœ¬æ€è·¯ï¼š ç»å…¸åˆ†ç±»ï¼šP(Y | X; Î¸) Hard Prompt: P(Y | [P;X] ; Î¸) Soft Prompt: P(Y | [P;X] ; Î¸; Î”) Pre-Training Fine-Tuning Prompt Tuning å®ç°ç»†èŠ‚ï¼š æ¨¡å‹å‚æ•°é‡ å‚æ•°é‡ï¼šT5 ~ T5-XXL(10B) é¢„è®­ç»ƒï¼šLM Adaptation Prompté•¿åº¦ï¼šxxx 1ã€5ã€20ã€100ã€150 åˆå§‹åŒ–æ–¹æ³•ï¼šxxx éšæœºåˆå§‹åŒ– ä½¿ç”¨é¢„è®¾æ–‡æœ¬çš„è¯å‘é‡åˆå§‹åŒ–ï¼Œç±»ä¼¼äºè®¾è®¡hard promptï¼Œç„¶åå°†hard promptè½¬åŒ–ä¸ºsoft prompt ä½¿ç”¨ç±»åˆ«è¯å‘é‡åˆå§‹åŒ–ï¼Œç±»ä¼¼äºæä¾›é€‰é¡¹ å®éªŒ æ•°æ®é›†ï¼šSuperGLUE xxx Promptçš„è§„æ¨¡è¶Šå¤§ï¼Œæ€§èƒ½ç›¸å¯¹è€Œè¨€ä¼šè¶Šå¥½ xxx åŸºäºè¯­ä¹‰ä¿¡æ¯çš„åˆå§‹åŒ–æ¯”éšæœºåˆå§‹åŒ–è¦å¥½ xxx LM Adaptation å¯¹æ€§èƒ½æå‡æ˜¾è‘— Prompt Tuningè¿˜æ˜¯éœ€è¦å¤§æ¨¡å‹æœ‰è¾ƒå¥½çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ› xxx æ¨¡å‹å‚æ•°è§„æ¨¡è¶Šå¤§ï¼ŒPrompt Tuningæ•ˆæœè¶Šå¥½ 10Bå‚æ•°æ—¶ä¸å…¨å‚æ•°å¾®è°ƒæ€§èƒ½æ¥è¿‘ ğŸ“šè®ºæ–‡è´¡çŒ® ä¼˜ç‚¹ï¼ˆè®¡ç®—å‹å¥½ï¼‰ å¤§æ¨¡å‹çš„å¾®è°ƒæ–°èŒƒå¼ ä¸€ä¸ªä¸­å¿ƒæ¨¡å‹æœåŠ¡å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ï¼ŒèŠ‚çœå‚æ•°å­˜å‚¨é‡ æ— éœ€ä¼˜åŒ–æ¨¡å‹å‚æ•°ï¼ŒèŠ‚çœä¼˜åŒ–å™¨çš„è®¡ç®—é‡å’Œå­˜å‚¨é‡ åªåœ¨è¾“å…¥å±‚è¿›è¡Œæ“ä½œï¼Œé€‚åˆå¤šä»»åŠ¡åœºæ™¯ä¸‹çš„è®¡ç®—åˆå¹¶ ç¼ºç‚¹ï¼ˆæ€§èƒ½å’Œæ”¶æ•›æ€§å­˜åœ¨é—®é¢˜ï¼‰ Prompt Tuningçš„æ”¶æ•›é€Ÿåº¦å¾ˆæ…¢ Prompt Tuningçš„æ¨¡å‹æ€§èƒ½ä¸ç¨³å®š Few-shotåœºæ™¯ä¸Šè¡¨ç°ä¸ä½³ Prompt Tuning[3] # Allow an additional k tunable tokens per downstream task to be prepended to the input text No intermediate-layer prefixes or task-specific output layers Freeze the entire pre-trained model and only optimize the embedding layer å‚è€ƒ # [ç»¼è¿°]é¹é£å¤§ç¥çš„Pre-train, Prompt, and Predict [1]\næ¸…ååšåå¸¦ä½ è½»æ¾åƒé€Prompt Tuningé¡¶ä¼šå¤§æ¨¡å‹è®ºæ–‡ V\nç¬¬ä¸ƒè¯¾ï¼šPrompt Tuning *** V æœ‰ppt\n1xx. è¿‘ä»£è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯å‘å±•çš„â€œç¬¬å››èŒƒå¼â€ Prompt Learning\n1xx. PromptèŒƒå¼çš„ç¼˜èµ·ï½œPattern-Exploiting Training\n1xx. PromptèŒƒå¼ç¬¬äºŒé˜¶æ®µï½œPrefix-tuningã€P-tuningã€Prompt-tuning\nP-tuning v2 # 1xx. æ¸…åP-tuning v2ã€è°·æ­ŒSPoTï½œPromptå¯ä»¥è¶…è¿‡ç²¾è°ƒäº†å—ï¼Ÿ\n"},{"id":21,"href":"/www6vAIGC/docs/Application/NL2SQL/NL2SQL/","title":"NL2SQL","section":"NL2SQL","content":" å‚è€ƒ # 1xx. å¤§æ¨¡å‹ä¸æ•°æ®ç§‘å­¦ï¼šä»Text-to-SQL å¼€å§‹ï¼ˆä¸€ï¼‰ å¤šæ¬¾äº§å“\nå®è·µ\u0026amp;ä¼˜åŒ– # 1xx. LLMåœ¨ä¸­æ–‡Text2SQLçš„å®è·µ 1xx. LLMåœ¨ä¸­æ–‡Text2SQLä»»åŠ¡ä¸Šçš„ä¼˜åŒ–V2.0 1xx. LLMåœ¨ä¸­æ–‡Text2SQLä»»åŠ¡ä¸Šçš„ä¼˜åŒ–V1.0\nWork # 1xx. C3: Zero-shot Text-to-SQL with ChatGPTç¬”è®° 1xx. C3SQL git\n1xx. ä¹Ÿçœ‹å¤§æ¨¡å‹ä¸æ•°æ®åº“æŸ¥è¯¢åˆ†æçš„è½åœ°ç»“åˆï¼šC3 Text2SQLæ–¹æ¡ˆåŠData-Copilotæ•°æ®è‡ªåŠ¨åŒ–ç¼–æ’æœºåˆ¶çš„å®ç°æ€æƒ³é˜…è¯» ***\næ—©æœŸWork # 1xx. è¯­ä¹‰è§£æ (Text-to-SQL) æŠ€æœ¯ç ”ç©¶åŠåº”ç”¨ ä¸Šç¯‡ 1xx. è¯­ä¹‰è§£æ (Text-to-SQL) æŠ€æœ¯ç ”ç©¶åŠåº”ç”¨ ä¸‹ç¯‡ å…¶ä»– # 1xx. LLMs and SQL\nç™¾åº¦åƒå¸†-ppt\nQCon-ppt\n"},{"id":22,"href":"/www6vAIGC/docs/RAG/%E6%A1%88%E4%BE%8B/RAGOpenAI/","title":"(åŸç†)RAG OpenAIæ¡ˆä¾‹","section":"æ¡ˆä¾‹","content":"\nOpenAI RAG æ¡ˆä¾‹[3] # retrieval with consine similarity HyDE retrieval [5] Fine-tune Embeddings Chunk/embedding experiments Reranking [6][8] Classification step Prompt engineering Tool use Query expansion[5] Query Transformations[5] # Query expansion Multi-query retriever HyDE Step back prompting [æŠ½è±¡prompting] Rewrite-Retrieve-Read Query Construction [4] # Examples Data source References Text-to-metadata-filter Vectorstores Docs Text-to-SQL SQL DB Docs, blog, blog Text-to-metadata-filter [7] A self-querying retriever is one that, as the name suggests, has the ability to query itself. Specifically, given any natural language query, the retriever uses a query-constructing LLM chain to write a structured query and then applies that structured query to its underlying VectorStore. This allows the retriever to not only use the user-input query for semantic similarity comparison with the contents of stored documents but to also extract filters from the user query on the metadata of stored documents and to execute those filters.\nAdvanced RAG # æ¶æ„ [1] # ç¦»çº¿ index åœ¨çº¿ æŸ¥è¯¢ å‚è€ƒ # Deconstructing RAG ***\nxxx\nApplying OpenAI\u0026rsquo;s RAG Strategies ***\nQuery Construction ***\nQuery Transformations\nSay Goodbye to Irrelevant Search Results: Cohere Rerank Is Here Rerank Cohere Reranker\nself_query\nRAG Fusion Forget RAG, the Future is RAG-Fusion\n"},{"id":23,"href":"/www6vAIGC/docs/FineTuning/PEFT/FineTuning/","title":"(åŸç†)PEFT +","section":"PEFT *","content":"\nPEFTåŸç† # (åŸç†)PEFT\n"},{"id":24,"href":"/www6vAIGC/docs/Agent/Communication/MCP/","title":"(åŸç†|å®æˆ˜)MCP +","section":"Communication *","content":"\nMCP # (åŸç†|å®æˆ˜)MCP\n"},{"id":25,"href":"/www6vAIGC/docs/Prompt-Engineering/PromptEngineering/","title":"(åŸç†)Prompt Engineering","section":"Prompt Engineering","content":"\nBasic Prompting [2] # Zero-Shot Prompting [3] # Few-Shot Prompting [3] # CoT [2] # Chain-of-Thought Prompting(CoT) [3] # Few-shot CoT Zero-shot COT\n\u0026ldquo;Let\u0026rsquo;s think step by step\u0026rdquo; Self-Consistency(CoT-SC) [3] # The idea is to sample multiple, diverse reasoning paths through few-shot CoT, and use the generations to select the most consistent answer.\nTree of Thoughts (ToT) # CoT vs. CoT-SC vs. ToT [3] # Tips and Extensions [2] # Self-Ask\nAutomatic Prompt Design [2] # Automatic Chain-of-Thought (Auto-CoT) [3] Six strategies for getting better results[1] # Write clear instructions # æ¸…æ™°çš„æŒ‡ä»¤\nProvide reference text # Split complex tasks into simpler subtasks # å¤æ‚ä»»åŠ¡ç®€å•åŒ–\rGive the model time to \u0026ldquo;think\u0026rdquo; # ç»™æ¨¡å‹æ—¶é—´å»æ€è€ƒ\nUse external tools # ä½¿ç”¨å¤–éƒ¨å·¥å…·\nTest changes systematically # ä¼˜ç‚¹vs ç¼ºç‚¹ # ä¼˜ç‚¹ # ç®€å• å®¹æ˜“ä¸Šæ‰‹\nç¼ºç‚¹ # ä¸Šé™æœ‰é™ æ¨¡å‹é€‚é… promptè¦é€‚é…æ¯ä¸ªæ¨¡å‹ å‚è€ƒ # Prompt engineering openai Prompt Engineering paper Prompt Engineering Guide guide Prompt-Engineering-Guide *** git 1xx. ã€ç¤¾åŒºç¬¬åä¸‰è®²ã€‘ è€åˆ˜è¯´NLPçº¿ä¸Šäº¤æµ *** å¾ˆå…¨\n1xx. [è®ºæ–‡é˜…è¯»] Prompt Engineeringç»¼è¿°\n1xx. The Prompt Landscape langchain\n1xx. CometLLM - suite of LLMOps tools - track and visualize LLM prompts and chains\n1xx. å¤§æ¨¡å‹ PUA æŒ‡å—ï¼šæ¥è‡ª Google Meta Microsoft ç­‰å¤§å‚\n1xx. NLPï¼ˆåä¸‰ï¼‰ï¼šPrompt Engineering é¢é¢è§‚\n1xx. prompt-engineering git\n1xx. Chain-of-Thought Prompting ç®€è¯» 1xx. ChatGPTåº”ç”¨ç«¯çš„Promptè§£æï¼šä»æ¦‚å¿µã€åŸºæœ¬æ„æˆã€å¸¸è§ä»»åŠ¡ã€æ„é€ ç­–ç•¥åˆ°å¼€æºå·¥å…·ä¸æ•°æ®é›† 1xx. AutoPrompt Repo git\næ¡ˆä¾‹ # è¿ç»´å¤§æ¨¡å‹æ¢ç´¢ä¹‹ Text2PromQL é—®ç­”æœºå™¨äºº æ¶æ„å›¾ï¼Œ æœ€åä¸¤ä¸ªé‡ç‚¹æ€»ç»“ æœª "},{"id":26,"href":"/www6vAIGC/docs/Agent/Overview/Agent/","title":"(åŸç†)Agent æ¶æ„ +","section":"Overview","content":"\nAgent æ¶æ„ # (åŸç†)Agent æ¶æ„ "},{"id":27,"href":"/www6vAIGC/docs/Langchain/Langchain/","title":"Langchain","section":"Langchain","content":"\nModules # main modules # Model I/O # Language models [10] LLM Chat Model Embedding Prompts Prompt Template Few-shot example Example Selectors [ç±»æ¯”é€‰æ‹©] å…³é”®å­— ç›¸ä¼¼åº¦ é•¿åº¦ Output parsers function call[2] Retrieval # Document Loaders Text Splitters Retrievers[10] VectorStores index Agent # Plan-and-execute agents Additional modules # Chains # 2å¤§ç±» Chain interface[Legacy] LangChain Expression Language (LCEL) LCEL is a declarative way to compose chains. Foundational LLM Sequential- SequentialChain Router Transformation Memory [10] # å¸®è¯­è¨€æ¨¡å‹è¡¥å……ä¸Šä¸‹æ–‡ ConversationBufferMemory ConversationBufferWindowMemory çª—å£ ConversationSummaryMemory VectorStoreRetrieverMemory Function Call # from langchain.chains.openai_functions.base import ( create_openai_fn_chain, create_structured_output_chain,[2] ) from langchain.chains.openai_functions.citation_fuzzy_match import ( create_citation_fuzzy_match_chain, ) from langchain.chains.openai_functions.extraction import ( create_extraction_chain, create_extraction_chain_pydantic, ) from langchain.chains.openai_functions.qa_with_structure import ( create_qa_with_sources_chain, create_qa_with_structure_chain, ) from langchain.chains.openai_functions.tagging import ( create_tagging_chain, create_tagging_chain_pydantic, ) åº”ç”¨[4] # Question \u0026amp; Answering Using Documents As Context[3] Extraction[Kor] Evaluation Querying Tabular Data[sqlite] Code Understanding Interacting with APIs Chatbots Chains [1] [8][9] # chain = load_summarize_chain(llm, chain_type=\u0026#34;stuff\u0026#34;, verbose=True) chain = load_summarize_chain(llm, chain_type=\u0026#34;map_reduce\u0026#34;, verbose=True) chain = load_summarize_chain(llm, chain_type=\u0026#34;refine\u0026#34;, verbose=True) chain = load_qa_chain(llm, chain_type=\u0026#34;map_rerank\u0026#34;, verbose=True, return_intermediate_steps=True) é“¾ç±»å‹ æ•´åˆæ–¹æ³• ä¼˜ç¼ºç‚¹ stuff å°†æ‰€æœ‰å†…å®¹æ”¾å…¥ä¸€ä¸ªæç¤ºä¸­ï¼Œè¾“å…¥LLM ç®€å•ã€å»‰ä»·ã€æ•ˆæœå¥½/ å¯¹è¾“å…¥æ–‡æœ¬æœ‰ä¸€å®štokené™åˆ¶ Map_reduce æ¯ä¸ªé—®é¢˜å’Œæ–‡æœ¬å—å•ç‹¬ç»™è¯­è¨€æ¨¡å‹ï¼Œå¹¶å°†ç­”æ¡ˆæ±‡æ€»ç”Ÿæˆæœ€ç»ˆç»“æœ è¾“å…¥ä»»æ„æ•°é‡æ–‡æœ¬ï¼Œä¸”å¹¶è¡Œå¤„ç†/ é€Ÿåº¦æ…¢ï¼Œè´¹token Refine è¿­ä»£å¤„ç†å¤šä¸ªæ–‡æœ¬ï¼ŒåŸºäºå‰ä¸€ä¸ªæ–‡æ¡£ç­”æ¡ˆæ„å»ºä¸‹ä¸€ä¸ªç­”æ¡ˆ ç”¨äºç»„åˆä¿¡æ¯ï¼Œä¾æ¬¡æ„å»ºç­”æ¡ˆ/ é€Ÿåº¦æ…¢ï¼Œè´¹token Map_rerank æ¯ä¸ªæ–‡æ¡£å•ç‹¬è°ƒç”¨LLM,å¹¶è¦æ±‚è¿”å›ä¸€ä¸ªå¾—åˆ†ï¼Œç„¶åé€‰æ‹©æœ€é«˜çš„å¾—åˆ† éœ€è¦å‘Šè¯‰æ¨¡å‹è¯„åˆ†çš„è§„åˆ™/ è´¹token Templates[7] # å‚è€ƒ # https://github.com/gkamradt/langchain-tutorials\nfunctioncall\nqaOnDoc\nLangChain Cookbook Part 2: Use Cases 10.å…¬å¼€è¯¾\nhttps://github.com/kyrolabs/awesome-langchain\nhttps://github.com/Crossme0809/langchain-tutorials\nTemplates *** docs templates webui\nå´æ©è¾¾çŸ­è¯¾_LangChain\nç²¾åç¬”è®°ï¼šå´æ©è¾¾ x LangChain ã€Šä½¿ç”¨LangChainæ„å»ºä¸æ•°æ®å¯¹è¯çš„èŠå¤©æœºå™¨äººã€‹ï¼ˆä¸‹ï¼‰\nä¸€æ–‡å…¥é—¨æœ€çƒ­çš„LLMåº”ç”¨å¼€å‘æ¡†æ¶LangChain æœª\nå¤§æ¨¡å‹LangChainæ¡†æ¶åŸºç¡€ä¸ä½¿ç”¨ç¤ºä¾‹ æœª\n"},{"id":28,"href":"/www6vAIGC/docs/Context-Engineering/context-engineering/","title":"(Manus)context engineering","section":"Context Engineering","content":" æ€»ç»“[1] # å‚è€ƒ # Manus å†…éƒ¨çš„ Context å·¥ç¨‹ç»éªŒï¼ˆç²¾æ ¡ã€é«˜äº®è¦ç‚¹ï¼‰ Manus åˆ›å§‹äººæ‰‹æŠŠæ‰‹æ‹†è§£ï¼šå¦‚ä½•ç³»ç»Ÿæ€§æ‰“é€  AI Agent çš„ä¸Šä¸‹æ–‡å·¥ç¨‹ï¼Ÿ\nContext Engineering for AI Agents: Lessons from Building Manus\n"},{"id":29,"href":"/www6vAIGC/docs/RAG/Overview/RAG/","title":"(ç»¼è¿°)RAG +","section":"Overview","content":"\nRAGç»¼è¿° # (ç»¼è¿°)RAG\n"},{"id":30,"href":"/www6vAIGC/docs/Application/gpt/","title":"GPT-å·¥å…·å’Œåº”ç”¨","section":"Application","content":"\nPlatform # å›½å¤– Poe *** å›½å†… å®æˆ˜äº‘ gpt3.5 gpt4 ChatGPTä½¿ç”¨æŒ‡å—ï¼ *** çµçŠ€ç™¾é€š gpt3.5 ChatGpt PLUS æ–‡å¿ƒä¸€è¨€ Tools \u0026amp; Mix # GPTå­¦ä¹ å®å…¸\nèšåˆ GPT å·¥å…·ç®± æ•™ç¨‹ å­¦ä¹ èµ„æ–™ æå®¢æ—¶é—´ AIGC çŸ¥è¯†åº“ ***\nèšåˆ AIå·¥å…·å¤§å…¨ AIä¸»æµå·¥å…·ç²¾é€‰ AIç»å…¸é¡¹ç›® AIå¯¼èˆªç«™ åº”ç”¨ä¸å˜ç°æ¡ˆä¾‹ AI å·¥å…·ç®± ***\nChatGPT Tutorial 101\nåº”ç”¨ # æ€ç»´å¯¼å›¾ # albus\nè§†é¢‘ # BibiGPT Youtube tools\nè‹±è¯­ # callannie\nå®¢æˆ·ç«¯ # ChatGPT å®¢æˆ·ç«¯ windowsï¼Œ mac Chrome plugin # WebChatGPT[instatlled]\nAIPRM for ChatGPT[instatlled]\nChatGPT Sidebar è¦æ³¨å†Œè´¦å·, éœ€è¦api token\nChatHub [instatlled] chatgpt + new bing ChatHub OpenAI Translator openai-translator è¦æ³¨å†Œè´¦å·, éœ€è¦api token\nåˆ›ä¸š # GPT-3 Demo èŠå¤©æœºå™¨äºº ä»£ç è¾…åŠ© å†™ä½œåº”ç”¨ æ¸¸æˆ "},{"id":31,"href":"/www6vAIGC/docs/Prompt-Engineering/PromptingClaude/","title":"(å®è·µ)Prompting Claude *","section":"Prompt Engineering","content":" Beginner[1] # Prompt generator [10] # Prompt generator\næç¤ºç”Ÿæˆå™¨\nBe clear and direct # Be clear and direct\næ¸…æ™°ç›´æ¥\nGive Claude a role (system prompts) *** # Give Claude a role (system prompts)\nç»™ Claude ä¸€ä¸ªè§’è‰²ï¼ˆç³»ç»Ÿæç¤ºï¼‰\nexample æ‚¨æ˜¯ä¸€å®¶ä¸–ç•Œ500å¼ºç§‘æŠ€å…¬å¸çš„æ€»æ³•å¾‹é¡¾é—®ã€‚æˆ‘ä»¬æ­£åœ¨è€ƒè™‘å°†è¿™ä»½è½¯ä»¶è®¸å¯åè®®ç”¨äºæˆ‘ä»¬çš„æ ¸å¿ƒæ•°æ®åŸºç¡€è®¾æ–½ï¼š {{CONTRACT}} åˆ†æå…¶æ½œåœ¨é£é™©ï¼Œé‡ç‚¹å…³æ³¨èµ”å¿ã€è´£ä»»å’ŒçŸ¥è¯†äº§æƒæ‰€æœ‰æƒã€‚è¯·ç»™å‡ºæ‚¨çš„ä¸“ä¸šæ„è§ã€‚\nIntermediate[1] # Use XML tags *** # Use XML tags\nä½¿ç”¨ XML æ ‡ç­¾\nexample ä½ æ˜¯AcmeCorpçš„è´¢åŠ¡åˆ†æå¸ˆã€‚ä¸ºæˆ‘ä»¬çš„æŠ•èµ„è€…ç”ŸæˆQ2è´¢åŠ¡æŠ¥å‘Šã€‚\nAcmeCorpæ˜¯ä¸€å®¶B2B SaaSå…¬å¸ã€‚æˆ‘ä»¬çš„æŠ•èµ„è€…é‡è§†é€æ˜åº¦å’Œå¯è¡Œçš„è§è§£ã€‚\nä½¿ç”¨è¿™äº›æ•°æ®ç”ŸæˆæŠ¥å‘Šï¼š{{SPREADSHEET_DATA}}\nåŒ…æ‹¬ä»¥ä¸‹éƒ¨åˆ†ï¼šæ”¶å…¥å¢é•¿ã€åˆ©æ¶¦ç‡ã€ç°é‡‘æµã€‚ çªå‡ºä¼˜åŠ¿å’Œéœ€è¦æ”¹è¿›çš„é¢†åŸŸã€‚ ä½¿ç”¨ç®€æ´ä¸“ä¸šçš„è¯­æ°”ã€‚éµå¾ªè¿™ä¸ªç»“æ„ï¼š \u0026lt;formatting_example\u0026gt;{{Q1_REPORT}}\u0026lt;/formatting_example\u0026gt;\nLet Claude think (chain of thought) *** # Let Claude think (chain of thought)\nè®© Claude æ€è€ƒï¼ˆæ€ç»´é“¾ï¼‰\nexample ä½ æ˜¯ä¸€åè´¢åŠ¡é¡¾é—®ã€‚ä¸€ä½å®¢æˆ·æƒ³æŠ•èµ„10,000ç¾å…ƒã€‚ä»–ä»¬å¯ä»¥åœ¨ä¸¤ä¸ªé€‰é¡¹ä¸­é€‰æ‹©ï¼šAï¼‰ä¸€æ”¯å†å²å¹´å›æŠ¥ç‡ä¸º12%ä½†æ³¢åŠ¨çš„è‚¡ç¥¨ï¼Œæˆ– Bï¼‰ä¸€æ”¯ä¿è¯å¹´å›æŠ¥ç‡6%çš„å€ºåˆ¸ã€‚å®¢æˆ·éœ€è¦åœ¨5å¹´å†…ç”¨è¿™ç¬”é’±ä½œä¸ºæˆ¿å­çš„é¦–ä»˜ã€‚ä½ æ¨èå“ªä¸ªé€‰é¡¹ï¼Ÿã€è¯·é€æ­¥æ€è€ƒã€‚ã€‘\nUse examples (multishot) *** # Use examples (multishot)\nä½¿ç”¨ç¤ºä¾‹ï¼ˆå¤šæ ·æœ¬ï¼‰\nexample æˆ‘ä»¬çš„å®¢æœå›¢é˜Ÿè¢«éç»“æ„åŒ–åé¦ˆæ·¹æ²¡äº†ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä¸ºæˆ‘ä»¬çš„äº§å“å’Œå·¥ç¨‹å›¢é˜Ÿåˆ†æåé¦ˆå¹¶å¯¹é—®é¢˜è¿›è¡Œåˆ†ç±»ã€‚ä½¿ç”¨è¿™äº›ç±»åˆ«ï¼šUI/UXã€æ€§èƒ½ã€åŠŸèƒ½è¯·æ±‚ã€é›†æˆã€å®šä»·å’Œå…¶ä»–ã€‚åŒæ—¶è¯„ä¼°æƒ…æ„Ÿï¼ˆç§¯æ/ä¸­æ€§/æ¶ˆæï¼‰å’Œä¼˜å…ˆçº§ï¼ˆé«˜/ä¸­/ä½ï¼‰ã€‚è¿™é‡Œæœ‰ä¸€ä¸ªç¤ºä¾‹ï¼š\nè¾“å…¥ï¼šæ–°ä»ªè¡¨æ¿ä¸€å›¢ç³Ÿï¼åŠ è½½éœ€è¦å¾ˆé•¿æ—¶é—´ï¼Œè€Œä¸”æˆ‘æ‰¾ä¸åˆ°å¯¼å‡ºæŒ‰é’®ã€‚è¯·å°½å¿«ä¿®å¤è¿™ä¸ªé—®é¢˜ï¼ ç±»åˆ«ï¼šUI/UXã€æ€§èƒ½ æƒ…æ„Ÿï¼šæ¶ˆæ ä¼˜å…ˆçº§ï¼šé«˜ ç°åœ¨ï¼Œåˆ†æè¿™ä¸ªåé¦ˆï¼š{{FEEDBACK}}\nPrefill Claudeâ€™s response # Prefill Claudeâ€™s response\né¢„å¡«å…… Claude çš„å“åº”\nexample ç¤ºä¾‹ 1ï¼šæ§åˆ¶è¾“å‡ºæ ¼å¼å¹¶è·³è¿‡å‰è¨€ # Advanced[1] # Chain complex prompts *** # Chain complex prompts\né“¾æ¥å¤æ‚æç¤º\nå¦‚ä½•é“¾å¼æç¤º # è¯†åˆ«å­ä»»åŠ¡ï¼šå°†ä»»åŠ¡åˆ†è§£ä¸ºä¸åŒçš„ã€è¿ç»­çš„æ­¥éª¤ã€‚ ä½¿ç”¨XMLæ„å»ºæ¸…æ™°çš„äº¤æ¥ï¼šä½¿ç”¨XMLæ ‡ç­¾åœ¨æç¤ºä¹‹é—´ä¼ é€’è¾“å‡ºã€‚ è®¾å®šå•ä¸€ä»»åŠ¡ç›®æ ‡ï¼šæ¯ä¸ªå­ä»»åŠ¡åº”è¯¥æœ‰ä¸€ä¸ªæ˜ç¡®çš„å•ä¸€ç›®æ ‡ã€‚ è¿­ä»£ï¼šæ ¹æ®Claudeçš„è¡¨ç°æ”¹è¿›å­ä»»åŠ¡ã€‚ example äº‹ä¾‹ï¼šåˆ†ææ³•å¾‹åˆåŒ\nLong context tips # Long context tips\né•¿ä¸Šä¸‹æ–‡æç¤º\nexample annual_report_2023.pdf {{ANNUAL_REPORT}} competitor_analysis_q2.xlsx {{COMPETITOR_ANALYSIS}} åˆ†æå¹´åº¦æŠ¥å‘Šå’Œç«äº‰å¯¹æ‰‹åˆ†æã€‚è¯†åˆ«æˆ˜ç•¥ä¼˜åŠ¿å¹¶æ¨èç¬¬ä¸‰å­£åº¦é‡ç‚¹å…³æ³¨é¢†åŸŸã€‚\nå‚è€ƒ # Anthropicæç¤ºå·¥ç¨‹æŒ‡å—ï¼šPrompt Engineering Overview https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview\nhttps://docs.anthropic.com/zh-CN/docs/build-with-claude/prompt-engineering/overview\nAnthropicäº¤äº’å¼æç¤ºå·¥ç¨‹æ•™ç¨‹ï¼šPrompt Engineering Interactive Tutorial\nhttps://github.com/anthropics/prompt-eng-interactive-tutorial\nâ€‹\tAnthropic\u0026rsquo;s Prompt Engineering Interactive Tutorial\nâ€‹\tPrompt Engineering Interactive Tutorial\nhttps://blog.zhexuan.org/archives/Anthropic-Prompt.html prompt-generator # è‡ªåŠ¨ç”Ÿæˆé¦–ç‰ˆæç¤ºè¯æ¨¡æ¿ â€‹ https://console.anthropic.com/dashboard\n"},{"id":32,"href":"/www6vAIGC/docs/%E5%85%B6%E4%BB%96/self-work/","title":"è‡ªå·±çš„å·¥ä½œ","section":"å…¶ä»–","content":" SFT # SFTï¼ˆ3æ¬¡ï¼‰ # + (åŸç†\u0026amp;å®æˆ˜) LORA 1æ¬¡ qwen2.5-7b Unsloth 1æ¬¡ llama2 deepspeed 1æ¬¡bloom â€£ xxx\nllama CPT+SFT\nAgent SFTï¼ˆ2æ¬¡ï¼‰ *** # AgentTuning *** SFT Data # â€£ xxx æ¨¡å‹éƒ¨ç½² # vLLM éƒ¨ç½² Qwen lmdeploy-æ¨ç†éƒ¨ç½² ä¹¦ç”Ÿå¤§æ¨¡å‹ "},{"id":33,"href":"/www6vAIGC/docs/Deep-Research/%E5%AE%9E%E7%8E%B0/DeepResearchJina/","title":"(åŸç†|å®ç°){Jina}Deep Research","section":"å®ç°","content":"\nDeep Research(Jina) # (åŸç†|å®ç°)Deep Research(Jina)\n"},{"id":34,"href":"/www6vAIGC/docs/Agent/Platform/DifySandbox/","title":"(å®ç°)Dify sandbox *","section":"Platform *","content":" Security Model # Security Architecture Overview # Syscall Filtering with Seccomp # Python Seccomp Implementation\nå®ç° # python.go\ntype PythonRunner struct { runner.TempDirRunner } //go:embed prescript.py var sandbox_fs []byte func (p *PythonRunner) Run( code string, timeout time.Duration, stdin []byte, preload string, options *types.RunnerOptions, ) (chan []byte, chan []byte, chan bool, error) { configuration := static.GetDifySandboxGlobalConfigurations() // initialize the environment untrusted_code_path, key, err := p.InitializeEnvironment(code, preload, options) if err != nil { return nil, nil, nil, err } // capture the output output_handler := runner.NewOutputCaptureRunner() output_handler.SetTimeout(timeout) output_handler.SetAfterExitHook(func() { // remove untrusted code os.Remove(untrusted_code_path) }) // create a new process ### æ‰§è¡Œpythonä»£ç çš„è¿›ç¨‹ cmd := exec.Command( configuration.PythonPath, untrusted_code_path, LIB_PATH, key, ) cmd.Env = []string{} cmd.Dir = LIB_PATH if configuration.Proxy.Socks5 != \u0026#34;\u0026#34; { cmd.Env = append(cmd.Env, fmt.Sprintf(\u0026#34;HTTPS_PROXY=%s\u0026#34;, configuration.Proxy.Socks5)) cmd.Env = append(cmd.Env, fmt.Sprintf(\u0026#34;HTTP_PROXY=%s\u0026#34;, configuration.Proxy.Socks5)) } else if configuration.Proxy.Https != \u0026#34;\u0026#34; || configuration.Proxy.Http != \u0026#34;\u0026#34; { if configuration.Proxy.Https != \u0026#34;\u0026#34; { cmd.Env = append(cmd.Env, fmt.Sprintf(\u0026#34;HTTPS_PROXY=%s\u0026#34;, configuration.Proxy.Https)) } if configuration.Proxy.Http != \u0026#34;\u0026#34; { cmd.Env = append(cmd.Env, fmt.Sprintf(\u0026#34;HTTP_PROXY=%s\u0026#34;, configuration.Proxy.Http)) } } if len(configuration.AllowedSyscalls) \u0026gt; 0 { cmd.Env = append(cmd.Env, fmt.Sprintf(\u0026#34;ALLOWED_SYSCALLS=%s\u0026#34;, strings.Trim(strings.Join(strings.Fields(fmt.Sprint(configuration.AllowedSyscalls)), \u0026#34;,\u0026#34;), \u0026#34;[]\u0026#34;), ), ) } err = output_handler.CaptureOutput(cmd) if err != nil { return nil, nil, nil, err } return output_handler.GetStdout(), output_handler.GetStderr(), output_handler.GetDone(), nil } func (p *PythonRunner) InitializeEnvironment(code string, preload string, options *types.RunnerOptions) (string, string, error) { if !checkLibAvaliable() { // ensure environment is reversed releaseLibBinary(false) } // create a tmp dir and copy the python script temp_code_name := strings.ReplaceAll(uuid.New().String(), \u0026#34;-\u0026#34;, \u0026#34;_\u0026#34;) temp_code_name = strings.ReplaceAll(temp_code_name, \u0026#34;/\u0026#34;, \u0026#34;.\u0026#34;) /// æŠŠprescript.pyä¸­çš„placeholderéƒ½æ›¿æ¢æ‰ script := strings.Replace( string(sandbox_fs), \u0026#34;{{uid}}\u0026#34;, strconv.Itoa(static.SANDBOX_USER_UID), 1, ) script = strings.Replace( script, \u0026#34;{{gid}}\u0026#34;, strconv.Itoa(static.SANDBOX_GROUP_ID), 1, ) if options.EnableNetwork { script = strings.Replace( script, \u0026#34;{{enable_network}}\u0026#34;, \u0026#34;1\u0026#34;, 1, ) } else { script = strings.Replace( script, \u0026#34;{{enable_network}}\u0026#34;, \u0026#34;0\u0026#34;, 1, ) } script = strings.Replace( script, \u0026#34;{{preload}}\u0026#34;, fmt.Sprintf(\u0026#34;%s\\\\n\u0026#34;, preload), 1, ) // generate a random 512 bit key key_len := 64 key := make([]byte, key_len) _, err := rand.Read(key) if err != nil { return \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, err } /// ä»£ç åŠ å¯† // encrypt the code encrypted_code := make([]byte, len(code)) for i := 0; i \u0026lt; len(code); i++ { encrypted_code[i] = code[i] ^ key[i%key_len] } /// ä»£ç åšbase64 // encode code using base64 code = base64.StdEncoding.EncodeToString(encrypted_code) // encode key using base64 encoded_key := base64.StdEncoding.EncodeToString(key) code = strings.Replace( script, \u0026#34;{{code}}\u0026#34;, code, 1, ) untrusted_code_path := fmt.Sprintf(\u0026#34;%s/tmp/%s.py\u0026#34;, LIB_PATH, temp_code_name) err = os.MkdirAll(path.Dir(untrusted_code_path), 0755) if err != nil { return \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, err } err = os.WriteFile(untrusted_code_path, []byte(code), 0755) if err != nil { return \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, err } return untrusted_code_path, encoded_key, nil } prescript.py\nimport ctypes import os import sys import traceback # setup sys.excepthook def excepthook(type, value, tb): sys.stderr.write(\u0026#34;\u0026#34;.join(traceback.format_exception(type, value, tb))) sys.stderr.flush() sys.exit(-1) sys.excepthook = excepthook lib = ctypes.CDLL(\u0026#34;./python.so\u0026#34;) lib.DifySeccomp.argtypes = [ctypes.c_uint32, ctypes.c_uint32, ctypes.c_bool] lib.DifySeccomp.restype = None # get running path running_path = sys.argv[1] if not running_path: exit(-1) # get decrypt key key = sys.argv[2] if not key: exit(-1) from base64 import b64decode key = b64decode(key) os.chdir(running_path) {{preload}} lib.DifySeccomp({{uid}}, {{gid}}, {{enable_network}}) code = b64decode(\u0026#34;{{code}}\u0026#34;) def decrypt(code, key): key_len = len(key) code_len = len(code) code = bytearray(code) for i in range(code_len): code[i] = code[i] ^ key[i % key_len] return bytes(code) code = decrypt(code, key) exec(code) "},{"id":35,"href":"/www6vAIGC/docs/FineTuning/Data/Data-Quality/Instruction-Diversity/DataSelfQA/","title":"(åŸç†|å®æˆ˜)Self-QA *","section":"Instruction Diversity","content":"\nSelf-QA[10] # è®ºæ–‡ # SELF-QA: Unsupervised Knowledge Guided Language Model Alignment\næ€æƒ³ # çŸ¥è¯†å¼•å¯¼çš„æŒ‡ä»¤ç”ŸæˆKnowledge-Guided Instruction Generation\næŒ‡ä»¤ç”Ÿæˆé˜¶æ®µ # é‡‡ç”¨è¯­è¨€æ¨¡å‹æœ¬èº«æ¥æ ¹æ®æ— ç›‘ç£çš„æ–‡æœ¬ç”ŸæˆæŒ‡ä»¤ã€‚è¿™ç§æ–¹æ³•ä½¿ç”Ÿæˆçš„æŒ‡ä»¤å…·æœ‰é¢†åŸŸé’ˆå¯¹æ€§ï¼Œå¹¶ä¸æ‰€æä¾›çš„æ— ç›‘ç£æ–‡æœ¬çš„å†…å®¹ç›¸å…³ã€‚ éç»“æ„åŒ–çš„çŸ¥è¯†ï¼Œå¦‚ç½‘é¡µå’Œä¹¦ç±æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨ã€‚ ç»“æ„åŒ–æ•°æ®ï¼Œå¦‚è¡¨æ ¼å’ŒçŸ¥è¯†å›¾è°±ï¼Œåœ¨è¢«åˆ©ç”¨ä¹‹å‰éœ€è¦è½¬æ¢ä¸ºéç»“æ„åŒ–æ–‡æœ¬æ•°æ®ã€‚å¦‚é€šè¿‡ä½¿ç”¨æ¨¡æ¿å¡«å……æ§½æˆ–å°†æ¯ä¸ªæ•°æ®æ¡ç›®ä¸ç›¸åº”çš„å±æ€§åç§°è¿æ¥èµ·æ¥æ¥å®ç°ã€‚ æŒ‡ä»¤ç­”æ¡ˆç”Ÿæˆé˜¶æ®µ # å°†ç”Ÿæˆçš„æŒ‡ä»¤é—®é¢˜è®©å¤§æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼Œç”Ÿæˆç­”æ¡ˆ Self-QA å®æˆ˜[11] # SYSTEM_PROMPT = \u0026#34;\u0026#34;\u0026#34; ä½ æ˜¯ä¸€ä¸ªèƒ½æ ¹æ®æä¾›çš„æ–‡æœ¬å†…å®¹ç”ŸæˆQAå¯¹çš„æœºå™¨äººã€‚ä»¥ä¸‹æ˜¯ä½ çš„ä»»åŠ¡è¦æ±‚ï¼š 1. ç”Ÿæˆå°½å¯èƒ½å¤šçš„QAå¯¹ã€‚ 2. æ¯ä¸ªQAå¯¹åŒ…å«ä¸€ä¸ªé—®é¢˜å’Œä¸€ä¸ªç®€æ´çš„ç­”æ¡ˆã€‚ 3. ç­”æ¡ˆå¿…é¡»ç”¨ç®€ä½“ä¸­æ–‡ã€‚ 4. ç”Ÿæˆçš„QAå¯¹ä¸èƒ½é‡å¤ã€‚ 5. ä½¿ç”¨jsonæ ¼å¼å°†QAå¯¹åŒ…è£¹èµ·æ¥ï¼Œé—®é¢˜ç”¨\u0026#34;question\u0026#34;è¡¨ç¤ºï¼Œç­”æ¡ˆç”¨\u0026#34;answer\u0026#34;è¡¨ç¤ºã€‚ ç¤ºä¾‹æ ¼å¼ï¼š [ { \u0026#34;question\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;answer\u0026#34;: \u0026#34;...\u0026#34; }, { \u0026#34;question\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;answer\u0026#34;: \u0026#34;...\u0026#34; } ] ä»¥ä¸‹æ˜¯ç»™å®šçš„æ–‡æœ¬å†…å®¹ï¼š \u0026#34;\u0026#34;\u0026#34; å‚è€ƒ # Self-QA # 10.ã€Šç¬¬äºŒç«  å¤§æ¨¡å‹è®­ç»ƒä¸å¾®è°ƒç ”å‘èƒŒåçš„æ•°æ®è‰ºæœ¯ã€‹ LLMå¤§è¯­è¨€æ¨¡å‹ç®—æ³•ç‰¹è®­ é‚£ä½ç§‘æŠ€ ***\nSELF-INSTRUCTï¼Œ Baizeï¼Œ Evol-instructï¼Œ Self-QAï¼Œ Ultra-chat\nSelf-QAï¼šç”Ÿæˆè‡ªç„¶è¯­è¨€å¤„ç†è®­ç»ƒæ•°æ®çš„å®ç”¨æ–¹æ³• 1xx. é¡¹ç›®å®è®­2024.04.12æ—¥å¿—ï¼šSelf-QAç”Ÿæˆé—®ç­”å¯¹\nSELF-QAï¼šæ— ç›‘ç£çŸ¥è¯†å¼•å¯¼è¯­è¨€æ¨¡å‹å¯¹é½\nSELF-QAï¼šæ— ç›‘ç£çš„çŸ¥è¯†å¼•å¯¼è¯­è¨€æ¨¡å‹å¯¹é½è®ºæ–‡ç²¾è¯»\n"},{"id":36,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/framework/RAGchatchat/","title":"(æ¡†æ¶)RAG Langchain-Chatchat","section":"framework","content":"\nLangchain-Chatchat æ¶æ„ # ç»„ä»¶ æœ¬åœ°çŸ¥è¯†åº“ Embedding æ¨¡å‹ å‘é‡æ•°æ®åº“ Prompt Template Langchain-Chatchat # éƒ¨ç½² windows 10 [5] éƒ¨ç½²æœ¬åœ°ï¼Œ æ²¡æ˜¾å­˜ï¼Œå¡ Linux [2] éƒ¨ç½² 32C125G ï¼Œæ²¡æ˜¾å­˜ï¼Œ æ¨ç†å¾ˆæ…¢ Docker å‚è€ƒ # Langchain-Chatchat master Langchain ä¸ ChatGLM ç­‰è¯­è¨€æ¨¡å‹çš„æœ¬åœ°çŸ¥è¯†åº“é—®ç­”\nLangchain-Chatchat v0.2.4\nlangchain-ChatGLM gitee\nColab for Langchain-Chatchat linux å¯ä»¥éƒ¨ç½² v0.2.6\nlangChain-ChatGLM å°è¯•ï¼Œè¸©å‘è®°å½•\nLangchain-Chatchat + é˜¿é‡Œé€šä¹‰åƒé—®Qwen ä¿å§†çº§æ•™ç¨‹ | æ¬¡ä¸–ä»£çŸ¥è¯†ç®¡ç†è§£å†³æ–¹æ¡ˆ Langchain-Chatchat + é€šä¹‰åƒé—®\nwin10 å®‰è£… Langchain-Chatchat é¿å‘æŒ‡å—ï¼ˆ2023å¹´9æœˆ18æ—¥v0.2.4ç‰ˆæœ¬ï¼ŒåŒ…å«å…¨éƒ¨ä¸‹è½½å†…å®¹ï¼ï¼‰\n"},{"id":37,"href":"/www6vAIGC/docs/RAG/phase/phaseRAGPostRetrieval/RAGFusion/","title":"(åŸç†|å®æˆ˜)RAG Fusion","section":"(Phase)post-retrieval","content":"\nRAG-Fusionå¤šæŸ¥è¯¢ç»“æœèåˆç­–ç•¥ # å°†å¤šä¸ªå¬å›æŸ¥è¯¢çš„ç»“æœè¿›è¡Œåˆå¹¶[3]\nå…¶æ€æƒ³åœ¨äºé€šè¿‡ç”Ÿæˆå¤šä¸ªç”¨æˆ·æŸ¥è¯¢å’Œé‡æ–°æ’åºç»“æœæ¥è§£å†³RAGå›ºæœ‰çš„çº¦æŸï¼›åˆ©ç”¨å€’æ•°æ’åºèåˆï¼ˆRRFï¼‰å’Œè‡ªå®šä¹‰å‘é‡è¯„åˆ†åŠ æƒï¼Œç”Ÿæˆå…¨é¢å‡†ç¡®çš„ç»“æœã€‚[2]\nä»£ç  # RAG Fusion git\nå‚è€ƒ # Forget RAG, the Future is RAG-Fusion å¤±æ•ˆ ä½¿ç”¨RAG-Fusionå’ŒRRFè®©RAGåœ¨æ„å›¾æœç´¢æ–¹é¢æ›´è¿›ä¸€æ­¥\nå†è°ˆå¤§æ¨¡å‹RAGé—®ç­”ä¸­çš„ä¸‰ä¸ªç°å®é—®é¢˜ï¼šå…¼çœ‹RAG-Fusionå¤šqueryèåˆç­–ç•¥ã€å›ç­”å¼•æ–‡ç”Ÿæˆç­–ç•¥åŠç›¸å…³æ•°æ®é›†æ¦‚è¿° äºŒã€åŸºäºå¤§æ¨¡å‹ç”Ÿæˆèƒ½åŠ›è‡ªåŠ¨ç”Ÿæˆå¼•æ–‡\nä¸€æ–‡è¯¦çœ‹Langchainæ¡†æ¶ä¸­çš„RAGå¤šé˜¶æ®µä¼˜åŒ–ç­–ç•¥ï¼šä»é—®é¢˜è½¬æ¢åˆ°æŸ¥è¯¢è·¯ç”±å†åˆ°ç”Ÿæˆä¼˜åŒ– *** åŸç†paperï¼Œä»£ç ç¤ºä¾‹\nMulti Queryå¤šæŸ¥è¯¢ç­–ç•¥ï¼Œ Decompositioné—®é¢˜ï¼Œ [RAG-Fusion]ï¼Œ Step Backï¼Œ HyDEæ··åˆ\nrag-from-scratch Repo git\n"},{"id":38,"href":"/www6vAIGC/docs/RAG/phase/phaseRAGPreRetrieval/RAGRouting/","title":"(åŸç†|å®æˆ˜)Query Routing","section":"(Phase)pre-retrival","content":"\nç±»å‹[1] # LLM Routers LLM Completion Routers LLM Function Calling Routers Semantic Routers [2] Zero Shot Classification Routers Language Classification Routers Logical and Semantic routing[3] # Logical routing # code from typing import Literal from langchain_core.prompts import ChatPromptTemplate from langchain_core.pydantic_v1 import BaseModel, Field from langchain_openai import ChatOpenAI # Data model class RouteQuery(BaseModel): \u0026#34;\u0026#34;\u0026#34;Route a user query to the most relevant datasource.\u0026#34;\u0026#34;\u0026#34; datasource: Literal[\u0026#34;python_docs\u0026#34;, \u0026#34;js_docs\u0026#34;, \u0026#34;golang_docs\u0026#34;] = Field( ..., description=\u0026#34;Given a user question choose which datasource would be most relevant for answering their question\u0026#34;, ) # LLM with function call llm = ChatOpenAI(model=\u0026#34;gpt-3.5-turbo-0125\u0026#34;, temperature=0) structured_llm = llm.with_structured_output(RouteQuery) # Prompt system = \u0026#34;\u0026#34;\u0026#34;You are an expert at routing a user question to the appropriate data source. Based on the programming language the question is referring to, route it to the relevant data source.\u0026#34;\u0026#34;\u0026#34; prompt = ChatPromptTemplate.from_messages( [ (\u0026#34;system\u0026#34;, system), (\u0026#34;human\u0026#34;, \u0026#34;{question}\u0026#34;), ] ) # Define router router = prompt | structured_llm def choose_route(result): if \u0026#34;python_docs\u0026#34; in result.datasource.lower(): ### Logic here return \u0026#34;chain for python_docs\u0026#34; elif \u0026#34;js_docs\u0026#34; in result.datasource.lower(): ### Logic here return \u0026#34;chain for js_docs\u0026#34; else: ### Logic here return \u0026#34;golang_docs\u0026#34; from langchain_core.runnables import RunnableLambda full_chain = router | RunnableLambda(choose_route) full_chain.invoke({\u0026#34;question\u0026#34;: question}) Semantic routing # code from langchain.utils.math import cosine_similarity from langchain_core.output_parsers import StrOutputParser from langchain_core.prompts import PromptTemplate from langchain_core.runnables import RunnableLambda, RunnablePassthrough from langchain_openai import ChatOpenAI, OpenAIEmbeddings # Two prompts physics_template = \u0026#34;\u0026#34;\u0026#34;You are a very smart physics professor. \\ You are great at answering questions about physics in a concise and easy to understand manner. \\ When you don\u0026#39;t know the answer to a question you admit that you don\u0026#39;t know. Here is a question: {query}\u0026#34;\u0026#34;\u0026#34; math_template = \u0026#34;\u0026#34;\u0026#34;You are a very good mathematician. You are great at answering math questions. \\ You are so good because you are able to break down hard problems into their component parts, \\ answer the component parts, and then put them together to answer the broader question. Here is a question: {query}\u0026#34;\u0026#34;\u0026#34; # Embed prompts embeddings = OpenAIEmbeddings() prompt_templates = [physics_template, math_template] prompt_embeddings = embeddings.embed_documents(prompt_templates) # Route question to prompt def prompt_router(input): # Embed question query_embedding = embeddings.embed_query(input[\u0026#34;query\u0026#34;]) # Compute similarity similarity = cosine_similarity([query_embedding], prompt_embeddings)[0] most_similar = prompt_templates[similarity.argmax()] # Chosen prompt print(\u0026#34;Using MATH\u0026#34; if most_similar == math_template else \u0026#34;Using PHYSICS\u0026#34;) return PromptTemplate.from_template(most_similar) chain = ( {\u0026#34;query\u0026#34;: RunnablePassthrough()} | RunnableLambda(prompt_router) | ChatOpenAI() | StrOutputParser() ) print(chain.invoke(\u0026#34;What\u0026#39;s a black hole\u0026#34;)) ã€åŸºäºembeddingçš„ç›¸ä¼¼åº¦åŒ¹é…ã€‘\nå‚è€ƒ # Routing in RAG-Driven Applications\nSematic router è®©LLMæ›´åŠ å¿«é€Ÿåšå‡ºå†³ç­– V\nsemantic-router Repo git\nsemantic-router doc\nä¸€æ–‡è¯¦çœ‹Langchainæ¡†æ¶ä¸­çš„RAGå¤šé˜¶æ®µä¼˜åŒ–ç­–ç•¥ï¼šä»é—®é¢˜è½¬æ¢åˆ°æŸ¥è¯¢è·¯ç”±å†åˆ°ç”Ÿæˆä¼˜åŒ–\nrag-from-scratch Repo git\nRAG(æ£€ç´¢å¢å¼ºï¼‰ ä»å…¥é—¨åˆ°ç²¾é€š è·¯ç”±ï¼ˆrouting) V\n"},{"id":39,"href":"/www6vAIGC/docs/Agent/Multi-agent/MultiAgentsPractice/","title":"(å®æˆ˜)LangGraph","section":"Multi-agent *","content":"\nLangGraph [1] # Agent Supervisor # Agent Supervisor Repo git\nMulti Agent Collaboration # Basic Multi-agent Collaboration git\nHierarchical Agent Teams # Hierarchical Agent Teams git\nå‚è€ƒ # LangGraph # LangGraph: Multi-Agent Workflows LangGraphï¼šMulti-Agent å®æˆ˜ V "},{"id":40,"href":"/www6vAIGC/docs/Agent/Multi-agent/MultiAgentsFail/","title":"Multi-Agent  Fail +","section":"Multi-agent *","content":" Multi-Agent Fail # Multi-Agent Fail\n"},{"id":41,"href":"/www6vAIGC/docs/RAG/Overview/RAGModularRAG/","title":"(åŸç†)Modular RAG +","section":"Overview","content":"\nModular RAG # (åŸç†)Modular RAG\n"},{"id":42,"href":"/www6vAIGC/docs/DocumentAI/MinerU/","title":"MinerU","section":"æ–‡æ¡£æ™ºèƒ½","content":" è®ºæ–‡ # è®ºæ–‡åœ°å€\nMinerU: An Open-Source Solution for Precise Document Content Extraction\nå¼€æºåœ°å€\nhttps://github.com/opendatalab/MinerU git\nonline demo\nhttps://www.modelscope.cn/studios/OpenDataLab/MinerU\nOverview # å¤æ‚æ–‡æ¡£è§£æ [10] # ã€everything2Markdownã€‘\nã€è¾¹ç•Œçš„åœ°æ–¹é”™çš„å¤š ã€‘\nã€å»å™ª - é¡µçœ‰ é¡µè„šã€‘\nå‚è€ƒ # æ·±å…¥æ‹†è§£ MinerU è§£æå¤„ç†æµç¨‹\nèš‚èšæ•°ç§‘AI Agent çŸ¥è¯†å·¥ç¨‹å®è·µ å…¶ä»– # å…³äºç›®å‰æ–‡æ¡£è½¬æ¢çš„ä¸€äº›è¯¯åŒºè®¤è¯†ï¼Œè®¨è®ºè§ç¤¾åŒºã€‚ ç›®å‰è¯´çš„mineruï¼Œocrç”¨çš„paddlepaddleï¼Œtableç”¨çš„rapd-tableï¼Œç‰ˆå¼åˆ†æç”¨çš„doclayoutï¼Œå…¬å¼ç”¨çš„unimernetï¼Œé˜…è¯»é¡ºåºç”¨çš„xycut/ layoutreaderï¼Œå…¬å¼æ£€æµ‹ç”¨çš„yoloï¼Œç„¶åä¸²èµ·æ¥ï¼Œå†™äº†å¾ˆå¤špostprocessï¼Œè¿™å°±æ˜¯miner-uï¼Œçº¯å¼€æºé›†æˆï¼›\nè€Œä¸æ˜¯é‡Œé¢è¯´çš„ä»€ä¹ˆå¤šæ¨¡æ€ï¼Œå¤šæ¨¡æ€è§£æèƒ½åŠ›ï¼Œæ”¯æŒå¤šç§æ ¼å¼çš„è½¬æ¢åŠé«˜ç²¾åº¦ OCRï¼Œä¸è¦ä¿¡ï¼Œå…¶éš¾çš„çš„æ˜¯åå¤„ç†çš„é€»è¾‘ã€‚\nocrç”¨æ¥æ€»å»ï¼Œç”¨çš„è¿˜æ˜¯PaddleOCRã€‚olmOCRï¼Œvaryï¼ŒgotOCR2.0è¿™äº›ï¼Œéƒ½æ˜¯åŸºäºå¤šæ¨¡æ€æ¨¡å‹å¾®è°ƒçš„æ–¹æ¡ˆï¼Œæ²¡æœ‰æœ¬è´¨åŒºåˆ«ã€‚\n"},{"id":43,"href":"/www6vAIGC/docs/RAG/%E6%A1%88%E4%BE%8B/RAGBaichuan/","title":"(åŸç†)RAG Baichuanæ¡ˆä¾‹","section":"æ¡ˆä¾‹","content":"\nBaichuan RAG[1] # å€Ÿé‰´äº†Metaçš„CoVeæŠ€æœ¯ è‡ªç ”çš„TSFï¼ˆThink-Step Further)æŠ€æœ¯ çŒœæµ‹å…¶æœ¬è´¨åº”è¯¥æ˜¯å¯¹Step-back promptingæ–¹æ³•çš„æ”¹è‰¯ è‡ªç ”äº†Baichuan-Text-Embeddingå‘é‡æ¨¡å‹ æ··åˆæ£€ç´¢ å‘é‡æ£€ç´¢ä¸ç¨€ç–æ£€ç´¢å¹¶è¡Œçš„ self-Critique æ€»ç»“[2] # **å¤šè½®é—®ç­”ç­‰åœºæ™¯çš„å¬å›å’Œä¼ ç»Ÿæœç´¢å¼•æ“çš„å¬å›åˆ†å¸ƒè¿˜ä¸å¤ªä¸€æ ·ã€‚**ç™¾å·å€ŸåŠ©å­é—®é¢˜æ£€ç´¢æ•ˆæœæ›´é«˜çš„ç‰¹ç‚¹ï¼Œå¯¹åŸå§‹å¤æ‚é—®é¢˜è¿›è¡Œæ‹†è§£ã€æ‹“å±•æ¥è§£å†³å¤æ‚é—®é¢˜æ£€ç´¢è´¨é‡åå·®çš„é—®é¢˜ã€‚ **å¯¹äºæ²¡è§è¿‡çš„è¯­æ–™ç›´æ¥ç”¨å‘é‡æ£€ç´¢çš„ç»“æœå¯èƒ½ä¸å¤ªç†æƒ³ã€‚**ç™¾å·åœ¨å¤§é‡è¯­æ–™ä¸Šåˆ©ç”¨æ— ç›‘ç£æ–¹æ³•è®­ç»ƒembeddingæ¨¡å‹æ¥ä¼˜åŒ–æ•ˆæœã€‚è€Œè¡Œä¸šå¤§æ¨¡å‹æ›´å€¾å‘äºç§æœ‰çš„æ•°æ®ï¼Œè¦æå‡ç§æœ‰æ•°æ®çš„è®­ç»ƒæ•ˆæœè¿˜å¾—ç»§ç»­åœ¨ç§æœ‰åŒ–æ•°æ®ä¸Šè®­ç»ƒæ•ˆæœä¼šæ›´ä½³ã€‚ **Queryæ‹“å±• + å¤šè·¯å¬å› + Rerank + self-Critiqueå¯èƒ½æ˜¯ç°é˜¶æ®µæ¯”è¾ƒå¥½çš„ä¸€ç§RAGæ–¹å¼ï¼Œä½†æ˜¯å…¶ä¹Ÿä¼šå¸¦æ¥æ›´å¤šæˆæœ¬ã€‚**æ€»ä½“æ€è·¯æœ‰ç‚¹åƒReAct[3]ç³»åˆ—çš„è¿›é˜¶ç‰ˆæœ¬ï¼Œå…¶åœ¨æœç´¢ä¾§å’Œç­”æ¡ˆä¿®æ­£ä¾§éƒ½åšäº†æ›´å¤šçš„ä¸€äº›å·¥ä½œæ¥ä¼˜åŒ–å®é™…æ•ˆæœã€‚å…¶ç¼ºç‚¹æ˜¯éœ€è¦å¤šæ¬¡è°ƒç”¨å¤§æ¨¡å‹ï¼Œä¼šå¸¦æ¥é¢å¤–çš„æˆæœ¬ï¼ŒçœŸå®çº¿ä¸Šæ˜¯å¦é‡‡ç”¨è¿™ç§ç­–ç•¥è¿˜æœ‰å¾…éªŒè¯ã€‚ å‚è€ƒ # å¤§æ¨¡å‹RAGé—®ç­”è¡Œä¸šæœ€ä½³æ¡ˆä¾‹åŠå¾®è°ƒã€æ¨ç†åŒé˜¶æ®µå®ç°æ¨¡å¼ï¼šåŸºäºæ¨¡å—åŒ–(Modular)RAGè‡ªå®šä¹‰RAG Flow\nç™¾å·æ™ºèƒ½RAGæ–¹æ¡ˆæ€»ç»“ï¼šæœç´¢å‡ºç”Ÿçš„ç™¾å·æ™ºèƒ½å¤§æ¨¡å‹RAGçˆ¬å‘ä¹‹è·¯\n1xx. LLM/ç™¾å·Baichuan2-53Bæœç´¢å¢å¼º-å¼€æ”¾API\n1xx. å¤§æ¨¡å‹+æœç´¢æ„å»ºå®Œæ•´æŠ€æœ¯æ ˆï¼Œç™¾å·æ™ºèƒ½ç”¨æœç´¢å¢å¼ºç»™ä¼ä¸šå®šåˆ¶åŒ–ä¸‹äº†ä¸€å‰‚ã€ŒçŒ›è¯ã€\n1xx. ç™¾å·æ™ºèƒ½RAGæ–¹æ¡ˆæ€»ç»“ï¼šæœç´¢å‡ºç”Ÿçš„ç™¾å·æ™ºèƒ½å¤§æ¨¡å‹RAGçˆ¬å‘ä¹‹è·¯\n"},{"id":44,"href":"/www6vAIGC/docs/FineTuning/PEFT/Soft-Prompt/PEFTPtuning/","title":"P-Tuning","section":"Soft Prompt","content":"\nP-Tuning[2] # P-Tuning çš„åˆ›æ–°ä¹‹å¤„åœ¨äºå°†æç¤ºï¼ˆPromptï¼‰è½¬åŒ–ä¸ºå¯å­¦ä¹ çš„åµŒå…¥å±‚ï¼ˆEmbedding Layerï¼‰ æ¶æ„ # ä¸€ä¸ªå…³äºâ€œThe capital of Britain is [MASK]â€ ç¤ºä¾‹ï¼š\nè“è‰²æ˜¯ä¸Šä¸‹æ–‡ â€œBritainâ€ çº¢è‰²æ˜¯ç›®æ ‡å•è¯ â€œ[MASK]â€ï¼Œ æ©™è‰²åŒºåŸŸæ˜¯æç¤ºè¯ã€‚ ä¼ ç»Ÿæ–¹å¼ ä¸ P-Tuning å¯¹æ¯”ï¼š\nåœ¨ï¼ˆaï¼‰ä¸­ï¼Œæç¤ºç”Ÿæˆå™¨åªæ¥æ”¶ç¦»æ•£å¥–åŠ±ï¼› åœ¨ï¼ˆbï¼‰ä¸­ï¼Œè¿ç»­çš„æç¤ºåµŒå…¥ï¼ˆPrompt Embeddingï¼‰ å’Œ**æç¤ºç¼–ç å™¨ï¼ˆPrompt Encoderï¼‰**ä»¥å¯å¾®çš„æ–¹å¼è¿›è¡Œ ä¼˜åŒ–ã€‚ P-Tuning v2[2] # èƒŒæ™¯ # ä¹‹å‰çš„æ–¹æ³•åœ¨ä»¥ä¸‹ä¸¤æ–¹é¢æœ‰æ‰€é™åˆ¶ï¼š â€¢ æ¨¡å‹è§„æ¨¡å·®å¼‚ï¼šåœ¨å¤§å‹é¢„è®­ç»ƒæ¨¡å‹ä¸­ï¼ŒPrompt Tuning å’Œ P-Tuning èƒ½å–å¾—ä¸å…¨é¢å¾®è°ƒç›¸ä¼¼çš„æ•ˆæœï¼Œä½†åœ¨å‚æ•°è¾ƒå°‘ çš„æ¨¡å‹ä¸Šåˆ™è¡¨ç°ä¸ä½³ã€‚ â€¢ ä»»åŠ¡ç±»å‹å·®å¼‚ï¼šæ— è®ºæ˜¯ Prompt Tuning è¿˜æ˜¯ P-Tuningï¼Œ åœ¨åºåˆ—æ ‡æ³¨ä»»åŠ¡ä¸Šçš„è¡¨ç°éƒ½è¾ƒå·®ã€‚\nç›®çš„ # P-Tuning v2 æ—¨åœ¨ä½¿æç¤ºè°ƒæ•´ï¼ˆPrompt Tuningï¼‰åœ¨ä¸åŒè§„æ¨¡çš„é¢„è®­ç»ƒæ¨¡å‹ä¸Šï¼Œé’ˆå¯¹å„ç§ä¸‹æ¸¸ä»»åŠ¡éƒ½èƒ½è¾¾åˆ°ç±»ä¼¼å…¨é¢å¾®è°ƒï¼ˆFine-tuningï¼‰çš„æ•ˆæœã€‚\næ¶æ„ [1] # åœ¨æ¯ä¸€å±‚éƒ½åŠ å…¥äº†Prompts tokens ä½œä¸ºè¾“å…¥, è€Œä¸æ˜¯ä»…ä»…åŠ åœ¨è¾“å…¥å±‚\næ€»ç»“ # P-tuning å’Œ Prompt Tuning ä»…ä»…æ›´æ–°ç¬¬ä¸€ä¸ªTransformerå±‚ Prefix tuning å’Œ P-Tuning v2 é’ˆå¯¹æ¯ä¸€ä¸ªTransformer å±‚è¿›è¡Œæ›´æ–° Prefix tuning å’Œ P-Tuning éœ€è¦é‡æ–°å‚æ•°åŒ–(PromptEncoder), è€ŒPrompt Tuning å’Œ P-Tuning v2åˆ™ä¸éœ€è¦ ç®€å•å°†P-Tuningè®¤ä¸ºæ˜¯é’ˆå¯¹ Prompt Tuningçš„æ”¹è¿›, P-Tuning v2 è®¤ä¸ºæ˜¯é’ˆå¯¹ Prefix tuning çš„æ”¹è¿›. å‚è€ƒ # å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†åŠå®è·µ pdf å¦‚ä½•é«˜æ•ˆå¾®è°ƒå¤§æ¨¡å‹ï¼ŸæŠ€æœ¯åŸç†ä¸æœ€ä½³å®è·µæ­ç§˜ï¼ V ***\nã€Š3-å¤§æ¨¡å‹å¾®è°ƒæŠ€æœ¯æ­ç§˜-PEFTã€‹ Aiå¤§æ¨¡å‹å¾®è°ƒ\n"},{"id":45,"href":"/www6vAIGC/docs/RAG/Pattern/Multimodal-RAG/RAGMultimodalPractice/","title":"(å®æˆ˜)å¤šæ¨¡æ€ RAG","section":"Multimodal RAG","content":"\nå¤šæ¨¡æ€RAG-å¤šå‘é‡æ£€ç´¢å™¨ [10][11] # semi-structured (tables + text) RAG [20] # åˆ†æpdfä¸­è¡¨æ ¼\nmulti-modal (text + tables + images) RAG [13] # åˆ†æPDFä¸­å›¾ç‰‡\nOption 1 [åŸºäºCLIP] [23] [30][32][33]\nUse multimodal embeddings (such as CLIP) to embed images and text Retrieve both using similarity search Pass raw images and text chunks to a multimodal LLM for answer synthesis\n{é€‰é¡¹1ï¼šå¯¹æ–‡æœ¬å’Œè¡¨æ ¼ç”Ÿæˆsummaryï¼Œç„¶ååº”ç”¨å¤šæ¨¡æ€embeddingæ¨¡å‹æŠŠæ–‡æœ¬/è¡¨æ ¼summaryã€åŸå§‹å›¾ç‰‡è½¬åŒ–æˆembeddingå­˜å…¥å¤šå‘é‡æ£€ç´¢å™¨ã€‚å¯¹è¯æ—¶ï¼Œæ ¹æ®queryå¬å›åŸå§‹æ–‡æœ¬/è¡¨æ ¼/å›¾åƒã€‚ç„¶åå°†å…¶å–‚ç»™å¤šæ¨¡æ€LLMç”Ÿæˆåº”ç­”ç»“æœã€‚}[10] Option 2 [21]\nUse a multimodal LLM (such as GPT4-V, LLaVA, or FUYU-8b) to produce text summaries from images Embed and retrieve text Pass text chunks to an LLM for answer synthesis\nã€å°†å›¾ç‰‡è½¬æˆæ‘˜è¦ï¼Œå’Œå…¶ä»–æ–‡æœ¬ä¿¡æ¯æ•´åˆåœ¨æ–‡æœ¬ç²’åº¦è¿›è¡Œæ£€ç´¢ã€‘[12]\n{é€‰é¡¹2ï¼šé¦–å…ˆåº”ç”¨å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆGPT4-Vã€LLaVAã€FUYU-8bï¼‰ç”Ÿæˆå›¾ç‰‡summaryã€‚ç„¶åå¯¹æ–‡æœ¬/è¡¨æ ¼/å›¾ç‰‡summaryè¿›è¡Œå‘é‡åŒ–å­˜å…¥å¤šå‘é‡æ£€ç´¢å™¨ä¸­ã€‚å½“ç”Ÿæˆåº”ç­”çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ä¸å…·å¤‡æ—¶ï¼Œå¯æ ¹æ®queryå¬å›åŸå§‹æ–‡æœ¬/è¡¨æ ¼+å›¾ç‰‡summaryã€‚}[10] Option 3 [24] [31][34]\nUse a multimodal LLM (such as GPT4-V, LLaVA, or FUYU-8b) to produce text summaries from images Embed and retrieve image summaries with a reference to the raw image Pass raw images and text chunks to a multimodal LLM for answer synthesis ã€å®é™…æ¨¡å‹è¾“å…¥ä½¿ç”¨çš„æ˜¯å›¾ç‰‡ã€‘\nã€å›¾ç‰‡æ¦‚è¦ä¾ç„¶æ˜¯ç”¨äºæ£€ç´¢ï¼ˆGPT-4Vï¼ŒLLaVAï¼ŒFUYU-8bï¼‰ã€‘[12]\n{é€‰é¡¹3ï¼šå‰ç½®é˜¶æ®µåŒé€‰é¡¹2ç›¸åŒã€‚å¯¹è¯æ—¶ï¼Œæ ¹æ®queryå¬å›åŸå§‹æ–‡æœ¬/è¡¨æ ¼/å›¾ç‰‡ã€‚æ„é€ å®Œæ•´Promptï¼Œè®¿é—®å¤šæ¨¡æ€å¤§æ¨¡å‹ç”Ÿæˆåº”ç­”ç»“æœã€‚}[10] private multi-modal (text + tables + images) RAG [22] # ç»„ä»¶ # pdfè§£æ\nunstructured store\nMultiVectorRetriever - å…ƒæ•°æ®+æ•°æ® å‚è€ƒ # å®æˆ˜ # æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æœ‰ä»€ä¹ˆå¥½çš„ä¼˜åŒ–æ–¹æ¡ˆï¼Ÿ\nMulti-Vector Retriever for RAG on tables, text, and images ***\nåŸºäºå¤šå‘é‡æ£€ç´¢å™¨çš„å¤šæ¨¡æ€RAGå®ç°ï¼šç”¨äºè¡¨æ ¼ã€æ–‡æœ¬å’Œå›¾åƒ\nlangchainçš„multi model RAG-ä»¥å¤šæ¨¡æ€pdfæ–‡ä»¶ä¸ºä¾‹å­\nMulti-modal RAG on slide decks\n1xx. Using Multi-Modal LLMs page21\nnotebook # Semi_Structured_RAG notebook\nAdvanced-RAG semi_structured_data notebook {åŠç»“æ„åŒ–-è§£æpdfä¸­çš„è¡¨æ ¼ï¼Œ è¿è¡Œæ²¡é—®é¢˜ï¼Œèƒ½é—®è¡¨æ ¼ä¸­çš„æ•°æ®}\nSemi_structured_and_multi_modal_RAG notebook\nPrivate Semi-structured and Multi-modal RAG w/ LLaMA2 and LLaVA notebook {å¤šæ¨¡æ€- è§£æpdfä¸­çš„å›¾ç‰‡ è¿è¡Œæœ‰é—®é¢˜}\nPrivate Semi-structured and Multi-modal RAG w/ LLaMA2 and LLaVA notebook\nChroma multi-modal RAG notebook\nMulti-modal RAG notebook\ntemplate (å¤±æ•ˆäº†) # rag-multi-modal-local\nOpenCLIP(image embedding) + bakllava(answer synthesis) rag-multi-modal-mv-local\nbakllava(image summaries embedding) + bakllava (answer synthesis) rag-chroma-multi-modal\nOpenCLIP(image embedding) + GPT-4V (answer synthesis) rag-gemini-multi-modal\nOpenCLIP(image embedding) + Gemini(answer synthesis) rag-chroma-multi-modal-multi-vector\nGPT-4V(image summaries embedding) + GPT-4V (answer synthesis) llamaindex # 1xx. æœ´ç´ å¤šæ¨¡æ€RAGå¦‚ä½•å®ç°ï¼Ÿå…¼çœ‹RAGä¸Šä¸‹æ–‡è¿‡æ»¤æ–¹æ¡ˆFILCOåŠ202402å¤§æ¨¡å‹æ—©æŠ¥ 1xx. Advanced Multi-Modal Retrieval using GPT4V and Multi-Modal Index/Retriever\n1xx. Multimodal RAG pipeline with LlamaIndex and Neo4j\n1xx. neo4j_llama_multimodal.ipynb git\n"},{"id":46,"href":"/www6vAIGC/docs/FineTuning/Instruct-Tuning/InstructTuningSurvey/","title":"(Survey)Instruct Tuning","section":"Instruct Tuning","content":"\nå‚è€ƒ # 1xx. å¤§è¯­è¨€æ¨¡å‹æŒ‡ä»¤å¾®è°ƒç»¼è¿° ä¸€ç¯‡å…³äºLLMæŒ‡ä»¤å¾®è°ƒçš„ç»¼è¿°\n1xx. [è®ºæ–‡]å¤§è¯­è¨€æ¨¡å‹æŒ‡ä»¤è°ƒä¼˜ç»¼è¿°\n1xx. Paperï¼šã€ŠInstruction Tuning for Large Language Models: A Surveyâ€”å¤§å‹è¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤è°ƒä¼˜çš„ç»¼è¿°ã€‹ç¿»è¯‘ä¸è§£è¯»\n1xx. Instruction Tuning for Large Language Models: A Survey git\nã€å‰é¢å¤§éƒ¨åˆ†æ˜¯Instruct-Tuningï¼Œ ä¸­é—´ä¸€éƒ¨åˆ†æ˜¯Multi-modality Instruction Tuningã€‘\n"},{"id":47,"href":"/www6vAIGC/docs/RAG/Pattern/Agentic-RAG/RAGSelfReflective/","title":"(åŸç†|å®æˆ˜)Self-Reflective RAG","section":"Agentic RAG","content":"\nCognitive Architecture [2] # Cognitive architectures for RAG [1] CRAG # è®ºæ–‡ # Corrective Retrieval Augmented Generation Figure 2\nå®ç°[10] # Corrective-RAG (CRAG) is a strategy for RAG that incorporates self-reflection / self-grading on retrieved documents.\nIn the paper here, a few steps are taken:\nIf at least one document exceeds the threshold for relevance, then it proceeds to generation Before generation, it performs knowledge refinement This partitions the document into \u0026ldquo;knowledge strips\u0026rdquo; It grades each strip, and filters our irrelevant ones If all documents fall below the relevance threshold or if the grader is unsure, then the framework seeks an additional datasource It will use web search to supplement retrieval We will implement some of these ideas from scratch using LangGraph:\nLet\u0026rsquo;s skip the knowledge refinement phase as a first pass. This can be added back as a node, if desired. If any documents are irrelevant, let\u0026rsquo;s opt to supplement retrieval with web search. We\u0026rsquo;ll use Tavily Search for web search. Let\u0026rsquo;s use query re-writing to optimize the query for web search. Self-RAG # è®ºæ–‡ # SELF-RAG: LEARNING TO RETRIEVE, GENERATE, AND CRITIQUE THROUGH SELF-REFLECTION Figure 1\nåŸç† [20] # Self-RAG åˆ™æ˜¯æ›´åŠ ä¸»åŠ¨å’Œæ™ºèƒ½çš„å®ç°æ–¹å¼ï¼Œä¸»è¦æ­¥éª¤æ¦‚æ‹¬å¦‚ä¸‹ï¼š\nåˆ¤æ–­æ˜¯å¦éœ€è¦é¢å¤–æ£€ç´¢äº‹å®æ€§ä¿¡æ¯ï¼ˆretrieve on demandï¼‰ï¼Œä»…å½“æœ‰éœ€è¦æ—¶æ‰å¬å› å¹³è¡Œå¤„ç†æ¯ä¸ªç‰‡æ®µï¼šç”Ÿäº§prompt+ä¸€ä¸ªç‰‡æ®µçš„ç”Ÿæˆç»“æœ ä½¿ç”¨åæ€å­—æ®µ(Reflection tokens)ï¼Œæ£€æŸ¥è¾“å‡ºæ˜¯å¦ç›¸å…³ï¼Œé€‰æ‹©æœ€ç¬¦åˆéœ€è¦çš„ç‰‡æ®µï¼› å†é‡å¤æ£€ç´¢ ç”Ÿæˆç»“æœä¼šå¼•ç”¨ç›¸å…³ç‰‡æ®µï¼Œä»¥åŠè¾“å‡ºç»“æœæ˜¯å¦ç¬¦åˆè¯¥ç‰‡æ®µï¼Œä¾¿äºæŸ¥è¯äº‹å®ã€‚ å®ç°[21] # Self-RAG is a strategy for RAG that incorporates self-reflection / self-grading on retrieved documents and generations.\nIn the paper, a few decisions are made:\nShould I retrieve from retriever, R - Input: x (question) OR x (question), y (generation) Decides when to retrieve D chunks with R Output: yes, no, continue Are the retrieved passages D relevant to the question x - Input: (x (question), d (chunk)) for d in D d provides useful information to solve x Output: relevant, irrelevant Are the LLM generation from each chunk in D is relevant to the chunk (hallucinations, etc) - Input: x (question), d (chunk), y (generation) for d in D All of the verification-worthy statements in y (generation) are supported by d Output: {fully supported, partially supported, no support The LLM generation from each chunk in D is a useful response to x (question) - Input: x (question), y (generation) for d in D y (generation) is a useful response to x (question). Output: {5, 4, 3, 2, 1} We will implement some of these ideas from scratch using LangGraph.\nå‚è€ƒ # Self-Reflective RAG with LangGraph ***\nOpenAI\u0026rsquo;s Bet on a Cognitive Architecture\n1xx. å†™çš„å¤ªé€šé€äº†ï¼å¤§æ¨¡å‹è‡ªçœå¼ RAG ä¸ LangGraph çš„å®è·µï¼\nCRAG # Corrective RAG (CRAG) langgraph git 1xx. ã€ç¤¾åŒºç¬¬åä¸‰è®²ã€‘ è€åˆ˜è¯´NLPçº¿ä¸Šäº¤æµ\nSelf-RAG # NLPï¼ˆå»¿ä¸€ï¼‰ï¼šä» RAG åˆ° Self-RAG â€”â€” LLM çš„çŸ¥è¯†å¢å¼º ***\nSelf-RAG langGraph git\n1xx. original implementation of Self-RAG\n"},{"id":48,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Planning/COT/","title":"(åŸç†)COT","section":"Planning","content":"\nCoT[4] # CoT(Chain of Thought)\nCoT-SC(Self Consistency) ToT(Tree of Thoughts) åˆ†ä¸ºäº†Thought Decompositionï¼ŒThought Generatorï¼ŒState Evaluatorï¼ŒSearch algorithms\nGoT(Graph of Thoughts)\nAoT(Algorithm of Thoughts)\nå‚è€ƒ # 2023å¹´èƒ½å¤Ÿè§£å†³å¤æ‚é—®é¢˜çš„æ€ç»´é“¾æŠ€æœ¯ï¼šCotï¼ŒToTï¼ŒGoTï¼ŒAoT 1xx. CoT-Reasoning-Survey 1xx. å¤§æ¨¡å‹COTæ€ç»´é“¾æ¨ç†çš„å‡ ä¸ªå…³é”®é—®é¢˜ï¼šä»è¯„æµ‹åŸºå‡†ã€ç»“æ„å˜ä½“åˆ°å¢å¼ºæ–¹æ¡ˆçš„ç³»ç»Ÿç»¼è¿° 1xx. å¤§æ¨¡å‹æ€ç»´é“¾æ¨ç†çš„ç»¼è¿°ï¼šè¿›å±•ã€å‰æ²¿å’Œæœªæ¥\n"},{"id":49,"href":"/www6vAIGC/docs/Application/NL2SQL/survey/","title":"(survey)NL2SQL","section":"NL2SQL","content":" å‚è€ƒ # Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL *** A Survey on Employing Large Language Models for Text-to-SQL Tasks *** NL2SQL_Handbook NL2SQLï¼ˆæ–‡æœ¬åˆ° SQLï¼‰æŠ€æœ¯ï¼Œhttps://github.com/HKUSTDial/NL2SQL_Handbookï¼Œé‡Œé¢æœ‰å¸¸ç”¨æ–¹æ¡ˆã€‚æ„Ÿå…´è¶£çš„å¯å…³æ³¨ã€‚ *** "},{"id":50,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/RAGPractice/","title":"(å®æˆ˜)RAG","section":"å®æˆ˜ *","content":"\nData processing[17] # é•¿æ–‡æœ¬ å˜æˆ QA pair\nè§„åˆ™åŒ¹é… åˆ©ç”¨LLMæŠ½å– äººå·¥å¤„ç† åŒ»ç–—é—®ç­”RAG[20] # æ¶æ„ # chuck # æ®µè½ å¥å­ token\næ•°æ®æ ¼å¼ # {\u0026ldquo;id\u0026rdquo;: xxx, \u0026ldquo;ç—…æƒ…æè¿°\u0026rdquo;: \u0026ldquo;xxx\u0026rdquo;, \u0026ldquo;æ²»ç–—æ–¹æ¡ˆ\u0026rdquo;: \u0026ldquo;xxx\u0026rdquo; }\næ”¹å†™query # HyDE RAG Fusion -\u0026gt; Generate Similar query ç”¨æˆ·çš„æŸ¥è¯¢ä¸ç²¾å‡†ï¼Œè¦æ‰©å……query, ç”¨å¤§æ¨¡å‹æ”¹å†™ å¬å›æ¨¡å‹ # bertæ¨¡å‹\nsbert 2ä¸ªbertæ¨¡å‹ï¼Œå…±äº«å‚æ•°ï¼Œs1,s2å‘é‡åŒ–ååšç›¸ä¼¼åº¦è®¡ç®— é€Ÿåº¦å¿« ç›¸ä¼¼åº¦ æ¬§å¼è·ç¦» åœ¨ç™¾ä¸‡è¯­æ–™ä¸Šè®­ç»ƒ è¯­æ–™æ ¼å¼\n[s1][s2] 0 - æ— å…³ [s1][s2] 1-ç±»ä¼¼ æ ¹æ®query, å¬å›idå’Œvalueæ•´æ¡è®°å½•\næ’åºæ¨¡å‹ # bertæ¨¡å‹ 1ä¸ªbertæ¨¡å‹ é€Ÿåº¦æ…¢ æ ¼å¼ query[sep]s2 -\u0026gt; ç»è¿‡softmaxï¼Œäº§ç”Ÿ2åˆ†ç±»ï¼Œ0-1 ä¹Ÿè¦è®­ç»ƒ åŒå¬å›æ¨¡å‹è®­ç»ƒæ–¹å¼ ç´¢å¼•æ–¹å¼ # æ ‘ç´¢å¼• çŸ¥è¯†å›¾è°±çš„ç´¢å¼• å¤§æ¨¡å‹ # ç»¼åˆå½’çº³çš„ä½œç”¨ å‚è€ƒ # xxx # \u0026laquo;å¤§æ¨¡å‹ç»“åˆ RAG æ„å»ºå®¢æœåœºæ™¯è‡ªåŠ¨é—®ç­”ç³»ç»Ÿ\u0026raquo; NVIDIAå¤§æ¨¡å‹æ—¥ç³»åˆ—æ´»åŠ¨ åŒ»ç–—é—®ç­” # åŸºäºç™¾ä¸‡è¯­æ–™çš„åŒ»ç–—RAGé¡¹ç›® v "},{"id":51,"href":"/www6vAIGC/docs/Langchain/Retrievers/","title":"Retrievers","section":"Langchain","content":"\nLangchain Retrievers[10] # MultiQueryRetriever # The MultiQueryRetriever automates the process of prompt tuning by using an LLM to generate multiple queries from different perspectives for a given user input query.\nContextual compression # Ensemble Retriever # The EnsembleRetriever takes a list of retrievers as input and ensemble the results of their get_relevant_documents() methods and rerank the results based on the Reciprocal Rank Fusion algorithm. The most common pattern is to combine a sparse retriever (like BM25) with a dense retriever (like embedding similarity), because their strengths are complementary. It is also known as â€œhybrid searchâ€.\nMultiVector Retriever # The methods to create multiple vectors per document include: - Smaller chunks: split a document into smaller chunks, and embed those (this is ParentDocumentRetriever). - Summary: create a summary for each document, embed that along with (or instead of) the document. - Hypothetical questions: create hypothetical questions that each document would be appropriate to answer, embed those along with (or instead of) the document.\nParent Document Retriever # chunks of data\nSelf-querying # This allows the retriever to not only use the user-input query for semantic similarity comparison with the contents of stored documents but to also extract filters from the user query on the metadata of stored documents and to execute those filters.\nLangchian Retriever[10] # Name Index Type Uses an LLM When to Use Description Vectorstore Vectorstore No If you are just getting started and looking for something quick and easy. This is the simplest method and the one that is easiest to get started with. It involves creating embeddings for each piece of text. ParentDocument Vectorstore + Document Store No If your pages have lots of smaller pieces of distinct information that are best indexed by themselves, but best retrieved all together. This involves indexing multiple chunks for each document. Then you find the chunks that are most similar in embedding space, but you retrieve the whole parent document and return that (rather than individual chunks). Multi Vector Vectorstore + Document Store Sometimes during indexing If you are able to extract information from documents that you think is more relevant to index than the text itself. This involves creating multiple vectors for each document. Each vector could be created in a myriad of ways - examples include summaries of the text and hypothetical questions. Self Query Vectorstore Yes If users are asking questions that are better answered by fetching documents based on metadata rather than similarity with the text. This uses an LLM to transform user input into two things: (1) a string to look up semantically, (2) a metadata filer to go along with it. This is useful because oftentimes questions are about the METADATA of documents (not the content itself). Contextual Compression Any Sometimes If you are finding that your retrieved documents contain too much irrelevant information and are distracting the LLM. This puts a post-processing step on top of another retriever and extracts only the most relevant information from retrieved documents. This can be done with embeddings or an LLM. Time-Weighted Vectorstore Vectorstore No If you have timestamps associated with your documents, and you want to retrieve the most recent ones This fetches documents based on a combination of semantic similarity (as in normal vector retrieval) and recency (looking at timestamps of indexed documents) Multi-Query Retriever Any Yes If users are asking questions that are complex and require multiple pieces of distinct information to respond This uses an LLM to generate multiple queries from the original one. This is useful when the original query needs pieces of information about multiple topics to be properly answered. By generating multiple queries, we can then fetch documents for each of them. Ensemble Any No If you have multiple retrieval methods and want to try combining them. This fetches documents from multiple retrievers and then combines them. Long-Context Reorder Any No If you are working with a long-context model and noticing that it\u0026rsquo;s not paying attention to information in the middle of retrieved documents. This fetches documents from an underlying retriever, and then reorders them so that the most similar are near the beginning and end. This is useful because it\u0026rsquo;s been shown that for longer context models they sometimes don\u0026rsquo;t pay attention to information in the middle of the context window. å‚è€ƒ # retrievers "},{"id":52,"href":"/www6vAIGC/docs/FineTuning/%E5%AE%9E%E8%B7%B5/FineTuningWhen/","title":"(åŸç†)Fine-Tuning æ—¶æœº","section":"å®è·µ *","content":"\nä½•æ—¶è¿›è¡Œå¾®è°ƒ[1] # è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ä»¥é€šè¿‡è‡³å°‘ä¸¤ç§æ–¹å¼å­¦ä¹ æ–°çŸ¥è¯†ï¼šæƒé‡æ›´æ–°ï¼ˆä¾‹å¦‚é¢„è®­ç»ƒæˆ–å¾®è°ƒï¼‰æˆ–æç¤ºï¼ˆä¾‹å¦‚æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ŒRAGï¼‰ã€‚æ¨¡å‹çš„æƒé‡å°±åƒé•¿æœŸè®°å¿†ï¼Œè€Œæç¤ºå°±åƒçŸ­æœŸè®°å¿†ã€‚è¿™ä¸ªOpenAI Cookbookç»™å‡ºäº†ä¸€ä¸ªæœ‰ç”¨çš„æ¯”å–»ï¼šå½“ä½ å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒæ—¶ï¼Œå°±åƒæ˜¯åœ¨ç¦»è€ƒè¯•è¿˜æœ‰ä¸€å‘¨çš„æ—¶å€™å‡†å¤‡å¤ä¹ ã€‚å½“ä½ é€šè¿‡æç¤ºï¼ˆä¾‹å¦‚æ£€ç´¢ï¼‰å‘æç¤ºä¸­æ’å…¥çŸ¥è¯†æ—¶ï¼Œå°±åƒæ˜¯åœ¨æœ‰å¼€æ”¾ç¬”è®°çš„è€ƒè¯•ä¸­ã€‚\nåŸºäºè¿™ä¸€ç‚¹ï¼Œä¸å»ºè®®ä½¿ç”¨å¾®è°ƒæ¥æ•™æˆLLMæ–°çš„çŸ¥è¯†æˆ–äº‹å®å›å¿†ï¼›OpenAIçš„John Schulmanåœ¨ä¸€æ¬¡è®²è¯ä¸­æŒ‡å‡ºï¼Œå¾®è°ƒå¯èƒ½ä¼šå¢åŠ è™šæ„ã€‚å¾®è°ƒæ›´é€‚åˆæ•™æˆä¸“é—¨çš„ä»»åŠ¡ï¼Œä½†åº”ä¸æç¤ºæˆ–RAGç›¸å¯¹æ¯”ã€‚æ­£å¦‚è¿™é‡Œæ‰€è®¨è®ºçš„ï¼Œå¯¹äºå…·æœ‰ä¸°å¯Œç¤ºä¾‹å’Œ/æˆ–ç¼ºä¹ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›çš„LLMæ¥è¯´ï¼Œå¾®è°ƒå¯¹äºå®šä¹‰æ˜ç¡®çš„ä»»åŠ¡å¯èƒ½æ˜¯æœ‰å¸®åŠ©çš„ã€‚è¿™ç¯‡Anyscaleåšå®¢å¾ˆå¥½åœ°æ€»ç»“äº†è¿™äº›è§‚ç‚¹ï¼šå¾®è°ƒæ˜¯ä¸ºå½¢å¼è€Œéäº‹å®[3]ã€‚\nwhat [4] # è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ã€‚æˆ‘å¤§è‡´å°†å¾®è°ƒç±»æ¯”ä¸ºäººçš„ä¸“ä¸šçŸ¥è¯†ï¼š\nç”¨æ–‡å­—æè¿°ä¸€ä¸ªä»»åŠ¡ ~= é›¶æ ·æœ¬æç¤º ç»™å‡ºè§£å†³ä»»åŠ¡çš„ç¤ºä¾‹ ~= å°‘æ ·æœ¬æç¤º å…è®¸äººä»¬ç»ƒä¹ ä»»åŠ¡ ~= å¾®è°ƒ è€ƒè™‘åˆ°è¿™ä¸ªæ¯”å–»ï¼Œä»¤äººæƒŠå¥‡çš„æ˜¯æˆ‘ä»¬æœ‰äº†å¯ä»¥ä»…é€šè¿‡æç¤ºå°±èƒ½åœ¨è®¸å¤šä»»åŠ¡ä¸Šè¾¾åˆ°é«˜æ°´å¹³å‡†ç¡®æ€§çš„æ¨¡å‹ï¼Œä½†æˆ‘ä¹Ÿé¢„è®¡è¾¾åˆ°é¡¶çº§æ€§èƒ½å¯èƒ½éœ€è¦å¾®è°ƒï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰æ˜ç¡®å®šä¹‰çš„å…·ä½“ä»»åŠ¡çš„åº”ç”¨ä¸­ï¼Œåœ¨è¿™äº›ä»»åŠ¡ä¸­æˆ‘ä»¬å¯ä»¥æ”¶é›†å¤§é‡æ•°æ®å¹¶åœ¨å…¶ä¸Šè¿›è¡Œâ€œç»ƒä¹ â€ã€‚\nè¿™å¯èƒ½æ˜¯ä¸€ä¸ªéœ€è¦ç‰¢è®°çš„ç²—ç•¥å›¾æ™¯ã€‚å°å‹æ¨¡å‹æ— æ³•è¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œå¹¶ä¸”ä»æç¤ºå·¥ç¨‹ä¸­å—ç›Šç”šå°‘ï¼Œä½†æ ¹æ®ä»»åŠ¡çš„éš¾åº¦ï¼Œä»ç„¶æœ‰å¯èƒ½å°†å®ƒä»¬å¾®è°ƒä¸ºè¡¨ç°è‰¯å¥½çš„ä¸“å®¶ã€‚\néœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ‰€æœ‰è¿™äº›éƒ½è¿˜æ˜¯éå¸¸æ–°é¢–çš„ã€‚\nCommon use cases[2] # å¾®è°ƒå¯ä»¥æ”¹å–„ç»“æœçš„ä¸€äº›å¸¸è§ç”¨ä¾‹åŒ…æ‹¬ï¼š\nè®¾å®šé£æ ¼ã€è¯­æ°”ã€æ ¼å¼æˆ–å…¶ä»–å®šæ€§å› ç´  æé«˜ç”Ÿæˆæ‰€éœ€è¾“å‡ºçš„å¯é æ€§ çº æ­£æ— æ³•æŒ‰ç…§å¤æ‚æç¤ºè¦æ±‚æ‰§è¡Œçš„é—®é¢˜ ä»¥ç‰¹å®šæ–¹å¼å¤„ç†è®¸å¤šè¾¹ç¼˜æƒ…å†µ æ‰§è¡Œéš¾ä»¥ç”¨æç¤ºæ¸…æ™°è¡¨è¾¾çš„æ–°æŠ€èƒ½æˆ–ä»»åŠ¡ ä»è¾ƒé«˜å±‚é¢æ¥çœ‹ï¼Œè¿™äº›æƒ…å†µä¸‹å¾®è°ƒæ›´å®¹æ˜“å®ç°â€œå±•ç¤ºè€Œéå‘Šè¯‰â€çš„æ•ˆæœã€‚åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨å¦‚ä½•ä¸ºå¾®è°ƒè®¾ç½®æ•°æ®ä»¥åŠå„ç§ç¤ºä¾‹ï¼Œè¿™äº›ç¤ºä¾‹ä¸­å¾®è°ƒæ”¹å–„äº†åŸºçº¿æ¨¡å‹çš„æ€§èƒ½ã€‚\nå‚è€ƒ # Using LangSmith to Support Fine-tuning colab LANGCHAIN_API_KEY\nFine-tuning openai ***\nFine tuning is for form, not facts ***\nAndrej Karpathy twitter\n"},{"id":53,"href":"/www6vAIGC/docs/FineTuning/PEFT/FineTuningPEFT/","title":"(å®æˆ˜)PEFT æ¦‚è¿°","section":"PEFT *","content":"\nHuggingface PEFTä¸­çš„ä»»åŠ¡[1] # class TaskType(str, enum.Enum):\rSEQ_CLS = \u0026#34;SEQ_CLS\u0026#34; # 3. åºåˆ—åˆ†ç±»ä»»åŠ¡\rSEQ_2_SEQ_LM = \u0026#34;SEQ_2_SEQ_LM\u0026#34; # 2. æ¡ä»¶ç”Ÿæˆä»»åŠ¡\rCAUSAL_LM = \u0026#34;CAUSAL_LM\u0026#34; # 1. å› æœè¯­è¨€å»ºæ¨¡ä»»åŠ¡\rTOKEN_CLS = \u0026#34;TOKEN_CLS\u0026#34; # 4. Token åˆ†ç±»ä»»åŠ¡\rQUESTION_ANS = \u0026#34;QUESTION_ANS\u0026#34;\rFEATURE_EXTRACTION = \u0026#34;FEATURE_EXTRACTION\u0026#34; 1. å› æœè¯­è¨€å»ºæ¨¡ä»»åŠ¡ï¼ˆCausal Language Modelingï¼‰ # å› æœè¯­è¨€å»ºæ¨¡ä»»åŠ¡ï¼ˆCLMï¼‰ï¼Œåœ¨è¿™ç§å»ºæ¨¡æ–¹æ³•ä¸­ï¼Œæ¨¡å‹è¯•å›¾é¢„æµ‹ç»™å®šä¸Šä¸‹æ–‡ä¸­çš„ä¸‹ä¸€ä¸ªå•è¯ï¼Œè¯¥ä¸Šä¸‹æ–‡é€šå¸¸åŒ…æ‹¬åœ¨å½“å‰å•è¯ä¹‹å‰çš„æ‰€æœ‰å•è¯ã€‚\n2. æ¡ä»¶ç”Ÿæˆä»»åŠ¡ï¼ˆConditional Generationï¼‰ # æ¡ä»¶ç”Ÿæˆä»»åŠ¡ï¼ˆConditional Generationï¼‰ï¼Œæ ¹æ®ç»™å®šçš„è¾“å…¥ï¼ˆå¯èƒ½æ˜¯æ–‡æœ¬ã€å›¾ç‰‡ç­‰ï¼‰ç”Ÿæˆç¬¦åˆæ¡ä»¶çš„è¾“å‡ºã€‚ æ¡ä»¶ç”Ÿæˆçš„åº”ç”¨åŒ…æ‹¬ä½†ä¸é™äºæœºå™¨ç¿»è¯‘ã€æ–‡æœ¬æ‘˜è¦ã€å›¾åƒæè¿°ç­‰ã€‚è¿™äº›ä»»åŠ¡é€šå¸¸éœ€è¦æ¨¡å‹åœ¨è¾“å…¥å’Œè¾“å‡ºä¹‹é—´å»ºç«‹å¤æ‚çš„æ˜ å°„å…³ç³»ã€‚\nå› æœè¯­è¨€å»ºæ¨¡ä»»åŠ¡ vs. æ¡ä»¶ç”Ÿæˆä»»åŠ¡ å› æœè¯­è¨€å»ºæ¨¡ä¸»è¦å…³æ³¨äºç”Ÿæˆè¿è´¯ã€è‡ªç„¶çš„æ–‡æœ¬ï¼Œè€Œæ¡ä»¶ç”Ÿæˆå…³æ³¨äºç”Ÿæˆæ»¡è¶³ç‰¹å®šæ¡ä»¶æˆ–ä»»åŠ¡è¦æ±‚çš„æ–‡æœ¬ã€‚è¿™ä¸¤ç§å»ºæ¨¡æ–¹æ³•åœ¨æŸäº›åœºæ™¯ä¸‹å¯èƒ½ä¼šäº’ç›¸ä½¿ç”¨å’Œç»“åˆï¼Œä»¥å®ç°æ›´å¤æ‚çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚\n3. åºåˆ—åˆ†ç±»ä»»åŠ¡ï¼ˆSequence Classificationï¼‰ # åºåˆ—åˆ†ç±»ï¼ˆSequence Classificationï¼‰ï¼Œå¯¹æ•´ä¸ªå¥å­è¿›è¡Œåˆ†ç±»ã€‚å¦‚: è·å–è¯„è®ºçš„æƒ…ç»ªï¼Œæ£€æµ‹ç”µå­é‚®ä»¶æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶ï¼Œç¡®å®šå¥å­åœ¨è¯­æ³•ä¸Šæ˜¯å¦æ­£ç¡®æˆ–ä¸¤ä¸ªå¥å­åœ¨é€»è¾‘ä¸Šæ˜¯å¦ç›¸å…³ç­‰\n4. Token åˆ†ç±»ä»»åŠ¡ï¼ˆToken Classificationï¼‰ # Token åˆ†ç±»ä»»åŠ¡ï¼ˆToken Classificationï¼‰ï¼Œå¯¹å¥å­ä¸­çš„æ¯ä¸ªè¯è¿›è¡Œåˆ†ç±»ã€‚å¦‚: è¯†åˆ«å¥å­çš„è¯­æ³•æˆåˆ†ï¼ˆåè¯ã€åŠ¨è¯ã€å½¢å®¹è¯ï¼‰æˆ–å‘½åå®ä½“ï¼ˆäººã€åœ°ç‚¹ã€ç»„ç»‡ï¼‰ã€‚\nå‚è€ƒ # å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å®æˆ˜ï¼ˆä¸€ï¼‰-PEFTæ¦‚è¿° LLMå¾®è°ƒå®æˆ˜ æå›½ä¸œ "},{"id":54,"href":"/www6vAIGC/docs/Application/VectorStore/","title":"å‘é‡æ•°æ®åº“","section":"Application","content":"\nå‘é‡æ•°æ®åº“ # å›½äº§\nMilvus Tencent zilliz cloud å›½å¤–\nPinecone FAISS [ANN] Chroma Weaviate å‘é‡æ•°æ®åº“-ç´¢å¼•æ–¹å¼ [7] # å‘é‡çš„ç›¸ä¼¼åº¦ç®—æ³•[3] # Cosine Similarity * ä½™å¼¦ Dot Product * Squared Euclidean (L2-Squared) * æ¬§å¼è·ç¦» Manhattan (L1 Norm or Taxicab Distance) * Hamming * ANN æ¯”è¾ƒ[4] # Similarity Metric Vector properties considered Euclidean distance Magnitudes and direction Cosine similarity Only direction Dot product similarity Magnitudes and direction å‚è€ƒ # äº‘åŸç”Ÿå‘é‡æ•°æ®åº“Milvusæ‰«ç›²ï¼Œçœ‹å®Œè¿™ç¯‡å°±å¤Ÿäº† äº‘åŸç”Ÿå‘é‡æ•°æ®åº“Milvusï¼ˆäºŒï¼‰-æ•°æ®ä¸ç´¢å¼•çš„å¤„ç†æµç¨‹ã€ç´¢å¼•ç±»å‹åŠSchema Distance Metrics in Vector Search Vector Similarity Explained xxx xxx å‘é‡æ•°æ®åº“ï¼ˆç¬¬ 1 éƒ¨åˆ†ï¼‰ï¼šæ¯ä¸ªæ•°æ®åº“æœ‰ä½•ä¸åŒï¼Ÿ 1xx. å¾®ä¿¡å‘é‡æ£€ç´¢åˆ†æä¸€ä½“åŒ–æ•°ä»“æ¢ç´¢ï¼šOLAP For Embedding *** 1xx. Metaå‘é‡æ•°æ®åº“Faissä»‹ç»\n"},{"id":55,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Tool-use/FunctionCall/","title":"(åŸç†|å®æˆ˜) [OpenAI]Function Call","section":"Tool use","content":"\nFunction Call # è°ƒç”¨é¡ºåº [0] [1][2] # Function Calling æ•´ä¸ªåŠŸèƒ½çš„è°ƒç”¨é¡ºåºå¤§è‡´å¦‚ä¸‹ å£°æ˜å‡½æ•°ï¼šå®šä¹‰å½“å‰å‡½æ•°çš„åç§°ï¼Œæè¿°ï¼Œä»¥åŠå¯¹åº”çš„å‚æ•°ä¿¡æ¯ï¼Œå¹¶è¯·æ±‚å¯¹åº”çš„æ¥å£ï¼› è§£æå‡½æ•°å‚æ•°ï¼šæ¥å—å¯¹åº”çš„æ¥å£è¿”å›ï¼Œå¹¶è§£æå¯¹åº”çš„å‡½æ•°å‚æ•°ä¿¡æ¯ï¼› æ‰§è¡Œå‡½æ•°ï¼šæ ¹æ®å¯¹åº”çš„å‚æ•°ä¿¡æ¯è°ƒç”¨æœ¬åœ°å‡½æ•°ï¼› ä¸ŠæŠ¥ç»“æœï¼šå°†æœ¬åœ°å‡½æ•°æ‰§è¡Œçš„ç»“æœä¸ŠæŠ¥ç»™ Chat æ¥å£ï¼› ä»£ç  [2] # goal # The goal of the OpenAI Function APIs is to more reliably return valid and useful function calls than a generic text completion or chat API.\nå‚è€ƒ # å¤§æ¨¡å‹å¼€å‘(åä¸€)ï¼šChat Completionsæ¨¡å‹çš„Function callingåŠŸèƒ½è¯¦è§£\nå¦‚ä½•ä½¿ç”¨Chat Completionsæ¥å£çš„å‡½æ•°è°ƒç”¨åŠŸèƒ½\nOpenAIå¼€å‘ç³»åˆ—ï¼ˆåä¸€ï¼‰ï¼šFunction callingåŠŸèƒ½çš„å®é™…åº”ç”¨æµç¨‹ä¸æ¡ˆä¾‹è§£æ ä»£ç  æµç¨‹å›¾ ä»£ç  git\nOpenAIå¼€å‘ç³»åˆ—ï¼ˆåä¸‰ï¼‰ï¼šåˆ©ç”¨Function callingåŠŸèƒ½å¼€å‘åŸºäºå¤§æ¨¡å‹çš„å®æ—¶å¤©æ°”æŸ¥è¯¢åŠ©æ‰‹ æœª\nOpenAIå¼€å‘ç³»åˆ—ï¼ˆåäºŒï¼‰ï¼šFunction callingåŠŸèƒ½çš„æµç¨‹ä¼˜åŒ–ä¸å¤šè½®å¯¹è¯å®ç° æœª\n"},{"id":56,"href":"/www6vAIGC/docs/Agent/Overview/AgentGuide/","title":"(åŸç†) Agent Guide +","section":"Overview","content":"\nAgent Guide # (åŸç†) Agent Guide\n"},{"id":57,"href":"/www6vAIGC/docs/Agent/Communication/MCPArch/","title":"(åŸç†)MCP æ¶æ„","section":"Communication *","content":" MCP æ¶æ„ [1] # å…¬ç½‘/å†…ç½‘çº§çš„æƒé™æ§åˆ¶ ç”¨æˆ·æ€çš„æƒé™æ§åˆ¶ å·¥å…·å¿«é€Ÿæ¥å…¥èƒ½åŠ› é•¿å·¥å…·åˆ—è¡¨ä¼˜åŒ– å‚è€ƒ # 1xx. Agentå·¥ç¨‹èƒ½åŠ›æ€è€ƒè®°å½•\n"},{"id":58,"href":"/www6vAIGC/docs/Agent/Communication/MCPManyTools/","title":"(åŸç†|å®ç°)MCP å¤§é‡å·¥å…·è°ƒç”¨ +","section":"Communication *","content":" MCPå¤§é‡å·¥å…·è°ƒç”¨ # MCP-Zero \u0026amp; BigTool\n"},{"id":59,"href":"/www6vAIGC/docs/Deep-Research/%E5%AE%9E%E7%8E%B0/DeepresearchGoogle/","title":"(Google)Deep Research","section":"å®ç°","content":"\n(Google)Deep Research # (Google)Deep Research\n"},{"id":60,"href":"/www6vAIGC/docs/FineTuning/PEFT/Soft-Prompt/PEFTPtuningPractice/","title":"(å®æˆ˜)PEFT P-Tuning","section":"Soft Prompt","content":"\næœ€ä½³å®è·µ[1] # è¦çœ‹losss, ä¹Ÿè¦çœ‹ä¸šåŠ¡çš„loss ç”Ÿæˆæ¨¡å‹å¸¸ç”¨çš„è¯„ä»·æ–¹æ³• BLEU èƒ½è¯„ä¼°æµç•…åº¦** ç»“æœéƒ½æ˜¯æµç•…çš„å‰æä¸‹ï¼ŒROUGE ååº”å‚ç…§å¥ä¸­å¤šå°‘å†…å®¹è¢«ç”Ÿæˆçš„å¥å­åŒ…å«ï¼ˆå¬å›ï¼‰ å‚ç›´æ¨¡å‹ stfä¹‹åå¤±å»é€šç”¨èƒ½åŠ› è¦æœ‰é€šç”¨èƒ½åŠ›, éœ€è¦pre-trainå’ŒSTFä¸­éƒ½èå…¥é€šç”¨çš„è¯­æ–™ æ¯ä¸ªæ¨¡å‹çš„å­¦ä¹ ç‡lrä¸ä¸€æ · chatglmçš„å­¦ä¹ ç‡ LR=2e-2 å­¦ä¹ ç‡ # æ”¹çš„ç‰¹åˆ«å¤§ æ¨¡å‹è®­ç»ƒçš„æ—¶å€™ä¼šéœ‡è¡ æ”¹çš„ç‰¹åˆ«å° æ¨¡å‹è®­ç»ƒçš„æ—¶å€™ä¼šæ”¶æ•›éå¸¸æ…¢ å‚è€ƒ # ã€Š13-åŸºäº ChatGLM2çš„ Fine-tuning å®æˆ˜ã€‹ AI å¤§æ¨¡å‹å…¨æ ˆå·¥ç¨‹å¸ˆåŸ¹å…»è®¡åˆ’ 2æœŸ train_pt2.sh git åŸºäºæ³•å¾‹æ–‡æœ¬çš„chatglmçš„p-tuning train_pt2.sh git åŸºäºæ³•å¾‹æ–‡æœ¬çš„chatglm-2çš„P-tuning v2 è¯¾ä»¶ biliæœ‰ç›¸å…³çš„æ€»ç»“çš„è§†é¢‘ "},{"id":61,"href":"/www6vAIGC/docs/FineTuning/%E5%AE%9E%E8%B7%B5/FineTuningBert/","title":"Fine Tuning-Bert","section":"å®è·µ *","content":"\nåŸºäºbertçš„äºŒåˆ†ç±» # ä»£ç  - å…¨å‚FT,éPEFT import datasets from datasets import load_dataset from datasets import load_metric from transformers import AutoTokenizer, AutoModel from transformers import AutoModelForSequenceClassification from transformers import TrainingArguments from transformers import Trainer import transformers from transformers import DataCollatorWithPadding from sklearn.metrics import f1_score import torch import numpy as np import os import torch.nn as nn SEED=42 # ALBERTæ˜¯ä¸€ç§å‹ç¼©è¿‡çš„BERT MODEL_NAME = \u0026#34;albert-base-v2\u0026#34; DATASET_NAME = \u0026#34;glue\u0026#34; # ä¸€ç»„NLPè¯„æµ‹ä»»åŠ¡ DATASET_TASK = \u0026#34;mrpc\u0026#34; # MRPC æ˜¯å…¶ä¸­ä¸€ä¸ªå­ä»»åŠ¡ -- Microsoft Research Paraphrase Corpus # åœ¨Bertçš„åŸºç¡€ä¸ŠåŠ äº†ä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨ class MyClassifier(torch.nn.Module): def __init__(self, backbone): super().__init__() self.bert_encoder = backbone self.linear = torch.nn.Linear(768, 2) def compute_loss(self, logits, labels): loss_fct = nn.CrossEntropyLoss() return loss_fct(logits, labels) def forward(self, input_ids, attention_mask,labels=None): output = self.bert_encoder(input_ids=input_ids, attention_mask=attention_mask) output = output.last_hidden_state[:, 0, :] output = self.linear(output) if labels is not None: loss = self.compute_loss(output, labels) return loss, output return output # åŠ è½½æ•°æ®é›†å¯¹åº”çš„è¯„ä¼°æ–¹æ³• glue_metric = datasets.load_metric(DATASET_NAME, DATASET_TASK) def compute_metrics(eval_pred): logits, labels = eval_pred predictions = np.argmax(logits, axis=-1) return glue_metric.compute(predictions=predictions, references=labels) # åŠ è½½æ•°æ®é›† raw_datasets = load_dataset(DATASET_NAME,DATASET_TASK) # è®­ç»ƒé›† raw_train_dataset = raw_datasets[\u0026#34;train\u0026#34;] # éªŒè¯é›† raw_valid_dataset = raw_datasets[\u0026#34;validation\u0026#34;] columns = raw_train_dataset.column_names # è®¾ç½®éšæœºç§å­ transformers.set_seed(SEED) # å®šä¹‰tokenizer tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) # å®šä¹‰æ•°æ®å¤„ç†å‡½æ•°ï¼ŒæŠŠåŸå§‹æ•°æ®è½¬æˆinput_ids, attention_mask, labels def process_fn(examples): inputs = tokenizer(examples[\u0026#34;sentence1\u0026#34;], examples[\u0026#34;sentence2\u0026#34;], truncation=True, max_length=128) examples[\u0026#34;input_ids\u0026#34;] = inputs[\u0026#34;input_ids\u0026#34;] examples[\u0026#34;attention_mask\u0026#34;] = inputs[\u0026#34;attention_mask\u0026#34;] examples[\u0026#34;labels\u0026#34;] = examples[\u0026#34;label\u0026#34;] return examples tokenized_train_dataset = raw_train_dataset.map( process_fn, batched=True, remove_columns=columns ) tokenized_valid_dataset = raw_valid_dataset.map( process_fn, batched=True, remove_columns=columns ) # å®šä¹‰æ•°æ®æ ¡å‡†å™¨ï¼ˆè‡ªåŠ¨ç”Ÿæˆbatchï¼‰ collater = DataCollatorWithPadding( tokenizer=tokenizer, return_tensors=\u0026#34;pt\u0026#34;, ) # å®šä¹‰æ¨¡å‹ -- å…¶å®Transformerå¯ä»¥ç›´æ¥ç”¨AutoModelForSequenceClassification #model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2) # æˆ‘æ‰‹å·¥å†™äº†åˆ†ç±»å™¨å±‚ï¼Œä¸ºäº†æ–¹ä¾¿å¤§å®¶ç†è§£ä»€ä¹ˆå«åœ¨Transformerä¸Šé¢åšåˆ†ç±»ä»»åŠ¡ backbone = AutoModel.from_pretrained(MODEL_NAME) model = MyClassifier(backbone) # å®šä¹‰è®­ç»ƒå‚æ•° training_args = TrainingArguments( output_dir=\u0026#34;./output\u0026#34;, # checkpointä¿å­˜è·¯å¾„ evaluation_strategy=\u0026#34;steps\u0026#34;, # æ¯Næ­¥åšä¸€æ¬¡eval overwrite_output_dir=True, num_train_epochs=1, # è®­ç»ƒepochæ•° per_device_train_batch_size=8, # æ¯å¼ å¡çš„batchå¤§å° gradient_accumulation_steps=4, # ç´¯åŠ å‡ ä¸ªstepåšä¸€æ¬¡å‚æ•°æ›´æ–° per_device_eval_batch_size=8, # evaluation batch size logging_steps=20, # æ¯20æ­¥evalä¸€æ¬¡ save_steps=20, # æ¯20æ­¥ä¿å­˜ä¸€ä¸ªcheckpoint learning_rate=2e-5, # å­¦ä¹ ç‡ warmup_ratio=0.1, # é¢„çƒ­ï¼ˆå¯é€‰ï¼‰ ) # å®šä¹‰è®­ç»ƒå™¨ trainer = Trainer( model=model, # å¾…è®­ç»ƒæ¨¡å‹ args=training_args, # è®­ç»ƒå‚æ•° data_collator=collater, # æ•°æ®æ ¡å‡†å™¨ train_dataset=tokenized_train_dataset, # è®­ç»ƒé›† eval_dataset=tokenized_valid_dataset, # éªŒè¯é›† compute_metrics=compute_metrics, # è¯„ä»·æŒ‡æ ‡ ) # ç¦ç”¨wandbï¼ˆä¸huggingface.coåŒæ­¥çš„æœºåˆ¶ï¼‰ os.environ[\u0026#34;WANDB_DISABLED\u0026#34;] = \u0026#34;true\u0026#34; # å¼€å§‹è®­ç»ƒ trainer.train() å‚è€ƒ # Bert fine-tuning äºŒåˆ†ç±»\n"},{"id":62,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/framework/RAGQanything/","title":"(æ¡†æ¶) Qanything","section":"framework","content":"\nQAnything # Arch[1] # ç´¢å¼•ï¼ˆindexingï¼‰ é€šè¿‡Embeddingä¸ºæ¯ä¸€ä¸ªæ–‡æœ¬å—ç”Ÿæˆä¸€ä¸ªå‘é‡è¡¨ç¤ºï¼Œç”¨äºè®¡ç®—æ–‡æœ¬å‘é‡å’Œé—®é¢˜å‘é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚åˆ›å»ºç´¢å¼•å°†åŸå§‹æ–‡æœ¬å—å’ŒEmbeddingå‘é‡ä»¥é”®å€¼å¯¹çš„å½¢å¼å­˜å‚¨ï¼Œä»¥ä¾¿å°†æ¥è¿›è¡Œå¿«é€Ÿå’Œé¢‘ç¹çš„æœç´¢ã€‚\næ£€ç´¢ï¼ˆRetrievalï¼‰ ä½¿ç”¨Embeddingæ¨¡å‹å°†ç”¨æˆ·è¾“å…¥é—®é¢˜è½¬æ¢ä¸ºå‘é‡ï¼Œè®¡ç®—é—®é¢˜çš„Embeddingå‘é‡å’Œè¯­æ–™åº“ä¸­æ–‡æœ¬å—Embeddingå‘é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œé€‰æ‹©ç›¸ä¼¼åº¦æœ€é«˜çš„å‰Kä¸ªæ–‡æ¡£å—ä½œä¸ºå½“å‰é—®é¢˜çš„å¢å¼ºä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\nç”Ÿæˆï¼ˆGenerationï¼‰ å°†æ£€ç´¢å¾—åˆ°çš„å‰Kä¸ªæ–‡æœ¬å—å’Œç”¨æˆ·é—®é¢˜ä¸€èµ·é€è¿›å¤§æ¨¡å‹ï¼Œè®©å¤§æ¨¡å‹åŸºäºç»™å®šçš„æ–‡æœ¬å—æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n1st Retrievalï¼ˆembeddingï¼‰[1] # Bcembeddingæ¨¡å‹ [3]\nä¸­è‹±åŒè¯­å’Œè·¨è¯­ç§èƒ½åŠ› å¤šé¢†åŸŸè¦†ç›– Embedding å¯ä»¥ç»™å‡ºä¸€ä¸ªå¾—åˆ†ï¼Œä½†æ˜¯è¿™ä¸ªå¾—åˆ†æè¿°çš„æ›´å¤šçš„æ˜¯ç›¸ä¼¼æ€§ã€‚Embeddingæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªåŒç¼–ç å™¨ï¼Œä¸¤ä¸ªæ–‡æœ¬åœ¨æ¨¡å‹å†…éƒ¨æ²¡æœ‰ä»»ä½•ä¿¡æ¯äº¤äº’ã€‚åªåœ¨æœ€åè®¡ç®—ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦æ—¶æ‰è¿›è¡Œå”¯ä¸€ä¸€æ¬¡äº¤äº’ã€‚æ‰€ä»¥Embeddingæ£€ç´¢åªèƒ½æŠŠæœ€ç›¸ä¼¼çš„æ–‡æœ¬ç‰‡æ®µç»™ä½ ï¼Œæ²¡æœ‰èƒ½åŠ›æ¥åˆ¤æ–­å€™é€‰æ–‡æœ¬å’Œqueryä¹‹é—´çš„ç›¸å…³æ€§ã€‚ä½†æ˜¯ç›¸ä¼¼åˆä¸ç­‰äºç›¸å…³ã€‚\nã€embedding -\u0026gt; ç›¸ä¼¼æ€§ã€‘\n2nd Retrievalï¼ˆrerankï¼‰[1] # Rerank [3]\nRerankæœ¬è´¨æ˜¯ä¸€ä¸ªCross-Encoderçš„æ¨¡å‹ã€‚Cross-Encoderèƒ½è®©ä¸¤ä¸ªæ–‡æœ¬ç‰‡æ®µä¸€å¼€å§‹å°±åœ¨BERTæ¨¡å‹å„å±‚ä¸­é€šè¿‡self-attentionè¿›è¡Œäº¤äº’ã€‚\nã€rerank -\u0026gt; ç›¸å…³æ€§ã€‘\nå‚è€ƒ # QAnything # QAnything Repo git xxx æœ‰é“QAnythingèƒŒåçš„æ•…äº‹ï¼šå…³äºRAGçš„ä¸€ç‚¹ç»éªŒåˆ†äº« V\næœ‰é“QAnythingèƒŒåçš„æ•…äº‹\u0026mdash;å…³äºRAGçš„ä¸€ç‚¹ç»éªŒåˆ†äº« æ–‡å­—ç‰ˆ\n[å…¬ä¼—å·æœ‰å…¶ä»–æ–‡ç« ] 1xx. å‰æ²¿é‡å™¨[45] RAGå¼€æºé¡¹ç›®Qanythingæºç é˜…è¯»1-æ¦‚è¿°+æœåŠ¡\n"},{"id":63,"href":"/www6vAIGC/docs/Agent/Multi-agent/AgentAutogen/","title":"(åŸç†\u0026å®æˆ˜)AutoGen +","section":"Multi-agent *","content":"\nAutoGen # (åŸç†\u0026amp;å®æˆ˜)AutoGen\n"},{"id":64,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/RAGFailure/","title":"(Work)RAG æ•…éšœç‚¹ +","section":"å®æˆ˜ *","content":"\nRAG æ•…éšœç‚¹ # RAG æ•…éšœç‚¹\n"},{"id":65,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/RAGOptimize/","title":"RAG ä¼˜åŒ– *","section":"å®æˆ˜ *","content":"\næœ´ç´ RAG Embedding # Embedding å¬å›æ–¹æ¡ˆåŠå±€é™æ€§[1] # å¬å›ç²¾åº¦ä½ ç²’åº¦è¿‡ç²— ä¸æ”¯æŒæ¡ä»¶æŸ¥è¯¢/ç»Ÿè®¡ ä¸èƒ½æ›¿ä»£ä¿¡æ¯æå– è§£å†³æ–¹æ¡ˆ # é—®é¢˜ç†è§£â€”â€”å‡†ç¡®è¯†åˆ«ç”¨æˆ·æ„å›¾(ä¼ ç»ŸNLP) [2]\nåŸºäºå…³é”®è¯Embeddingçš„å…¥åº“å’Œæœç´¢ [2]\nå…³é”®è¯æå– å®ç°ä¿¡æ¯æŠ½å–ï¼ˆInformation Extractionï¼ŒIEï¼‰ å®ä½“å…³ç³»ä¸‰å…ƒç»„æŠ½å–(RE, Relation Extraction ) å‘½åå®ä½“è¯†åˆ«(NER, Name-Entity Recognition) äº‹ä»¶æŠ½å–(EE, Event Extraction) åŸºäº LLM æå– [ä¸æ¨è] ç»“æœä¸å‡†ç¡®ã€å¼€é”€ä¹Ÿå¤§ ä¼ ç»Ÿ NLP æ–¹æ³•æå–[æ¨è] åè¯çŸ­è¯­æå–ä¸æ•´åˆ ä¾å­˜åˆ†æ æˆåˆ†å¥æ³•åˆ†æ æ€»ç»“ ä»å®Œæ•´è¯­å¥çš„ Embeddingï¼Œåˆ‡æ¢ä¸ºå…³é”®è¯ Embeddingï¼š ä¼˜åŠ¿ ç›¸æ¯”ä¼ ç»Ÿ Embeddingï¼Œå¤§å¹…æå‡å¬å›ç²¾å‡†åº¦ã€‚ ä½¿ç”¨ä¼ ç»Ÿ NLP åœ¨ä¸“é¡¹é—®é¢˜å¤„ç†ä¸Šï¼Œç›¸æ¯” LLM æä¾›æ›´å¥½çš„ç²¾åº¦å’Œæ€§èƒ½ã€‚ çŸ¥è¯†åº“å­˜å‚¨é€‰å‹\nVector Store åˆ†ç‰‡: åŒºåˆ†å±‚çº§ç»“æ„ Relational Database Graph Database å›¾æ•°æ®æ£€ç´¢ è¡Œä¸šé—®ç­”[3] # æŒ‘æˆ˜ # ç‰ˆé¢å¤æ‚å¤šæ · æ–‡æœ¬åˆ†å— å­˜åœ¨çŸ¥è¯†ç‚¹è¢«åˆ†å‰²ã€ä¸å®Œæ•´çš„æƒ…å†µã€‚ å¤šå› ç´ å½±å“å†…å®¹å¬å›æ•ˆæœ ä¾‹å¦‚ï¼šæ–‡æ¡£å†…å®¹ç›¸ä¼¼åº¦é«˜(ä¸“ä¸šæ–‡æ¡£ç»†åˆ†é¢†åŸŸã€ç‰ˆæœ¬è¿­ä»£ç­‰)ï¼› é€šç”¨çš„å‘é‡ç›¸ä¼¼åº¦ç®—æ³•æ•ˆæœä¸å¥½(é—®é¢˜ä¸é—®é¢˜åŒ¹é… VSé—®é¢˜ä¸ç­”æ¡ˆåŒ¹é…)ï¼› å¬å›ç‡å—æ–‡æ¡£åº“å¢å¤§è€Œé™ä½ ä¼˜åŒ– # å‘é‡åŒ–ä¸Šçš„ä¼˜åŒ–\nè®­ç»ƒç›®æ ‡ä¼˜åŒ–ä¸ºæå‡Queryä¸æ®µè½çš„ç›¸å…³æ€§ï¼Œä½¿å¾—é—®é¢˜å’Œç›¸å…³æ®µè½çš„è¯­ä¹‰å‘é‡è¡¨ç¤ºæ›´æ¥è¿‘ï¼Œè®­ç»ƒæ¨¡å‹æœ‰sbertï¼Œcosentç­‰ å…³é”®ä¿¡æ¯ä¸Šçš„ä¼˜åŒ–\nåœ¨æ–‡æ¡£å†…å®¹çš„ä¿¡æ¯å‹ç¼©ä¸Šï¼Œè¿›è¡Œæ–‡æœ¬å…³é”®è¯å’Œæ‘˜è¦çš„æå– ä»å®Œæ•´è¯­å¥çš„Embeddingï¼Œåˆ‡æ¢ä¸ºå…³é”®è¯Embedding å‚è€ƒ # RAGæ¢ç´¢ä¹‹è·¯çš„è¡€æ³ªå²åŠæ›™å…‰ è…¾è®¯ Embedding, Retrieval\nLLM+Embeddingæ„å»ºé—®ç­”ç³»ç»Ÿçš„å±€é™æ€§åŠä¼˜åŒ–æ–¹æ¡ˆ åŸºäºå…³é”®è¯Embeddingçš„å…¥åº“å’Œæœç´¢çš„æµç¨‹å›¾, ç»“åˆä¼ ç»Ÿnlpä»»åŠ¡ 1xx. åŸºäºå¤§è¯­è¨€æ¨¡å‹æ„å»ºçŸ¥è¯†é—®ç­”ç³»ç»Ÿ\nå†çœ‹ä¸šç•Œå¤§æ¨¡å‹è¡Œä¸šé—®ç­”çš„å›°éš¾åŠè‹¥å¹²ä¸šç•Œå®è·µï¼šå…¼çœ‹æ™ºèƒ½å®¢æœå¸¸ç”¨è·¯çº¿åŠå¤šåœºæ™¯prompt é—®é¢˜ ä¼˜åŒ–\n1xx. å¤§æ¨¡å‹RAGé—®ç­”ç ”å‘çœŸå®å›¾é‰´ï¼šä¸€å‘¨å‡ºDemoï¼ŒåŠå¹´ç”¨ä¸å¥½ï¼Œç¼è¡¥ä¹‹è·¯æ¼«æ¼« 1xx. å¤§æ¨¡å‹è¡Œä¸šè½åœ°å®è·µçš„ä¸€äº›æ€»ç»“å’Œè§‚ç‚¹ï¼šå¤§æ¨¡å‹è¡Œä¸šé—®ç­”è½åœ°ä¸­çš„ç°å®æŒ‘æˆ˜ä»¥åŠæ½œåœ¨çš„ç¼“è§£ç­–ç•¥ ã€ŠDataFunCon2023æ·±åœ³ç«™-20231125-åˆ˜ç„•å‹‡-å¤§æ¨¡å‹è¡Œä¸šé—®ç­”çš„ç°å®æŒ‘æˆ˜åŠæ½œåœ¨çš„ç¼“è§£ç­–ç•¥ã€‹ pdf\nxxx # 1xx. å†çœ‹RAGåœ¨çœŸå®é‡‘èæ–‡æ¡£é—®ç­”åœºæ™¯çš„å®è·µæ–¹æ¡ˆï¼šSMP2023 é‡‘èå¤§æ¨¡å‹æŒ‘æˆ˜èµ›çš„ä¸¤ç§ä»£è¡¨å®ç°æ€è·¯\n1xx. æ„å»ºä¼ä¸šçº§ RAG ç³»ç»Ÿçš„é«˜çº§æŒ‡å— [è¯‘]\n"},{"id":66,"href":"/www6vAIGC/docs/FineTuning/Data/DataSFTScaling/","title":"(åŸç†)SFT Scaling","section":"Data","content":"\nè®ºæ–‡ # è®ºæ–‡åœ°å€ ã€ŠWhen Scaling Meets LLM Fine-tuning: The Effect of Data, Model and Fine-tuning Methodã€‹ æ‘˜è¦[1] # è¿™ç¯‡è®ºæ–‡ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¾®è°ƒï¼ˆfinetuningï¼‰é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŒè§„æ¨¡å› ç´ ä¸‹çš„å¾®è°ƒæ€§èƒ½ã€‚ä½œè€…æ¢è®¨äº†åŒ…æ‹¬LLMæ¨¡å‹å¤§å°ã€é¢„è®­ç»ƒæ•°æ®å¤§å°ã€æ–°å¾®è°ƒå‚æ•°å¤§å°å’Œå¾®è°ƒæ•°æ®å¤§å°åœ¨å†…çš„å¤šä¸ªå› ç´ ï¼Œå¹¶è€ƒè™‘äº†ä¸¤ç§å¾®è°ƒæ–¹æ³•ï¼šå…¨æ¨¡å‹å¾®è°ƒï¼ˆFMTï¼‰å’Œå‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPETï¼ŒåŒ…æ‹¬prompt tuningå’ŒLoRAï¼‰ã€‚ç ”ç©¶å‘ç°LLMå¾®è°ƒéµå¾ªåŸºäºåŠŸç‡çš„ä¹˜æ³•è”åˆè§„æ¨¡æ³•åˆ™ï¼ŒLLMæ¨¡å‹è§„æ¨¡çš„å¢åŠ å¯¹å¾®è°ƒæ€§èƒ½çš„æå‡å¤§äºé¢„è®­ç»ƒæ•°æ®è§„æ¨¡çš„å¢åŠ ï¼Œè€ŒPETå‚æ•°è§„æ¨¡çš„å¢åŠ é€šå¸¸æ•ˆæœä¸ä½³ã€‚æ­¤å¤–ï¼Œå¾®è°ƒæ–¹æ³•çš„é€‰æ‹©é«˜åº¦ä¾èµ–äºå…·ä½“ä»»åŠ¡å’Œå¾®è°ƒæ•°æ®ã€‚\nã€ åŠŸç‡çš„ä¹˜æ³•è”åˆè§„æ¨¡æ³•åˆ™: å¾®è°ƒæ•°æ®æ•°é‡ \u0026lt;\u0026ndash;\u0026gt; xxxã€‘\nã€æ¨¡å‹å¤§å°(æ ‡é¢˜é‡Œçš„Model ) \u0026gt; é¢„è®­ç»ƒæ•°æ®(æ ‡é¢˜é‡Œçš„Data), PETå‚æ•°(æ ‡é¢˜é‡Œçš„Fine-tuning Method) æ— æ•ˆã€‘\nã€å¾®è°ƒæ–¹æ³•çš„é€‰æ‹©é«˜åº¦ä¾èµ–äºå…·ä½“ä»»åŠ¡å’Œå¾®è°ƒæ•°æ®ã€‘\nå®éªŒæ–¹æ³•[1] # å®éªŒåŸºäºä¸¤ç»„é¢„è®­ç»ƒçš„åŒè¯­LLMsï¼ˆè‹±è¯­\u0026amp;å¾·è¯­ï¼Œè‹±è¯­\u0026amp;ä¸­æ–‡ï¼‰ï¼Œæ¨¡å‹å¤§å°ä»1Båˆ°16Bã€‚ä½œè€…åœ¨WMTæœºå™¨ç¿»è¯‘ï¼ˆè‹±è¯­-å¾·è¯­ã€è‹±è¯­-ä¸­æ–‡ï¼‰å’Œå¤šè¯­è¨€æ‘˜è¦ï¼ˆè‹±è¯­ã€å¾·è¯­ã€æ³•è¯­å’Œè¥¿ç­ç‰™è¯­ï¼‰ä»»åŠ¡ä¸Šè¿›è¡Œäº†å¤§è§„æ¨¡ç ”ç©¶ï¼Œæœ€å¤šä½¿ç”¨20Må¾®è°ƒç¤ºä¾‹ã€‚å®éªŒè®¾ç½®åŒ…æ‹¬ï¼š\nä¸‹æ¸¸ä»»åŠ¡ï¼šé€‰æ‹©æœºå™¨ç¿»è¯‘å’Œå¤šè¯­è¨€æ‘˜è¦ä½œä¸ºå¾®è°ƒçš„ä¸‹æ¸¸ä»»åŠ¡ã€‚ LLMså’Œé¢„è®­ç»ƒï¼šé‡‡ç”¨è§£ç å™¨ä»…Transformeræ¨¡å‹ï¼Œä½¿ç”¨ä¿®æ”¹åçš„UL2ç›®æ ‡è¿›è¡Œè®­ç»ƒã€‚ å¾®è°ƒè®¾ç½®ï¼šç ”ç©¶äº†ä¸‰ç§å¾®è°ƒæ–¹æ³•ï¼ˆFMTã€Promptå’ŒLoRAï¼‰ï¼Œå¹¶æ¢ç´¢äº†å››ç§ä¸åŒçš„è§„æ¨¡å› ç´ ã€‚ è¯„ä¼°ï¼šä½¿ç”¨åŸºäºtokençº§åˆ«çš„å›°æƒ‘åº¦ï¼ˆPPLï¼‰é€‰æ‹©æœ€ä½³æ£€æŸ¥ç‚¹è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ä½¿ç”¨BLEURTå’ŒRougeLè¯„ä¼°ç”Ÿæˆè´¨é‡ã€‚ ç»“è®º[1] # æå‡ºäº†ä¸€ä¸ªä¹˜æ³•è”åˆè§„æ¨¡æ³•åˆ™æ¥æè¿°å¾®è°ƒæ•°æ®å¤§å°å’Œå…¶ä»–è§„æ¨¡å› ç´ ä¹‹é—´çš„è§„æ¨¡å…³ç³»ã€‚ LLMæ¨¡å‹è§„æ¨¡çš„å¢åŠ å¯¹å¾®è°ƒæ€§èƒ½çš„æå‡å¤§äºé¢„è®­ç»ƒæ•°æ®è§„æ¨¡çš„å¢åŠ ã€‚ PETå‚æ•°è§„æ¨¡çš„å¢åŠ å¯¹äºLoRAå’ŒPromptçš„æ•ˆæœæœ‰é™ï¼Œä¸”æœ‰æ—¶ç”šè‡³ä¼šå¯¼è‡´åå‘è§„æ¨¡æ•ˆåº”ã€‚ å¾®è°ƒæ–¹æ³•çš„é€‰æ‹©å¯¹äºä¸‹æ¸¸ä»»åŠ¡æ¥è¯´å¹¶ä¸ç®€å•ï¼Œéœ€è¦æ ¹æ®ä»»åŠ¡ç‰¹æ€§å’Œå¾®è°ƒæ•°æ®çš„å¯ç”¨æ€§æ¥å†³å®šã€‚ å¾®è°ƒå¯èƒ½ä¼šæé«˜æ¨¡å‹å¯¹ç›¸å…³ä»»åŠ¡çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯å½“åŸºç¡€LLMè¾ƒå¤§æ—¶ï¼ŒPromptå’ŒLoRAé€šå¸¸æ¯”FMTè¡¨ç°å¾—æ›´å¥½ã€‚ ä½œè€…æŒ‡å‡ºï¼Œå°½ç®¡ç ”ç©¶æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ï¼Œä½†ä¹Ÿå­˜åœ¨ä¸€äº›å±€é™æ€§ï¼Œå¦‚è”åˆè§„æ¨¡æ³•åˆ™ä¸»è¦åŸºäºå°é—­ç”Ÿæˆä»»åŠ¡çš„å®è¯ç»“æœï¼Œç¼ºä¹ç†è®ºåŸºç¡€ã€‚æœªæ¥çš„å·¥ä½œå°†æ‰©å±•åˆ°å¤šæ¨¡æ€LLMsï¼Œæ¢ç´¢å¾®è°ƒæ•°æ®è´¨é‡çš„å½±å“ï¼Œå¹¶è€ƒè™‘å¼€æ”¾å’Œåˆ›é€ æ€§çš„ç”Ÿæˆä»»åŠ¡ä»¥åŠå¾®è°ƒçš„å¤šä»»åŠ¡è®¾ç½®ã€‚\né‡è¦ç»“è®º[2] # ä½œè€…ä»¬æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¾®è°ƒï¼ˆfinetuningï¼‰è¿‡ç¨‹ä¸­ä¸åŒè§„æ¨¡å› ç´ å¯¹æ€§èƒ½çš„å½±å“ã€‚ä»¥ä¸‹æ˜¯è®ºæ–‡çš„ä¸€äº›é‡è¦ç»“è®ºåŠå…¶å¯¹â€œSCALINGâ€æ¦‚å¿µçš„è§£é‡Šï¼š\nä¹˜æ³•è”åˆç¼©æ”¾æ³•åˆ™ï¼šä½œè€…æå‡ºäº†ä¸€ä¸ªåŸºäºä¹˜æ³•çš„è”åˆç¼©æ”¾æ³•åˆ™ï¼ˆmultiplicative joint scaling lawï¼‰ï¼Œç”¨äºæè¿°å¾®è°ƒæ•°æ®å¤§å°ä¸å…¶ä»–ç¼©æ”¾å› ç´ ï¼ˆå¦‚LLMæ¨¡å‹å¤§å°ã€é¢„è®­ç»ƒæ•°æ®å¤§å°ã€PETå‚æ•°å¤§å°ï¼‰ä¹‹é—´çš„å…³ç³»ã€‚è¿™ä¸ªæ³•åˆ™è¡¨æ˜ï¼Œå¾®è°ƒæ€§èƒ½ä¸è¿™äº›å› ç´ çš„ä¹˜æ³•ç»„åˆæœ‰å…³ï¼Œè€Œä¸æ˜¯ç®€å•çš„åŠ æ³•å…³ç³»ã€‚ æ¨¡å‹å¤§å°å¯¹å¾®è°ƒçš„å½±å“ï¼šç ”ç©¶å‘ç°ï¼Œå¢åŠ LLMæ¨¡å‹çš„å¤§å°å¯¹å¾®è°ƒæ€§èƒ½çš„æå‡æ¯”å¢åŠ é¢„è®­ç»ƒæ•°æ®çš„å¤§å°æ›´ä¸ºæ˜¾è‘—ã€‚è¿™è¡¨æ˜åœ¨æœ‰é™èµ„æºä¸‹ï¼Œä¼˜å…ˆè€ƒè™‘æ‰©å¤§æ¨¡å‹è§„æ¨¡è€Œä¸æ˜¯æ•°æ®è§„æ¨¡ï¼Œå¯èƒ½ä¼šå¸¦æ¥æ›´å¥½çš„å¾®è°ƒæ•ˆæœã€‚ å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPETï¼‰çš„å±€é™æ€§ï¼šå°½ç®¡PETæ–¹æ³•ï¼ˆå¦‚prompt tuningå’ŒLoRAï¼‰æ—¨åœ¨é€šè¿‡ä¼˜åŒ–å°‘é‡å‚æ•°æ¥æé«˜æ€§èƒ½ï¼Œä½†ç ”ç©¶å‘ç°å¢åŠ PETå‚æ•°çš„å¤§å°å¯¹äºå¾®è°ƒæ€§èƒ½çš„æå‡æ•ˆæœæœ‰é™ï¼Œæœ‰æ—¶ç”šè‡³ä¼šå‡ºç°åå‘ç¼©æ”¾ç°è±¡ã€‚ ä»»åŠ¡å’Œæ•°æ®ä¾èµ–æ€§ï¼šå¾®è°ƒçš„ç¼©æ”¾ç‰¹æ€§é«˜åº¦ä¾èµ–äºå…·ä½“ä»»åŠ¡å’Œæ•°æ®ã€‚è¿™æ„å‘³ç€æ²¡æœ‰ä¸€ç§é€šç”¨çš„æœ€ä¼˜å¾®è°ƒæ–¹æ³•ï¼Œé€‰æ‹©å“ªç§å¾®è°ƒæ–¹æ³•éœ€è¦æ ¹æ®ä¸‹æ¸¸ä»»åŠ¡çš„ç‰¹æ€§å’Œå¯ç”¨çš„å¾®è°ƒæ•°æ®é‡æ¥å†³å®šã€‚ å¾®è°ƒå¯¹é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›çš„å½±å“ï¼šå°½ç®¡å¾®è°ƒé€šå¸¸æ˜¯ä¸ºäº†æé«˜ç‰¹å®šä»»åŠ¡çš„æ€§èƒ½ï¼Œä½†ç ”ç©¶å‘ç°ï¼ŒåŸºäºLLMçš„å¾®è°ƒä»ç„¶å¯ä»¥ä¿ƒè¿›å¯¹ç›¸å…³ä»»åŠ¡çš„é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›ã€‚ç‰¹åˆ«æ˜¯PETæ–¹æ³•åœ¨ä¿ç•™æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›æ–¹é¢è¡¨ç°æ›´å¥½ã€‚ å¾®è°ƒæ•°æ®é‡çš„ä¸´ç•Œç‚¹ï¼šè®ºæ–‡ä¸­è¿˜è®¨è®ºäº†ä¸åŒå¾®è°ƒæ–¹æ³•ä¹‹é—´çš„ä¸´ç•Œç‚¹ï¼Œå³åœ¨ç‰¹å®šçš„å¾®è°ƒæ•°æ®é‡ä¸‹ï¼Œä¸€ç§æ–¹æ³•å¯èƒ½æ¯”å¦ä¸€ç§æ–¹æ³•è¡¨ç°å¾—æ›´å¥½ã€‚è¿™ä¸ªä¸´ç•Œç‚¹ä¼šéšç€ä»»åŠ¡å’Œæ¨¡å‹å¤§å°çš„ä¸åŒè€Œå˜åŒ–ã€‚ è¿™äº›ç»“è®ºå¯¹ç†è§£LLMå¾®è°ƒè¿‡ç¨‹ä¸­çš„â€œSCALINGâ€å…·æœ‰é‡è¦æ„ä¹‰ã€‚å®ƒä»¬æ­ç¤ºäº†ä¸åŒè§„æ¨¡å› ç´ å¦‚ä½•ç›¸äº’ä½œç”¨ä»¥åŠå®ƒä»¬å¯¹å¾®è°ƒæ€§èƒ½çš„å…±åŒå½±å“ï¼Œä¸ºåœ¨å®é™…åº”ç”¨ä¸­é€‰æ‹©å’Œä¼˜åŒ–å¾®è°ƒç­–ç•¥æä¾›äº†ç†è®ºä¾æ®ã€‚é€šè¿‡è¿™äº›å‘ç°ï¼Œç ”ç©¶è€…å’Œå®è·µè€…å¯ä»¥æ›´å¥½åœ°ç†è§£åœ¨ç‰¹å®šæ¡ä»¶ä¸‹å¦‚ä½•æœ‰æ•ˆåœ°ç¼©æ”¾å’Œé…ç½®ä»–ä»¬çš„æ¨¡å‹ä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚\nå‚è€ƒ # è¯·å¸®æˆ‘è¯»ç¯‡è®ºæ–‡ï¼Œè¯¦ç»†çš„å†™å‡ºæ‘˜è¦ï¼Œå®éªŒæ–¹æ³•ï¼Œç»“è®º kimi è¯·å¸®æˆ‘è¯»ç¯‡è®ºæ–‡ï¼Œè®ºæ–‡æœ‰å“ªäº›é‡è¦çš„ç»“è®ºï¼Ÿ è¿™äº›ç»“è®ºæ˜¯å¦‚ä½•è§£é‡Šé¢˜ç›®ä¸­çš„SCALINGçš„ï¼Ÿ kimi 1xx. å€¼å¾—ä¸€çœ‹çš„å¤§æ¨¡å‹é¢„è®­ç»ƒæ•°æ®é€‰æ‹©ç­–ç•¥æ€»ç»“ï¼šå…¼è¯»20240229å¤§æ¨¡å‹è¿›å±•æ—©æŠ¥\nã€ŠWhen Scaling Meets LLM Finetuning: The Effect of Dataï¼Œ Model and Finetuning MethodÂ»\n"},{"id":67,"href":"/www6vAIGC/docs/DocumentAI/DocumentAI/","title":"æ–‡æ¡£æ™ºèƒ½","section":"æ–‡æ¡£æ™ºèƒ½","content":"\næ–‡æ¡£ç†è§£ ä¸¤ç§èŒƒå¼[1, 10] # pipeline(OCR) # ERNIElayout [1] LayoutLMç³»åˆ— [1] ç«¯åˆ°ç«¯(OCR-free) # åŸºäºå°æ¨¡å‹çš„OCR-freeå¾®è°ƒæ–¹æ¡ˆ\nDonut åŸºäºå¤§æ¨¡å‹çš„OCR-FREEå¾®è°ƒæ–¹æ¡ˆ\nLLaVAR [12] TextMonkey [11] mPLUG-DocOwl1.5 [20]\nDocOwl1.5ç”±mPLUG-Owl2åˆå§‹åŒ–ï¼Œä½¿ç”¨ViT/L-14ä½œä¸ºè§†è§‰ç¼–ç å™¨ï¼Œå¹¶ä½¿ç”¨å¸¦æœ‰æ¨¡æ€è‡ªé€‚åº”æ¨¡å—çš„7Bå¤§æ¨¡å‹ä½œä¸ºè§£ç å™¨ã€‚ æ¯ä¸ªå­å›¾åƒç”±ViT/L-14ç¼–ç ä¸º1,024ä¸ªç‰¹å¾ï¼Œç„¶åç”±H-Reducerç¼©å‡ä¸º256ä¸ªç‰¹å¾ã€‚ TextMonkey [20]\nä¸ºäº†å‡å°‘å›¾åƒç‰¹å¾çš„å†—ä½™ï¼Œç»§æ‰¿äº†Qwen-VLä¸­çš„å›¾åƒé‡é‡‡æ ·å™¨ï¼Œåœ¨æ¯ä¸ªçª—å£ä¸­éƒ½ä¼šä½¿ç”¨ã€‚ æ–‡æ¡£ç‰ˆå¼åˆ†ææ•°æ®é›†[10] # å‚è€ƒ # è€åˆ˜-åˆ†äº« å€¼å¾—ä¸€çœ‹çš„æ–‡æ¡£ç†è§£å‰æ²¿æ–¹æ¡ˆåŠç‰ˆå¼åˆ†æå¼€æºæ•°æ®ï¼šä¸‰ç§æ¨¡å¼ã€ä¹å¤§æ•°æ®é›† Monkey\nMonkey Demo LLaVARï¼šå¢å¼ºçš„è§†è§‰æŒ‡ä»¤å¾®è°ƒ\nLLaVAR: Enhanced Visual Instruction Tuning for Text-rich Image Understanding 1xx. åŠ é€Ÿ Document AI (æ–‡æ¡£æ™ºèƒ½) å‘å±•\nåŠ é€Ÿ Document AI (æ–‡æ¡£æ™ºèƒ½) å‘å±•\n1xx. é˜¿é‡Œé¢å‘ä¼ä¸šæ•°å­—åŒ–çš„æ–‡æ¡£æ™ºèƒ½æŠ€æœ¯ä¸åº”ç”¨\nå…¶ä»– # ä¹Ÿçœ‹è·¨æ¨¡æ€å¤§æ¨¡å‹é‡è§æ–‡æ¡£ç†è§£ï¼šmPLUG-DocOwl1.5åŠTextMonkeyæ–¹æ¡ˆä¸­çš„æ•°æ®å·¥ç¨‹ "},{"id":68,"href":"/www6vAIGC/docs/DocumentAI/Table/","title":"è¡¨æ ¼","section":"æ–‡æ¡£æ™ºèƒ½","content":" è¡¨æ ¼å¤„ç†[1] # é•¿è¡¨æ ¼ å¤„ç†\nåˆ†æˆä¸¤åŠå„è‡ªå¤„ç†\näº‹ååšæ£€æµ‹ï¼Œæ ¹æ®é¡µçœ‰é¡µè„šåšåˆå¹¶ï¼Œ å¯¹è¾¹ç•Œçš„å¤„ç† RapidTable [2] # MinerU ä¸­çš„è¡¨æ ¼è¯†åˆ«ä½¿ç”¨äº†RapidTable RapidTable ä½¿ç”¨äº†ä»¥ä¸‹4ä¸­æ¨¡å‹ class ModelType(Enum): PPSTRUCTURE_EN = \u0026#34;ppstructure_en\u0026#34; # PaddleOCR PPSTRUCTURE_ZH = \u0026#34;ppstructure_zh\u0026#34; # PaddleOCR SLANETPLUS = \u0026#34;slanet_plus\u0026#34; # PaddleX UNITABLE = \u0026#34;unitable\u0026#34; ppstructure(PaddleOCR)[3] # è¡¨æ ¼è¯†åˆ«ä¸»è¦åŒ…å«ä¸‰ä¸ªæ¨¡å‹ å•è¡Œæ–‡æœ¬æ£€æµ‹-DB å•è¡Œæ–‡æœ¬è¯†åˆ«-CRNN è¡¨æ ¼ç»“æ„å’Œcellåæ ‡é¢„æµ‹-SLANet å…·ä½“æµç¨‹å›¾å¦‚ä¸‹\nå‚è€ƒ # èš‚èšæ•°ç§‘AI AgentçŸ¥è¯†å·¥ç¨‹å®è·µ Datafun https://github.com/RapidAI/RapidTable\nhttps://github.com/opendatalab/MinerU ppstructure/table 1xx. RAGå®æˆ˜ç³»åˆ—ï¼Œå¦‚ä½•é’ˆå¯¹wordæ–‡æ¡£ä¸­çš„è¡¨æ ¼è¿›è¡Œé—®ç­”ï¼Œè§£å†³è·¨é¡µè¡¨æ ¼é—®é¢˜ v\n1xx. å°†å›¾ç‰‡æˆ–PDFä¸­å¤æ‚çš„è¡¨æ ¼æ•°æ®è½¬æˆçº¯æ–‡æœ¬è¾“å…¥å¤§æ¨¡å‹ï¼Œå¦‚ä½•ä¿æŒè¡¨æ ¼æ–‡å­—çš„æ’ç‰ˆå¸ƒå±€ä¸å˜ï¼Ÿ v\n"},{"id":69,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Tool-use/AgentTuning/","title":"(å®æˆ˜)Agent Tuning","section":"Tool use","content":"\nåŸºäºå¾®è°ƒçš„Agent - Function Call[1][2] # åŸºåº§æ¨¡å‹\ninternLM å¾®è°ƒæ¡†æ¶\nxtuner Agent Tuning[3] # åŸºåº§æ¨¡å‹\nYi-6B Datasets å¾®è°ƒæ¡†æ¶\nLLama-Factory ç¯å¢ƒå‡†å¤‡ # # source code git clone -b v0.7.1 \u0026lt;https://github.com/hiyouga/LLaMA-Factory.git\u0026gt; git switch -c v0.7.1 cd LLaMA-Factory # package å®‰è£… conda create -n llama_factory python=3.10 conda activate llama_factory pip install llmtuner==0.5.1 # ç¯å¢ƒå˜é‡ export CUDA_VISIBLE_DEVICES=0 # ä½¿ç”¨ç¬¬ä¸€å— GPU export USE_MODELSCOPE_HUB=1 # ä½¿ç”¨é­”æ­ç¤¾åŒºä¸‹è½½æ¸ é“ # é˜¿é‡Œäº‘å¿…é¡»åŠ è¿™å¥ï¼Œä¸ç„¶é¡µé¢ä¼šæŠ¥å¼‚å¸¸ $ export GRADIO_ROOT_PATH=/${JUPYTER_NAME}/proxy/7860/ # å¯åŠ¨ python -m llmtuner.webui.interface è®­ç»ƒæµç¨‹ # # flash-attn å®‰è£… pip install flash-attn --no-build-isolation pip install modelscope -U è®­ç»ƒè„šæœ¬ # è®­ç»ƒè½®æ•° 1.0 CUDA_VISIBLE_DEVICES=0 python src/train_bash.py \\\\ --stage sft \\\\ --do_train True \\\\ --model_name_or_path 01ai/Yi-6B \\\\ --finetuning_type lora \\\\ --template default \\\\ --flash_attn True \\\\ --dataset_dir data \\\\ --dataset glaive_toolcall,alpaca_gpt4_en,alpaca_gpt4_zh,oaast_sft_zh \\\\ --cutoff_len 1024 \\\\ --learning_rate 5e-05 \\\\ --num_train_epochs 1.0 \\\\ --max_samples 8000 \\\\ --per_device_train_batch_size 4 \\\\ --gradient_accumulation_steps 4 \\\\ --lr_scheduler_type cosine \\\\ --max_grad_norm 1.0 \\\\ --logging_steps 5 \\\\ --save_steps 100 \\\\ --warmup_steps 0 \\\\ --lora_rank 8 \\\\ --lora_dropout 0.1 \\\\ --lora_target all \\\\ --output_dir saves/Yi-6B/lora/yi-agent-6b \\\\ --fp16 True \\\\ --plot_loss True è®­ç»ƒé…ç½® è®­ç»ƒç»“æœ æ•ˆæœå±•ç¤º\nå·¥å…·è°ƒç”¨ - æŸ¥è¯¢å¤©æ°”\nã€1ä¸ªepochå¥½åƒæœ‰ç‚¹é—®é¢˜ã€‘\nTuning # xtuner å®æˆ˜ 4ã€è¡¥å……ã€‘ç”¨ MS-Agent æ•°æ®é›† èµ‹äºˆ LLM ä»¥ Agent èƒ½åŠ› (4)XTuner å¤§æ¨¡å‹å•å¡ä½æˆæœ¬å¾®è°ƒå®æˆ˜ V å•å¡ 3 å°æ—¶è®­ç»ƒä¸“å±å¤§æ¨¡å‹ Agentï¼šåŸºäº LLaMA Factory å®æˆ˜ AgentTuning # 1xx. åŸºäºllama7Bçš„æ–‡æœ¬åµŒå…¥æ¨¡å‹ANGLEï¼šå…¼çœ‹Agentå¾®è°ƒæ•°æ®çš„ç”Ÿæˆæ–¹æ¡ˆ AgentTuning\n1xx. LLMä¹‹Agentï¼ˆäº”ï¼‰| AgentTuningï¼šæ¸…åå¤§å­¦ä¸æ™ºè°±AIæå‡ºAgentTuningæé«˜å¤§è¯­è¨€æ¨¡å‹Agentèƒ½åŠ›\n1xx. AgentTuningè§£è¯»\nAgentTuning å®æˆ˜ # 1xx. 2024å¹´å¤§æ¨¡å‹Agent tuningå…³é”®æŠ€æœ¯Fireact, Agent-FLAN, AgentOhana, Agent LUMOS, STE, ETO,MoE, DebateGPTç­‰\n1xx. Agent-FLAN æŠ€æœ¯æŠ¥å‘Šâ€”â€”ç¤¾åŒºç¿»è¯‘ç‰ˆ 1xx. LLM å¤§æ¨¡å‹å­¦ä¹ å¿…çŸ¥å¿…ä¼šç³»åˆ—(ä¹)ï¼šAgentå¾®è°ƒæœ€ä½³å®è·µï¼Œç”¨æ¶ˆè´¹çº§æ˜¾å¡è®­ç»ƒå±äºè‡ªå·±çš„Agentï¼\n"},{"id":70,"href":"/www6vAIGC/docs/Agent/Overview/AgentCategory/","title":"(åŸç†)Agent åˆ†ç±»[æœ‰è¶£|æœ‰ç”¨]","section":"Overview","content":"\næœ‰è¶£çš„AIï¼šæ›´åƒäººçš„AI # å¥½çœ‹çš„çš®å›Š å¤šæ¨¡æ€ # å¤šæ¨¡æ€ç†è§£èƒ½åŠ›\nå¤šæ¨¡æ€æ•°æ®ç«¯åˆ°ç«¯é¢„è®­ç»ƒçš„æ¨¡å‹ Gemini å·¥ç¨‹åŒ– projection layer ç›´æ¥ç”¨æ–‡æœ¬å»ç²˜æ¥ encoderã€decoder å’Œæ–‡æœ¬å¤§æ¨¡å‹ egã€è‡ªå·±åŠ¨æ‰‹åšå‡ºGeminiæ¼”ç¤ºè§†é¢‘çš„æ•ˆæœã€‘ å¤šæ¨¡æ€ç”Ÿæˆèƒ½åŠ›\nè§†é¢‘ç”Ÿæˆ Live2Dï¼Œ3D æ¨¡å‹ DeepFake å½•åˆ¶ä¸€ä¸ªçœŸäººè§†é¢‘ï¼Œ æŠŠè§†é¢‘ä¸­çš„äººè„¸æ¢æˆæŒ‡å®šçš„äººè„¸ç…§ç‰‡ Image Animation ç»™å®šä¸€å¼ ç…§ç‰‡ï¼Œéšåæ ¹æ®è¿™å¼ ç…§ç‰‡ç”Ÿæˆä¸€ç³»åˆ—çš„å¯¹åº”è§†é¢‘ Video Diffusion å¯¹ç‰©ç†ä¸–ç•Œçš„å»ºæ¨¡ æˆæœ¬æœ€é«˜ æœ‰è¶£çš„çµé­‚ # ä¸ªæ€§\nåŸºäºprompt å®Œæ•´åœ°åˆ»ç”»å‡ºä¸€ä¸ªäººç‰©çš„å†å²ã€ä¸ªæ€§ã€è®°å¿†å’Œæ€§æ ¼ é•¿æ–‡æœ¬ åŸºäºå¾®è°ƒçš„ agent æ›´å…³é”®çš„è¿˜æ˜¯æ•°æ® å¯¹è¯æ€§è¯­æ–™ \u0026amp; äº‹å®æ€§è¯­æ–™ ç¬¬ä¸€æ­¥ï¼Œæˆ‘ä»¬å…ˆç”¨å¯¹è¯æ€§è¯­æ–™å»å¾®è°ƒä»–çš„ä¸ªæ€§å’Œè¯´è¯é£æ ¼ ç¬¬äºŒæ­¥ï¼Œå†å»æŠŠäº‹å®æ€§è¯­æ–™è¿›è¡Œæ•°æ®æ¸…æ´—åï¼ŒåŸºäºå„ç§è§’åº¦æé—®ï¼Œç”Ÿæˆè¿™ä¸ªäººç‰©ç¬¬ä¸€äººç§°å£å»çš„å›ç­”ï¼Œè¿™å«åšæ•°æ®å¢å¼º æ…¢æ€è€ƒä¸è®°å¿†\nç»„ä»¶ è®°å¿†ã€æƒ…æ„Ÿã€ä»»åŠ¡è§„åˆ’ã€å·¥å…· é•¿æœŸè®°å¿† äº‹å®æ€§çš„è®°å¿† æ€»ç»“ æ–‡æœ¬æ€»ç»“ MemGPT RAG å’Œä¿¡æ¯å‹ç¼© é•¿ä¸Šä¸‹æ–‡ é•¿ä¸Šä¸‹æ–‡ ç»“åˆæŒä¹…åŒ– KV Cache æˆæœ¬è¿˜æ˜¯å¤ªé«˜ ã€eg. æ–‡æœ¬æ€»ç»“ + RAGã€‘ ç¨‹åºæ€§çš„è®°å¿† few-shot å¾®è°ƒ çŸ­æœŸæ¥çœ‹ä»ç„¶æ˜¯æ•ˆæœæœ€å¥½çš„è·¯çº¿ æœ‰ç”¨çš„AIï¼šæ›´åƒå·¥å…·çš„AI # å¤§æ¨¡å‹åŸºç¡€èƒ½åŠ› # å¤æ‚ä»»åŠ¡çš„è§„åˆ’å’Œåˆ†è§£ éµå¾ªå¤æ‚æŒ‡ä»¤ è‡ªä¸»ä½¿ç”¨å·¥å…· å‡å°‘å¹»è§‰ 1P-3P äº§å“æ³•åˆ™ # åˆ†ç±»\nä¸ªäººåŠ©ç†ç±» å•†ä¸šæ™ºèƒ½ç±» OpenAI çš„ 1P-3P äº§å“æ³•åˆ™\nåªè¦ä¸€ä¸¤ä¸ªäººï¼ˆ1Pï¼‰å¼€å‘çš„äº§å“å°±è‡ªå·±ï¼ˆfirst Partyï¼‰åš 1P äº§å“ä¾‹å­ å¯¼æ¸¸ ä¼ä¸š ERP åŠ©æ‰‹ å¤§æ¨¡å‹é‡‡é›†æ•°æ® æ‰‹æœºè¯­éŸ³åŠ©æ‰‹ RPAï¼ˆæœºå™¨äººæµç¨‹è‡ªåŠ¨åŒ–ï¼‰ è…¾è®¯çš„AppAgent è§†è§‰æ–¹æ¡ˆ ä¼šè®®å’Œç”Ÿæ´»è®°å½•å™¨ éœ€è¦ä¸‰ä¸ªäººï¼ˆ3Pï¼‰ä»¥ä¸Šå¼€å‘çš„äº§å“å°±è®©ç¬¬ä¸‰æ–¹ï¼ˆthird Partyï¼‰åš è§£å†³å¤æ‚ä»»åŠ¡å’Œä½¿ç”¨å·¥å…· # æ…¢æ€è€ƒ æ€ç»´é“¾ æ€ç»´é“¾æ˜¯éå¸¸è‡ªç„¶çš„ä¸€ç§æ…¢æ€è€ƒçš„æ¨¡å¼ å¤æ‚ä»»åŠ¡çš„è§„åˆ’å’Œåˆ†è§£ ç”¨å¤šæ­¥çš„ç½‘ç»œæœç´¢å»å›ç­”éš¾é¢˜ AI éœ€è¦èƒ½å¤ŸæŒ‰ç…§æµç¨‹è°ƒç”¨å·¥å…· å·¥å…·ä½¿ç”¨å±äºè¿‡ç¨‹è®°å¿†ï¼Œä½¿ç”¨åœºæ™¯å’Œæ¡ä»¶ä¸æ˜¯è¯­è¨€å¯ä»¥æ˜ç¡®æè¿°çš„ ä½¿ç”¨ fine-tuning æ–¹æ³•å‘Šè¯‰æ¨¡å‹ä¸€äº›å·¥å…·ä½¿ç”¨çš„æ ·ä¾‹ï¼Œç”šè‡³åœ¨é¢„è®­ç»ƒæ—¶å°±åŠ å…¥ å·¥å…·ä½¿ç”¨å¯ä»¥ç”¨ä»£ç å½¢å¼è¡¨è¾¾ï¼Œå› æ­¤å±äºä»£ç ç”Ÿæˆèƒ½åŠ› ä½¿ç”¨RAGæ–¹æ³•è·å–åˆ°å·¥å…·ä½¿ç”¨çš„ä»£ç  å‚è€ƒ # 1xx. AI Agent åº”è¯¥æ›´æœ‰è¶£è¿˜æ˜¯æ›´æœ‰ç”¨ï¼Ÿ ***\n"},{"id":71,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Planning/AgentPlanAndExecute/","title":"(Work|å®æˆ˜)Plan\u0026Execute,ReWOO","section":"Planning","content":"\nPlan-and-execute [0] # åŸç†\nFigure 2 - åŸºäºprompt [1] ä»£ç \nplan [2] Planning Step Re-Plan Step é—®é¢˜\nå†—ä½™çš„æç¤ºå’Œé‡å¤çš„æ‰§è¡Œ -\u0026gt; ReWOO ReWOO [0] # åŸç†\nAbstract [10] å¢å¼ºè¯­è¨€æ¨¡å‹ï¼ˆALMï¼‰å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›ä¸å…è®¸çŸ¥è¯†æ£€ç´¢å’Œæ‰§è¡Œæ“ä½œçš„å·¥å…·ç›¸ç»“åˆã€‚ç°æœ‰çš„ALMç³»ç»Ÿä»¥äº¤é”™çš„æ–¹å¼è§¦å‘LLMçš„æ€è€ƒè¿‡ç¨‹ï¼ŒåŒæ—¶ä»è¿™äº›å·¥å…·ä¸­è·å–è§‚å¯Ÿç»“æœã€‚å…·ä½“è€Œè¨€ï¼ŒLLMæ¨ç†è¿‡ç¨‹ä¸­ä¼šè°ƒç”¨å¤–éƒ¨å·¥å…·ï¼Œç„¶ååœ¨è·å–å·¥å…·å“åº”ååœæ­¢ï¼ŒåŸºäºä¹‹å‰çš„å“åº”ä»¤ç‰Œæ¥å†³å®šä¸‹ä¸€æ­¥çš„æ“ä½œã€‚è¿™ç§èŒƒå¼è™½ç„¶ç›´è§‚ä¸”æ˜“äºå®ç°ï¼Œä½†å¸¸å¸¸ç”±äºå†—ä½™çš„æç¤ºå’Œé‡å¤çš„æ‰§è¡Œè€Œå¯¼è‡´è®¡ç®—å¤æ‚åº¦æé«˜ã€‚æœ¬ç ”ç©¶é¦–æ¬¡è§£å†³äº†è¿™äº›æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æ¨¡å—åŒ–çš„èŒƒå¼ReWOOï¼ˆæ— è§‚å¯Ÿæ¨ç†ï¼‰ï¼Œå°†æ¨ç†è¿‡ç¨‹ä¸å¤–éƒ¨è§‚å¯Ÿç»“æœåˆ†ç¦»ï¼Œä»è€Œæ˜¾è‘—å‡å°‘äº†ä»¤ç‰Œçš„æ¶ˆè€—ã€‚ Figure 1 [10] Planneré‡Œæœ‰æ ¼å¼åŒ–çš„#E Figure 2 [10] ä»£ç  [11]\nExecutor-tool_execution() -\u0026gt; çŠ¶æ€æœº é—®é¢˜\næ˜¯å¦å¯ä»¥å¹¶è¡Œï¼Ÿ-\u0026gt; LLMCompiler LLMCompiler # åŸç†\nAbstract [20] LLMçš„å¤šå‡½æ•°è°ƒç”¨èƒ½åŠ›å‚¬ç”Ÿäº†åŸºäºLLMçš„è½¯ä»¶å¼€å‘ï¼Œä½¿å…¶èƒ½å¤Ÿè§£å†³æ›´å¤æ‚çš„é—®é¢˜ã€‚ç„¶è€Œï¼Œå½“å‰çš„å¤šå‡½æ•°è°ƒç”¨æ–¹æ³•é€šå¸¸éœ€è¦é’ˆå¯¹æ¯ä¸ªå‡½æ•°è¿›è¡Œé¡ºåºæ¨ç†å’Œæ‰§è¡Œï¼Œè¿™å¯èƒ½å¯¼è‡´è¾ƒé«˜çš„å»¶è¿Ÿã€æˆæœ¬ä»¥åŠä¸å‡†ç¡®çš„è¡Œä¸ºã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†LLMCompilerï¼Œå®ƒå¯ä»¥å¹¶è¡Œæ‰§è¡Œå‡½æ•°ï¼Œä»¥é«˜æ•ˆåœ°ç¼–æ’å¤šå‡½æ•°è°ƒç”¨ã€‚LLMCompilerå€Ÿé‰´äº†ç»å…¸ç¼–è¯‘å™¨çš„åŸç†ï¼Œåœ¨LLMä¸­ä½¿ç”¨ä¸‰ä¸ªç»„ä»¶æ¥ç®€åŒ–å¹¶è¡Œå‡½æ•°è°ƒç”¨ï¼šï¼ˆiï¼‰LLMè§„åˆ’å™¨ï¼Œåˆ¶å®šæ‰§è¡Œç­–ç•¥å’Œä¾èµ–å…³ç³»ï¼›ï¼ˆiiï¼‰ä»»åŠ¡è·å–å•å…ƒï¼Œåˆ†æ´¾å’Œæ›´æ–°å‡½æ•°è°ƒç”¨ä»»åŠ¡ï¼›ï¼ˆiiiï¼‰æ‰§è¡Œå™¨ï¼Œä»¥å¹¶è¡Œæ–¹å¼æ‰§è¡Œè¿™äº›ä»»åŠ¡ã€‚é€šè¿‡LLMCompilerï¼Œç”¨æˆ·å¯ä»¥æŒ‡å®šå·¥å…·ä»¥åŠå¯é€‰çš„ä¸Šä¸‹æ–‡ç¤ºä¾‹ï¼ŒLLMCompilerä¼šè‡ªåŠ¨è®¡ç®—å‡½æ•°è°ƒç”¨çš„ä¼˜åŒ–ç¼–æ’ã€‚é‡è¦çš„æ˜¯ï¼ŒLLMCompilerå¯ä»¥ä¸LLaMA-2ç­‰å¼€æºæ¨¡å‹ä»¥åŠOpenAIçš„GPTæ¨¡å‹ä¸€èµ·ä½¿ç”¨ã€‚ Figure 2 [20] ä»£ç  [21]\nPlanner Task Fetching Unit Joiner å‚è€ƒ # Plan-and-execute # LangGraphï¼šPlan-Execute Agents å®æˆ˜ V Plan-and-Execute Agents *** Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models Figure 2 plan-and-execute git ReWOO # ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models Reasoning without Observation git\nReWoo Agentæ¡†æ¶ä»£ç å®ç° V\n1xx. ReWOO: é«˜æ•ˆå¢å¼ºè¯­è¨€æ¨¡å‹ä¸­è§£å¶è§‚æµ‹å’Œæ¨ç† LLMCompiler # An LLM Compiler for Parallel Function Calling LLMCompiler "},{"id":72,"href":"/www6vAIGC/docs/Langchain/LangchainAgent/","title":"Langchain  Agent","section":"Langchain","content":"\nLangchain Agent # Conversational OpenAI assistants OpenAI functions OpenAI Multi Functions Agent OpenAI tools OpenAI parallel function calling (a.k.a. tool calling) ReAct ZeroShotReactAgent Self-ask with search Structured tool chat Langchain Apps # rag-chroma-private [2] # æœ¬åœ° éƒ¨ç½² This template performs RAG with no reliance on external APIs. It utilizes Ollama the LLM, GPT4All for embeddings, and Chroma for the vectorstore.\nresearch-assistant [3][4] # This template implements a version of \u0026ldquo;GPT Researcher\u0026rdquo; that you can use as a starting point for a research agent.\nLangGraph[5] # å‚è€ƒ # Langchain Apps Project Code LangChain Agents ä¿å§†çº§æ•™ç¨‹ | åŠ¨ç”»æ¼”ç¤º è®²æ¸… æ ¸å¿ƒæ¨¡å— Agents | Code è®²è§£ | Demo æ¼”ç¤º \u0026ldquo;Research Assistant\u0026rdquo;: Exploring UXs Besides Chat Building a Research Assistant from Scratch LangGraph gpt-researcher "},{"id":73,"href":"/www6vAIGC/docs/Agent/Practice/AgentOpt/","title":"(Survey) Agent ä¼˜åŒ– +","section":"Practice","content":"\nAgent ä¼˜åŒ– # (Survey) Agent ä¼˜åŒ–\n"},{"id":74,"href":"/www6vAIGC/docs/Agent/Practice/AgentPractice/","title":"(å®æˆ˜)Agent","section":"Practice","content":"\nAssistant API [3] # Assistant APIåŠŸèƒ½ä»‹ç» # ä»åŠŸèƒ½å®ç°å±‚é¢æ¥è¯´ï¼ŒAssistant APIæ˜¯æˆªè‡³ç›®å‰æœ€å®Œæ•´ã€æ€§èƒ½æœ€å¼ºå¤§çš„AIåº”ç”¨å¼€å‘APIï¼Œå…·ä½“åŠŸèƒ½å¦‚ä¸‹ï¼š\né¦–å…ˆï¼ŒAssistant APIå‰æ‰€æœªæœ‰çš„èƒ½å¤Ÿè°ƒç”¨OpenAIå„æ¨¡å‹çš„å„é¡¹èƒ½åŠ›ï¼ŒåŒ…æ‹¬å¯ä»¥è°ƒç”¨Chatç³»åˆ—æ¨¡å‹ï¼ˆå³GPTç³»åˆ—æ¨¡å‹ï¼‰å®Œæˆæ–‡æœ¬å¯¹è¯ã€è°ƒç”¨DALLÂ·E 3è¿›è¡Œç»˜å›¾ã€è°ƒç”¨GPT-4-visionè¿›è¡Œå›¾åƒè¯†åˆ«ã€ä»¥åŠè°ƒç”¨Text-to-Speechæ¨¡å‹è¿›è¡Œè¯­éŸ³è½¬æ–‡å­—ç­‰ï¼Œå¹¶ä¸”æ”¯æŒåœ¨ä¸€è½®å¯¹è¯ä¸­è°ƒç”¨ä¸åŒæ¨¡å‹ï¼› å…¶æ¬¡ï¼ŒAssistant APIè¿˜å†…ç½®äº†ä»£ç è§£é‡Šå™¨åŠŸèƒ½ï¼ˆCode interpreterï¼‰å’Œæµ·é‡æ–‡æœ¬ä¿¡æ¯æå–åŠŸèƒ½ï¼ˆKnowledge retrievalï¼‰åŒæ—¶ä¹Ÿä¸€å¦‚æ—¢å¾€æ”¯æŒå€ŸåŠ©Function callingè¿›è¡Œæ¨¡å‹åŠŸèƒ½å±‚é¢æ‹“å±•ï¼Œæ­¤å¤–ï¼Œéå¸¸é‡è¦çš„æ˜¯ï¼ŒAssistant APIè¿˜æ”¯æŒåœ¨ä¸€è½®å¯¹è¯ä¸­è°ƒç”¨å¤šä¸ªå·¥å…·ï¼› å…¶ä¸‰ï¼Œæ­¤å¤–å¯¹äºå¼€å‘è€…éå¸¸å‹å¥½çš„ä¸€ç‚¹æ˜¯ï¼ŒAssistant APIæœ€å°è¿è¡Œå•å…ƒä¸ºæŒä¹…åŒ–çš„çº¿ç¨‹å¯¹è±¡ï¼ˆpersistent Threadsï¼‰ï¼Œå› æ­¤åœ¨å®é™…è¿è¡ŒAssistant APIæ—¶ï¼Œä¸ä»…èƒ½å¯ä»¥ç²¾ç¡®æ§åˆ¶æ¯ä¸€æ­¥çš„æ‰§è¡Œè¿‡ç¨‹ï¼ŒåŒæ—¶persistent Threadsä¹Ÿä¼šä¿ç•™æ¯è½®å¯¹è¯çš„æ ¸å¿ƒä¿¡æ¯ï¼Œå¹¶ä¸”å½“è¶…å‡ºæ¨¡å‹æ¥æ”¶ä¿¡æ¯æœ€å¤§ä¸Šä¸‹æ–‡é™åˆ¶æ—¶èƒ½å¤Ÿè‡ªåŠ¨åˆ é™¤æ—©æœŸä¿¡æ¯ï¼Œä»è€Œå®ç°å¯¹æ¨¡å‹çŸ­æœŸè®°å¿†çš„åˆç†ç®¡ç†ï¼› å…¶å››ï¼ŒAssistant APIè¿˜èƒ½å¤Ÿç›´æ¥è¿æ¥OpenAIåœ¨çº¿æ–‡æ¡£åº“ï¼Œå³å¦‚æœç”¨æˆ·å°†å¤–éƒ¨æ–‡æ¡£ä¿å­˜åœ¨OpenAIäº‘ç©ºé—´å†…ï¼Œåˆ™å¯ä»¥åœ¨è°ƒç”¨Assistant APIæ—¶å®æ—¶è®¿é—®æ–‡æ¡£åº“ä¸­çš„ä»»æ„æ–‡ä»¶ï¼Œç”šè‡³å¯ä»¥åœ¨ä¸åŒçº¿ç¨‹ä¸­è°ƒç”¨ä¸åŒçš„æ–‡æ¡£ã€‚è€Œåœ¨å€ŸåŠ©Assistant APIçš„Knowledge retrievalåŠŸèƒ½ï¼Œåˆ™å¯ä»¥è®©å¤§æ¨¡å‹å®æ—¶è·å–è¿™äº›æ–‡ä»¶ä¿¡æ¯ï¼Œå¹¶ä¸”åˆç†ç®¡ç†çŸ­æœŸè®°å¿†ï¼› å®æˆ˜ # Lagent \u0026amp; AgentLego[4] # å‚è€ƒ # Assistant APIè¯¦è§£ä¸Agentå¼€å‘å®æˆ˜-ä¹å¤©Hector\nLagent \u0026amp; AgentLego æ™ºèƒ½ä½“åº”ç”¨æ­å»º\nLagentï¼šè½»é‡çº§æ™ºèƒ½ä½“æ¡†æ¶\nAgentLegoï¼šç»„è£…æ™ºèƒ½ä½“â€œä¹é«˜â€\n1xx. ä½¿ç”¨Qwen-Agentå°†ä¸Šä¸‹æ–‡è®°å¿†æ‰©å±•åˆ°ç™¾ä¸‡é‡çº§\n"},{"id":75,"href":"/www6vAIGC/docs/RAG/Overview/RAGPerformance/","title":"(åŸç†)Advanced RAG +","section":"Overview","content":"\nAdvanced RAG # (åŸç†)Advanced RAG\n"},{"id":76,"href":"/www6vAIGC/docs/Prompt-Engineering/PromptCode/","title":"(åŸç†)[Prompting]Coding","section":"Prompt Engineering","content":"\nå·¥å…· # Copilot *** - æ”¶è´¹ AWS CodeWhispter Cursor *** tabnine å…è´¹ Code Llama - å¼€æº ä»£ç ç›¸å…³-ç®€å•ä»»åŠ¡ [1] # æ³¨é‡Š\nä½ ä½œä¸ºä¸€åç¨‹åºå‘˜ï¼Œè¯·è§£é‡Šä¸€ä¸‹ä¸‹é¢è¿™æ®µä»£ç \né˜²å¾¡æ€§ç¼–ç¨‹ è¯·ä¸ºè¿™æ®µä»£ç å¢åŠ é˜²å¾¡æ€§ç¼–ç¨‹çš„åŠŸèƒ½\nå†™å•å…ƒæµ‹è¯•\næ—¶é—´å¤æ‚åº¦ time complexity è¿™æ®µä»£ç çš„æ—¶é—´å¤æ‚åº¦æ˜¯å¤šå°‘\næµç¨‹å›¾ ç”»å‡ºredis masterå’Œslaveä¹‹é—´åŒæ­¥çš„æµç¨‹å›¾\nWriting shell script\nWriting git commands ä¸€ä¸ªåˆ†æ”¯ä¸­çš„ä»£ç åˆå¹¶åˆ°å¦ä¸€ä¸ªåˆ†æ”¯ä¸­\nImprove code\nHow do i improve this code? fruits = [\u0026#34;apple\u0026#34;, \u0026#34;banana\u0026#34;, \u0026#34;cherry\u0026#34;] newlist = [] for x in fruits: if \u0026#34;a\u0026#34; in x: newlist.append(x) print(newlist) Translating Code ä»£ç è½¬æ¢ Convert this Python code to Javascript è¯·æŠŠä¸‹é¢è¿™æ®µpythonä»£ç è½¬æ¢æˆJavaä»£ç  ä»£ç ç›¸å…³- ç¹çå·¥ä½œ [1] # Building API\nI need an API built with express.js to return the list of products. Each product should have attributes like ID, title, description, price and imageUrl modify the code and retrieve the products from a MongoDB database use TypeScript in this code Generate this API using Python and FastAPI Generating Dummy Data\nGenerate dummy data for a table called customers. Each customer should have an ID, first name, last name and city. I don\u0026rsquo;t need a Javascript. Just give the data. Create a Python class for storing these objects. SQL\nwrite a SQL query to generate a table called products with these columnsï¼š IDï¼ˆintï¼‰ titleï¼ˆstringï¼‰ category(int) write a query to retrieve the top 5 customers in Shanghai Revise this query and join the customers table with the orders table to find out how much each cumster has spent. Then pick the top 5 who have spent the most. æ­£åˆ™ [2]\nCronJob [2]\nK8s\nè¿ç»´ Ops [4] # ç¼–ç¨‹è¯­è¨€ vs è‡ªç„¶è¯­è¨€ # è¯­è¨€ç±»å‹ æ‰§è¡ŒåŸç† C++è¯­è¨€ C++è¯­è¨€ \u0026ndash;\u0026gt; ç¼–è¯‘å™¨/é“¾æ¥å™¨ \u0026ndash;\u0026gt; æ—¢å®šä»»åŠ¡ Javaè¯­è¨€ Javaè¯­è¨€ \u0026ndash;\u0026gt; ç¼–è¯‘å™¨/è™šæ‹Ÿæœº \u0026ndash;\u0026gt; æ—¢å®šä»»åŠ¡ Pythonè¯­è¨€ Pythonè¯­è¨€ \u0026ndash;\u0026gt; è§£é‡Šå™¨ \u0026ndash;\u0026gt; æ—¢å®šä»»åŠ¡ äººç±»è‡ªç„¶è¯­è¨€ äººç±»è‡ªç„¶è¯­è¨€ \u0026ndash;\u0026gt; LLMs \u0026ndash;\u0026gt; å„ç§åç«¯ç»„ä»¶ \u0026ndash;\u0026gt; æ—¢å®šä»»åŠ¡ å‚è€ƒ # ã€ChatGPTã€‘é¢å‘ç¨‹åºå‘˜çš„ChatGPTä½¿ç”¨æ•™ç¨‹38ç§æ–¹å¼æ¥æå‡ç”Ÿäº§åŠ› V GitHub Copilot å®è·µè¯¾ 03, 04, 06 AICoder git ChatGPT å¸®æˆ‘è·‘äº†ä¸€ä¸ªå®Œæ•´çš„ DevOps æµæ°´çº¿ï¼Œç¦»äº†ä¸ªå¤§è°±\u0026hellip; Gin on K8s git PromptOps Top 20 ChatGPT Prompts For Software Developers æœª "},{"id":77,"href":"/www6vAIGC/docs/Deep-Research/%E5%AE%9E%E7%8E%B0/DeepresearchLanggraph/","title":"(Langgraph)Deep Research","section":"å®ç°","content":"\n(Langgraph)Deep Research # (Langgraph)Deep Research\n"},{"id":78,"href":"/www6vAIGC/docs/RAG/%E5%AE%9E%E6%88%98/framework/RAGRAGflow/","title":"(æ¡†æ¶)RAGflow +","section":"framework","content":"\nRAGflow # RAGflow\n"},{"id":79,"href":"/www6vAIGC/docs/RAG/Overview/RAGEval/","title":"RAG è¯„ä¼°","section":"Overview","content":"\n1xx. å¦‚ä½•åˆ©ç”¨RAGAsè¯„ä¼°RAGç³»ç»Ÿçš„å¥½å\nä½¿ç”¨LangChainå’ŒRAGASå¯¹RAGç³»ç»Ÿè¿›è¡Œè‡ªåŠ¨æœ‰æ•ˆè¯„ä¼°\n1xx. ä¸€æ¬¡ææ‡‚RAGè¯„ä¼°ï¼Œä¸‰ä¸ªè§’åº¦LangChainï¼ŒLlamaIndexï¼ŒRAGAS\nRAGè¯„ä¼°èµ„æ–™å¤§å…¨ RAGè¯„ä¼°æŒ‡æ ‡ï¼šä¸¤ç§è§†è§’ç†è§£è¯„ä¼°æŒ‡æ ‡\nRAG Evaluation\nRAG evaluation with RAGAS\n1xx. å†çœ‹å¤§æ¨¡å‹RAGæ£€ç´¢å¢å¼ºå¦‚ä½•è¯„ä¼°ï¼šRAGASå¼€æºè‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶\n1xx. å¤§æ¨¡å‹RAGæ£€ç´¢å¢å¼ºé—®ç­”å¦‚ä½•è¯„ä¼°ï¼šå™ªå£°ã€æ‹’ç­”ã€åäº‹å®ã€ä¿¡æ¯æ•´åˆå››å¤§èƒ½åŠ›è¯„æµ‹ä»»åŠ¡æ¢ç´¢ "},{"id":80,"href":"/www6vAIGC/docs/RAG/phase/phaseRAGPostRetrieval/RAGRerank/","title":"(åŸç†|å®æˆ˜)RAG Rerank","section":"(Phase)post-retrieval","content":"\nReranker [22] # A reranking model â€” also known as a cross-encoder â€” is a type of model that,given a query and document pair, will output a similarity score.\näº§å“ # BGE Ranker [20] # äº¤å‰ç¼–ç å™¨å°†å¯¹æŸ¥è¯¢å’Œç­”æ¡ˆå®æ—¶è®¡ç®—ç›¸å…³æ€§åˆ†æ•°ï¼Œè¿™æ¯”**å‘é‡æ¨¡å‹(å³åŒç¼–ç å™¨)**æ›´å‡†ç¡®ï¼Œä½†æ¯”å‘é‡æ¨¡å‹æ›´è€—æ—¶ã€‚ å› æ­¤ï¼Œå®ƒå¯ä»¥ç”¨æ¥å¯¹åµŒå…¥æ¨¡å‹è¿”å›çš„å‰kä¸ªæ–‡æ¡£é‡æ–°æ’åºã€‚ æˆ‘ä»¬åœ¨å¤šè¯­è¨€æ•°æ®ä¸Šè®­ç»ƒäº†äº¤å‰ç¼–ç å™¨ï¼Œæ•°æ®æ ¼å¼ä¸å‘é‡æ¨¡å‹ç›¸åŒï¼Œå› æ­¤æ‚¨å¯ä»¥æ ¹æ®æˆ‘ä»¬çš„ç¤ºä¾‹ è½»æ¾åœ°å¯¹å…¶è¿›è¡Œå¾®è°ƒã€‚\nBCE[24] # ä¸­æ–‡æ•ˆæœæ¯”BGEå¥½[è€åˆ˜è¯´nlp]\nä¼˜ç§€çš„ç»„åˆ [21] # OpenAI + CohereRerank Voyage + big-reranker-large\nå‚è€ƒ # BGE Reranker transformersäºŒæ¬¡å¼€å‘â€”â€”bge-rerankeræ¨¡å‹å¾®è°ƒæµç¨‹ V RAG å†æ·»æ–°åˆ©å™¨ï¼æ™ºæºå¼€æºæœ€å¼ºæ£€ç´¢æ’åºæ¨¡å‹ BGE Re-Ranker v2.0 æå‡RAGâ€”â€”é€‰æ‹©æœ€ä½³Embeddingå’Œé‡æ–°æ’åæ¨¡å‹ Boosting RAG: Picking the Best Embedding \u0026amp; Reranker models\nRerankers and Two-Stage Retrieval *** æ–‡ä¸­çš„ç¬¬äºŒé˜¶æ®µå°±æ˜¯æŒ‡Reranker\nyoudao RerankerModal BCE\n1xx. ä¸€æ–‡è¯¦çœ‹Langchainæ¡†æ¶ä¸­çš„RAGå¤šé˜¶æ®µä¼˜åŒ–ç­–ç•¥ï¼šä»é—®é¢˜è½¬æ¢åˆ°æŸ¥è¯¢è·¯ç”±å†åˆ°ç”Ÿæˆä¼˜åŒ– rag-from-scratch Repo git\n"},{"id":81,"href":"/www6vAIGC/docs/Agent/Practice/AgentChallenge/","title":"(åŸç†)Agent Challenge","section":"Practice","content":"\né—®é¢˜å’Œå±€é™æ€§ [4] # è®°å¿†å¬å›é—®é¢˜\nåªæ˜¯åšç®€å•çš„ embedding ç›¸ä¼¼æ€§å¬å›ï¼Œå¾ˆå®¹æ˜“å‘ç°å¬å›çš„ç»“æœä¸æ˜¯å¾ˆå¥½\né”™è¯¯ç´¯ç§¯é—®é¢˜\næ¢ç´¢æ•ˆç‡é—®é¢˜\nä¸­é€”å¼•å…¥äººå·¥çš„åˆ¤æ–­å¹²é¢„å’Œåé¦ˆè¾“å…¥\nä»»åŠ¡ç»ˆæ­¢ä¸ç»“æœéªŒè¯\næ¨¡å‹ agent çš„å·¥ä½œå¦‚ä½•ç»ˆæ­¢ä¹Ÿæ˜¯ä¸€ä¸ªæŒ‘æˆ˜\næŒ‘æˆ˜ [8] # å¦‚ä½•è®© agent é€‰æ‹©åˆé€‚çš„å·¥å…· # Toolformer - fine tune Gorilla - retrievalï¼Œfine tune\nã€solution: SFT or RLã€‘ ä¸å¿…è¦çš„å·¥å…·ä½¿ç”¨ # â€œHuman Inputâ€ä¹Ÿå†™æˆä¸€ç§å·¥å…·ï¼Œè®©æ¨¡å‹æ¥ä¸»åŠ¨å‘èµ·å¯¹äººç±»çš„æé—®\nHuman as a tool\nã€solution: human-in-the-loopã€‘\nAgent è¿”å›çš„æ ¼å¼ä¸ç¨³å®š # è¿™é‡Œå¸¸è§çš„åšæ³•æ˜¯è®© LLM æŒ‰ç…§ json è¿™ç±»å¸¸è§çš„ schema æ¥è¿”å›ï¼Œä¸€èˆ¬ç¨³å®šæ€§ä¼šé«˜ä¸€äº›ï¼ˆç›¸æ¯”â€œAction:â€è¿™ç§ï¼‰ã€‚\næ­¤å¤–è‡ªåŠ¨ä¿®å¤é‡è¯•ä¹Ÿå¾ˆå®ç”¨ï¼Œå¯ä»¥åˆ©ç”¨ LangChain é‡Œçš„ output parsers æ¥å¸®åŠ©å®Œæˆã€‚\nã€solution: json outputã€‘\nè®°ä½ä¹‹å‰çš„æ“ä½œï¼Œé¿å…é‡å¤ # AutoGPT - retrieval ç»“åˆè¿‘æœŸæ“ä½œè®°å½•\nã€solution: memoryã€‘\nå¤„ç†è¶…é•¿çš„ observation # éœ€è¦ç”¨ä¸€äº›å·¥å…·ä»ä¸­æå–æœ‰ç”¨ä¿¡æ¯ï¼Œæˆ–è€…æ”¾åˆ°å¤–éƒ¨å­˜å‚¨ä¸­å†å€ŸåŠ© retrieval æ¥ä½¿ç”¨ã€‚\nä¸“æ³¨äºç›®æ ‡ # ç®€å•çš„åšæ³•æ˜¯åœ¨ prompt ç»“å°¾å¤„å†æŠŠç›®æ ‡åŠ ä¸Šï¼Œå¼•èµ· agent çš„æ³¨æ„ã€‚\nå¦å¤–åƒ BabyAGIï¼ŒHuggingGPT è¿™ç§æŠŠ planning å’Œ execution åˆ†å¼€çš„åšæ³•ä¹Ÿæ˜¯å¾ˆæœ‰ç”¨ã€‚æ‹†åˆ†çš„æ¯”è¾ƒç»†çš„ä»»åŠ¡å¾€å¾€æ­¥éª¤æ¯”è¾ƒçŸ­ï¼Œä¹Ÿä¸å®¹æ˜“ä¸¢å¤±ç›®æ ‡ã€‚\nç»“æœè¯„ä¼° # è¯„ä¼°æœ€ç»ˆç»“æœæ˜¯å¦æ­£ç¡® è¿‡ç¨‹çš„ç»†åŒ–è¯„ä¼° é€‰æ‹©çš„ä¸­é—´æ­¥éª¤æ˜¯å¦æ­£ç¡®ã€‚ ç”Ÿæˆ action çš„ input æ˜¯å¦æ­£ç¡®ã€‚ ç”Ÿæˆçš„æ­¥éª¤åºåˆ—æ˜¯å¦åˆç†é«˜æ•ˆã€‚\nã€ eval ã€‘ å‚è€ƒ # AutoGPTä¸LLM Agentè§£æ *** LLM å…¨æ ˆå¼€å‘æŒ‡å—è¡¥é— Agents ***\nHarrison Chase: Agents *** 1xx. LLM Agent ç°çŠ¶å’Œä¸€äº›æ€è€ƒ ï¼ˆ202401ï¼‰\nå½“å‰ Agent çš„ç¼ºé™·å’ŒæŒ‘æˆ˜\n1xx. Agentå¼€å‘è€…å¦ç™½ï¼šçª˜å¢ƒä¸­å‰è¡Œ\n"},{"id":82,"href":"/www6vAIGC/docs/FineTuning/Data/DataSelection/","title":"(åŸç†)Data Selection","section":"Data","content":"\nIFD[1] # ä¸‰ä¸ªæ­¥éª¤ Learning from Brief Experience åˆ©ç”¨å°‘é‡è¿›è¡Œè¿›è¡Œæ¨¡å‹åˆå­¦ Evaluating Based on Experience åˆ©ç”¨åˆå­¦æ¨¡å‹è®¡ç®—åŸå§‹æ•°æ®ä¸­æ‰€æœ‰IFDæŒ‡æ ‡ ç®—æ³• æ¡ä»¶å›ç­”åˆ†æ•°ï¼ˆ Conditioned Answer Scoreï¼ŒCASï¼‰ ç›´æ¥ç­”æ¡ˆåˆ†æ•°ï¼ˆDirect Answer Scoreï¼ŒDASï¼‰ æŒ‡ä»¤è·Ÿéšéš¾åº¦ï¼ˆInstruction-Following Difficultyï¼ŒIFDï¼‰åˆ†æ•° Retraining from Self-Guided Experience åˆ©ç”¨æ¨±æ¡ƒæ•°æ®è¿›è¡Œæ¨¡å‹é‡è®­ç»ƒ MoDS[2] # è´¨é‡ç­›é€‰ é‡‡ç”¨OpenAssistantçš„reward-model-debertav3-large-v2æ¨¡å‹ï¼ˆä¸€ä¸ªåŸºäºDeBERTaæ¶æ„è®¾è®¡çš„å¥–åŠ±æ¨¡å‹ï¼‰å¯¹æ•°æ®è¿›è¡Œè´¨é‡æ‰“åˆ†ã€‚\nå¤šæ ·æ€§ç­›é€‰ ä¸ºäº†é¿å…æ‰€é€‰è´¨é‡æ•°æ®é«˜åº¦ç›¸ä¼¼ï¼Œé€šè¿‡K-Center-Greedyç®—æ³•è¿›è¡Œæ•°æ®ç­›é€‰ï¼Œåœ¨æœ€å¤§åŒ–å¤šæ ·æ€§çš„æƒ…å†µä¸‹ï¼Œä½¿æŒ‡ä»¤æ•°æ®é›†æœ€å°ã€‚ åœ¨è¯¥æ­¥éª¤ä¸­ï¼Œé‡‡ç”¨BERTæ¨¡å‹ä¸ºæŒ‡ä»¤æ•°æ®ç”Ÿæˆå¥å‘é‡æ¥è®¡ç®—ä¸åŒæ•°æ®ä¹‹é—´çš„è·ç¦»ã€‚\nå¿…è¦æ€§ç­›é€‰\nDEITA [3] # å¤æ‚æ€§è¯„åˆ† # å¤æ‚æ€§è¯„ä¼°çš„æ–¹æ³• Random Selectionï¼šéšæœºé€‰æ‹©æ ·æœ¬ã€‚ Instruction Lengthï¼šæŒ‰ç…§æŒ‡ä»¤çš„é•¿åº¦è®¡ç®—å¤æ‚æ€§ã€‚ Perplexityï¼šé€šè¿‡é¢„è®­ç»ƒæ¨¡å‹è®¡ç®—å›å¤çš„å›°æƒ‘åº¦ä½œä¸ºå¤æ‚æ€§æŒ‡æ ‡ï¼Œå›°æƒ‘å€¼è¶Šå¤§æ„å‘³ç€æ•°æ®æ ·æœ¬è¶Šéš¾ã€‚ Direct Scoringï¼šåˆ©ç”¨ChaGPTç»™æŒ‡ä»¤çš„å¤æ‚æ€§æ‰“åˆ†ã€‚ Instruction Nodeï¼šåˆ©ç”¨ChatGPTå°†æŒ‡ä»¤è½¬æ¢æˆè¯­ä¹‰æ ‘ï¼Œé€šè¿‡æ ‘çš„èŠ‚ç‚¹æ•°ä½œä¸ºå¤æ‚æ€§æŒ‡æ ‡ã€‚ Instag Complexityï¼šåˆ©ç”¨ChatGPTå¯¹éƒ¨åˆ†æ•°æ®è¿›è¡Œæ‰“æ ‡ç­¾ï¼Œå†è®­ç»ƒä¸€ä¸ªLlamaæ¨¡å‹ï¼Œå†åˆ©ç”¨è®­ç»ƒåçš„Llamaæ¨¡å‹å¯¹å…¨é‡æ•°æ®é¢„æµ‹ï¼Œæ ‡ç­¾è¶Šå¤šè¯´æ˜æ•°æ®çº¦å¤æ‚ã€‚ IFDï¼šæŒ‡ä»¤è·Ÿéšéš¾åº¦ä½œä¸ºå¤æ‚æ€§æŒ‡æ ‡ã€‚ DEITAè¯„ä¼°å¤æ‚æ€§çš„æ–¹æ³•ï¼Œä¸»è¦å…ˆå¯¹ä¸€ä¸ªå°è§„æ¨¡ç§å­æ•°æ®é›†ï¼ˆ2kï¼‰è¿›è¡Œæ•°æ®å¤æ‚æ€§æ‰©å±•ï¼Œå†åˆ©ç”¨ChatGPTå¯¹æ‰©å±•æ•°æ®è¿›è¡Œæ‰“åˆ†ï¼Œå¹¶è®­ç»ƒä¸€ä¸ªLlama1-7Bçš„æ¨¡å‹ï¼Œæœ€ååˆ©ç”¨è®­ç»ƒåçš„æ¨¡å‹å¯¹æ•°æ®çš„æ‰“åˆ†ä½œä¸ºå¤æ‚æ€§è¯„ä¼°æŒ‡æ ‡ã€‚\nè´¨é‡è¯„åˆ† # è´¨é‡è¯„ä¼°çš„æ–¹æ³•æœ‰ Random Selectionï¼šéšæœºé€‰æ‹©æ ·æœ¬ã€‚ Response Lengthï¼šé‡‡ç”¨è¾“å‡ºé•¿åº¦ä½œä¸ºè´¨é‡è¯„ä¼°æŒ‡æ ‡ã€‚ Direct Scoringï¼šåˆ©ç”¨ChatGPTç›´æ¥è¯„ä¼°å¯¹ç‰¹å®šæŒ‡ä»¤è¾“å‡ºç»“æœçš„å‡†ç¡®æ€§ã€‚ DEITAè¯„ä¼°è´¨é‡çš„æ–¹æ³•ï¼Œä¸è¯„ä¼°å¤æ‚æ€§æ–¹æ³•ä¸€è‡´ã€‚å…ˆå¯¹ä¸€ä¸ªå°è§„æ¨¡ç§å­æ•°æ®é›†ï¼ˆ2kï¼Œä¸å¤æ‚æ€§æ•°æ®ä¸€è‡´ï¼‰è¿›è¡Œæ•°æ®è´¨é‡æ‰©å±•ï¼Œå†åˆ©ç”¨ChatGPTå¯¹æ‰©å±•æ•°æ®è¿›è¡Œæ‰“åˆ†å¹¶è®­ç»ƒä¸€ä¸ªLlama1-7Bçš„æ¨¡å‹ï¼Œæœ€ååˆ©ç”¨è®­ç»ƒåçš„æ¨¡å‹å¯¹æ•°æ®çš„æ‰“åˆ†ä½œä¸ºè´¨é‡è¯„ä¼°æŒ‡æ ‡ã€‚\næ•°æ®è´¨é‡æ‰©å±•ï¼Œé€šè¿‡ç‰¹æ®Šçš„æç¤ºè¯åˆ©ç”¨ChatGPTå¯¹æ•°æ®çš„å›å¤éƒ¨åˆ†è¿›è¡Œæ”¹å†™ï¼Œä¸»è¦æ˜¯å¢å¼ºå›å¤çš„æœ‰ç”¨æ€§ã€ç›¸å…³æ€§ã€ä¸°å¯Œæ·±åº¦ã€åˆ›é€ åŠ›å’Œæä¾›é¢å¤–çš„ç»†èŠ‚æè¿°ã€‚\nå¤šæ ·æ€§ç­›é€‰ # å¤šæ ·æ€§ç­›é€‰æ–¹æ³•ï¼Œé¦–å…ˆå°†æ•°æ®æ± ä¸­çš„æ•°æ®æŒ‰ç…§å¤æ‚æ€§å’Œè´¨é‡çš„ç»¼åˆå¾—åˆ†ï¼ˆå¤æ‚æ€§åˆ†æ•°*è´¨é‡åˆ†æ•°ï¼‰è¿›è¡Œé™åºæ’åºï¼› ç„¶åæŒ‰é¡ºåºé€ä¸ªå–å‡ºæ ·æœ¬æ•°æ®x ï¼Œè®¡ç®—x ä¸ç­›é€‰æ± ä¸­ç›¸é‚»æœ€è¿‘çš„æ ·æœ¬ä¹‹é—´è·ç¦»å€¼ï¼Œå…¶ä¸­ï¼Œæ•°æ®åˆ©ç”¨Llama1-13Bæ¨¡å‹è¿›è¡Œå‘é‡è¡¨å¾ï¼Œè·ç¦»è®¡ç®—é‡‡ç”¨ä½™å¼¦ç›¸ä¼¼åº¦ã€‚ å¦‚æœè·ç¦»å€¼å°äº ræ—¶ï¼Œè®¤ä¸ºè¯¥æ ·æœ¬ä¸ç­›é€‰æ± ä¸­æ•°æ®ç›¸ä¼¼ç¨‹åº¦ä¸é«˜ï¼Œå¯ä»¥çº³å…¥ç­›é€‰æ± ï¼›å¦åˆ™ä¸çº³å…¥ç­›é€‰æ± ã€‚å½“ç­›é€‰æ± ä¸­æ ·æœ¬æ•°è¾¾åˆ°è§„å®šæ ·æœ¬ä¸ªæ•°ï¼Œå®Œæˆå¤šæ ·æ€§ç­›é€‰ã€‚\nå‚è€ƒ # å¦‚ä½•ä»æ•°æ®é›†ä¸­è‡ªåŠ¨è¯†åˆ«é«˜è´¨é‡çš„æŒ‡ä»¤æ•°æ®-IFDæŒ‡æ ‡çš„ä½¿ç”¨\nã€ŠFrom Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuningã€‹\nChatLawå°±è¿™ä¹ˆè®­çš„\né«˜è´¨é‡æŒ‡ä»¤æ•°æ®ç­›é€‰æ–¹æ³•-MoDS\nã€ŠMoDS: Model-oriented Data Selection for Instruction Tuningã€‹\nè´¨é‡ç­›é€‰ï¼Œ å¤šæ ·æ€§ç­›é€‰ï¼Œå¿…è¦æ€§ç­›é€‰\nDEITA-å¤§æ¨¡å‹æŒ‡ä»¤å¾®è°ƒçš„æ•°æ®é«˜æ•ˆç­›é€‰æ–¹æ³•\n1xx. DEITAï¼šèåˆå¤æ‚åº¦ã€è´¨é‡ã€å¤šæ ·æ€§çš„é«˜æ•ˆæ•°æ®ç­›é€‰\nå¤æ‚åº¦ã€è´¨é‡ã€å¤šæ ·æ€§\n1xx. å€¼å¾—ä¸€çœ‹çš„å¤§æ¨¡å‹é¢„è®­ç»ƒæ•°æ®é€‰æ‹©ç­–ç•¥æ€»ç»“ï¼šå…¼è¯»20240229å¤§æ¨¡å‹è¿›å±•æ—©æŠ¥ ã€ŠA Survey on Data Selection for Language Modelsã€‹\n"},{"id":83,"href":"/www6vAIGC/docs/FineTuning/PEFT/Soft-Prompt/PromptTuningPractice/","title":"(å®æˆ˜)PromptTuning","section":"Soft Prompt","content":"\nå‚è€ƒ # å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯å®æˆ˜ï¼ˆäºŒï¼‰-Prompt Tuning å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†ç»¼è¿°ï¼ˆäºŒï¼‰-BitFitã€Prefix Tuningã€Prompt Tuning peft_prompt_tuning_clm.ipynb\n"},{"id":84,"href":"/www6vAIGC/docs/Application/NL2SQL/chatBI-Ant/","title":"(èš‚èš)chatbi","section":"NL2SQL","content":"\nã€éš¾ç‚¹ å¤§é‡çš„æœ¯è¯­ã€é»‘è¯ã€ç»éªŒé€»è¾‘ã€‘\nã€æ•°æ®åº“ç†è§£ - ä¿åº•ã€‘\nã€ä¸šåŠ¡é€»è¾‘ - æ‘¸é«˜ã€‘\nã€ ç¬¬ä¸‰æ­¥æ˜¯å¿…é¡»çš„ sqllinking - è¦ç”¨ES å€’æ’ å¬å›ç›¸å…³çš„ è¡¨ï¼Œ åˆ—ï¼Œ UDF ï¼Œ å•å…ƒæ ¼\nå•å…ƒæ ¼é“¾æ¥ - è®©å¤§æ¨¡å‹çœ‹åˆ° fund_type = â€˜æ··åˆå‹â€™ ã€‘\nå‚è€ƒ # èš‚èšæ•°ç§‘AI Agent çŸ¥è¯†å·¥ç¨‹å®è·µ "},{"id":85,"href":"/www6vAIGC/docs/Prompt-Engineering/Prompt/","title":"(åŸç†)[Prompting]How to use","section":"Prompt Engineering","content":"\nä¹”å“ˆé‡Œæ²Ÿé€šè§†çª—-4 è±¡é™ # ä½ ä¸çŸ¥é“ï¼ŒGPTçŸ¥é“ # 1ã€å…ƒé—®é¢˜ï¼šæˆ‘æƒ³äº†è§£xxxxï¼Œæˆ‘åº”è¯¥å‘ä½ é—®å“ªäº›é—®é¢˜ï¼Ÿ\n2ã€è¯·ç»™æˆ‘åˆ—å‡ºxxxé¢†åŸŸ/è¡Œä¸šç›¸å…³çš„ï¼Œæœ€å¸¸ç”¨çš„50ä¸ªæ¦‚å¿µï¼Œå¹¶åšç®€å•è§£é‡Šã€‚å¦‚æœæœ‰è‹±æ–‡ç¼©å†™ï¼Œè¯·ç»™å‡ºå®Œæ•´çš„è‹±æ–‡è§£é‡Šã€‚\n3ã€è¯·è¯¦ç»†ä»‹ç»ä¸€ä¸‹elon muskçš„ä¸»è¦ç”Ÿå¹³äº‹è¿¹ã€‚è¯·è¯¦ç»†ä»‹ç»ä¸€ä¸‹teslaè¿™å®¶ä¼ä¸šçš„å‘å±•å†ç¨‹ã€‚\nä½ çŸ¥é“ï¼ŒGPTä¹ŸçŸ¥é“ # æ£€éªŒè®¤çŸ¥ï¼š 1ã€å¯¹äºxxxä¸»é¢˜/æŠ€èƒ½ï¼Œä½ è®¤ä¸ºå“ªäº›æ˜¯æˆ‘å¿…é¡»ç†è§£å’ŒæŒæ¡çš„æ ¸å¿ƒè¦ç‚¹ï¼Ÿ\n2ã€æˆ‘ç†è§£çš„xxxæ˜¯è¿™æ ·çš„ï¼Œä½ è§‰å¾—æˆ‘çš„ç†è§£å¯¹å—ï¼Ÿ\n3ã€æˆ‘å¯¹xxxæœ‰ä¸€äº›æƒ³æ³•ï¼Œä½ èƒ½å¸®æˆ‘æ‰¹åˆ¤æ€§åœ°åˆ†æä¸€ä¸‹è¿™äº›æƒ³æ³•çš„ä¼˜ç‚¹å’Œç¼ºç‚¹å—ï¼Ÿ\n4ã€æˆ‘æ­£åœ¨è€ƒè™‘xxxçš„å†³å®šï¼Œä½ èƒ½å¸®æˆ‘åˆ†æä¸€ä¸‹å¯èƒ½çš„ç»“æœå’Œå½±å“å—ï¼Ÿ\næ‰©å……è®¤çŸ¥ï¼š\n1ã€æˆ‘çŸ¥é“xxxçš„æ¦‚å¿µï¼Œæˆ‘æƒ³çŸ¥é“æ›´å¤šå…³äºxxxçš„ä¿¡æ¯ã€‚\n2ã€æˆ‘åœ¨xxxé—®é¢˜ä¸Šé‡åˆ°å›°éš¾ï¼Œä½ èƒ½æä¾›ä¸€äº›å¯èƒ½çš„è§£å†³æ–¹æ¡ˆæˆ–å»ºè®®å—ï¼Ÿ\n3ã€æˆ‘æƒ³è¦æ·±å…¥å­¦ä¹ xxxï¼Œä½ èƒ½æ¨èä¸€äº›è¿›é˜¶çš„å­¦ä¹ èµ„æºæˆ–å­¦ä¹ è·¯å¾„å—ï¼Ÿ\n4ã€æˆ‘æƒ³è¦åœ¨xxxé¢†åŸŸæœ‰æ‰€åˆ›æ–°ï¼Œä½ èƒ½æä¾›ä¸€äº›å¯å‘æˆ–æƒ³æ³•å—ï¼Ÿ\n5ã€æˆ‘æƒ³åœ¨xxxé¢†åŸŸæå‡è‡ªå·±ï¼Œä½ èƒ½æ ¹æ®æœ€æ–°çš„ç ”ç©¶å’Œè¶‹åŠ¿ç»™æˆ‘ä¸€äº›å»ºè®®å—ï¼Ÿ\n6ã€æˆ‘æ­£åœ¨è€ƒè™‘å­¦ä¹ xxxï¼Œä½ èƒ½ç»™æˆ‘ä¸€äº›å…³äºè¿™ä¸ªé¢†åŸŸæœªæ¥å‘å±•çš„è§‚ç‚¹å—ï¼Ÿ\n7ã€ï¼ˆèƒŒæ™¯ä¿¡æ¯xxxï¼‰ï¼Œæˆ‘è¦åšå…³äºxxxçš„ç ”ç©¶ï¼Œæˆ‘è®¤ä¸ºåŸå› æ˜¯ï¼Œè¿˜æœ‰å…¶ä»–å¯èƒ½çš„åŸå› å—ï¼Ÿç»™å‡ºä¸€äº›å¯èƒ½çš„ç ”ç©¶å‡è®¾ã€‚\n8ã€æˆ‘æ˜¯ä¸€ä¸ªxxæ–°æ‰‹ï¼Œé©¬ä¸Šè¦é‡‡è®¿è¿™ä¸ªè¡Œä¸šçš„èµ„æ·±å¤§ä½¬ï¼Œæˆ‘åº”è¯¥å‘ä»–è¯·æ•™å“ªäº›æœ‰ä»·å€¼çš„é—®é¢˜ï¼Ÿ\nä½ çŸ¥é“ï¼ŒGPTä¸çŸ¥é“ # ä»‹ç»èƒŒæ™¯ç°è±¡ä¹‹åå¯ä»¥å‘gptå‘é—®ï¼Œä½ æ€ä¹ˆçœ‹å¾…è¿™ç§ç°è±¡ï¼Ÿå¯èƒ½çš„åŸå› æœ‰å“ªäº›ï¼Ÿè¿™ä¼šå¯¹xxxäº§ç”Ÿä»€ä¹ˆæ ·çš„å½±å“ï¼Ÿä½ è§‰å¾—xxxåº”è¯¥æ€ä¹ˆåšï¼Ÿ\nä½ å’ŒGPTéƒ½ä¸çŸ¥é“ # å¦‚æœxxxï¼Œè¿™å¯¹ç¤¾ä¼šä¼šäº§ç”Ÿä»€ä¹ˆå½±å“ï¼Ÿ\nè¾¾å…‹æ•ˆåº” # æ£€éªŒè‡ªå·±è®¤çŸ¥/èƒ½åŠ›æ°´å¹³æé—®å¥å¼ # 1ã€ä¸ºäº†æµ‹è¯•æˆ‘å¯¹xxxçš„ç†è§£ç¨‹åº¦ï¼Œä½ ä¼šé—®æˆ‘ä»€ä¹ˆé—®é¢˜æ¥æ£€éªŒæˆ‘çš„æ°´å¹³ï¼Œæœ€å°‘10ä¸ªã€‚\n2ã€æˆ‘æ˜¯xxé¢†åŸŸçš„ä¸“å®¶ï¼Œä½ ä¼šé—®æˆ‘å“ªäº›é—®é¢˜æ¥æ£€éªŒæˆ‘çš„ä¸“ä¸šæ°´å¹³ï¼Ÿ\n3ã€è¿½é—®ä¸€å¥ï¼Œè¿™äº›æˆ‘éƒ½æ‡‚ï¼Œè¿˜æœ‰æ›´ä¸“ä¸šæ›´ç»†æ›´æ·±çš„é—®é¢˜å—ï¼Ÿ\n4ã€ä½ é—®æˆ‘ç­”çš„æ¸¸æˆ\næ‰©å±•è‡ªå·±èƒ½åŠ›è¾¹ç•Œçš„æé—®å¥å¼æˆ‘å·²ç»å¾ˆç²¾é€šxxxäº†ï¼Œæˆ‘æƒ³çŸ¥é“æˆ‘æ˜¯å¦è¿˜æœ‰éœ€è¦å­¦ä¹ çš„åœ°æ–¹ï¼Ÿç„¶åä¸åœçš„é—®ï¼Œè¿˜æœ‰å‘¢è¿˜æœ‰å‘¢ï¼Ÿ\nçŸ¥é“åšåˆ° # è®©GPTå®Œæˆå…·ä½“ä»»åŠ¡\n1ã€æˆ‘æƒ³åšxxxï¼Œä½ èƒ½ç»™æˆ‘æä¾›ä»€ä¹ˆå¸®åŠ©ï¼Ÿ\n2ã€æˆ‘æƒ³è¦ä½ åšxxxï¼Œæˆ‘åº”è¯¥ç»™ä½ è¾“å…¥ä»€ä¹ˆä¿¡æ¯ï¼Ÿ\n3ã€ç›´æ¥ä¸‹æŒ‡ä»¤\nè§’è‰²å…³ç³» # æ¨¡æ‹Ÿè™šæ‹Ÿäººç‰© æ¨¡æ‹Ÿåäºº æ¨¡æ‹Ÿä¸€æ®µå…³ç³» æ¨¡æ‹Ÿå¤šä¸ªå…·ä½“çš„äºº æ¨¡æ‹Ÿå¤šç±»äºº é€šç”¨ # æ²Ÿé€šæ¨¡å¼ # prompt = å®šä¹‰è§’è‰²+èƒŒæ™¯ä¿¡æ¯+ä»»åŠ¡ç›®æ ‡+è¾“å‡ºè¦æ±‚\nå½’çº³ # ä½¿ç”¨markdownæ ¼å¼å†™å¯Œçˆ¸çˆ¸ç©·çˆ¸çˆ¸çš„æ€ç»´å¯¼å›¾ï¼Œä»¥ä»£ç æ ¼å¼è¾“å‡º ä»¥è„‘å›¾çš„æ–¹å¼å½’çº³ä¸Šæ–‡ è¯·ç”¨æçº²çš„æ–¹å¼æ¥å½’çº³ä¸Šæ–‡ è¯·ç”¨ç®€ç»ƒçš„åˆ—æçº²çš„æ–¹å¼æ¥å½’çº³ä¸Šæ–‡ æ€ç»´é“¾ # æ²¡å•¥ç”¨ # è¯·ç”¨ç®€å•çš„è¯­å¥æ¥å½’çº³ä¸Šæ–‡ï¼Œå½’çº³çš„è¯­å¥å¯ä»¥ç”Ÿæˆè„‘å›¾\nè¯·ç”¨é‡‘å­—å¡”æ€ç»´çš„æ–¹å¼æ¥ç®€å•çš„å½’çº³ä¸Šæ–‡\nPrompt - How to use # Learn Prompting *** **\nChatgpt ShortCut ChatGPT Shortcut Awesome ChatGPT Prompts\nsnackprompt.com ***\nflowgpt ***\nprompthero\npublicprompts\nhttps://learningprompt.wiki/ prompt å­¦ä¹ æ•™ç¨‹\nPrompt å¤§å…¨\næç¤ºæŒ‡ä»¤åº“ æ±‡æ€»\nå‚è€ƒ # å­¦å®Œè¿™ä¸ªè§†é¢‘ï¼Œç®€å†åŠ ä¸€æ¡ï¼šç†Ÿç»ƒæŒæ¡ChatGPTè§£å†³å¤æ‚é—®é¢˜ï½œChatGPTä½¿ç”¨æ•™ç¨‹ ***\n"},{"id":86,"href":"/www6vAIGC/docs/RAG/Pattern/KG-RAG/RAGKG/","title":"RAG KG","section":"KG-RAG","content":"\nVector+KG RAG[15][16] # RAG å¤šè·³é—®é¢˜ # å‚è€ƒ # RAG å¤šè·³é—®é¢˜ # 1xx. Knowledge Graphs \u0026amp; LLMs: Multi-Hop Question Answering\nçŸ¥è¯†å›¾è°±å’Œ LLMï¼šå¤šè·³é—®ç­”-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘\nLLMsä¹‹KG-RAGï¼šKG-RAG/GraphRAG(åŸºäºçŸ¥è¯†å›¾è°±çš„RAGç³»ç»Ÿ)çš„ç®€ä»‹(å¯ä»¥è§£å†³å¤šè·³é—®é¢˜/åŒæ—¶æ”¯æŒç»“æ„åŒ–å’Œéç»“æ„åŒ–æ•°æ®æŸ¥è¯¢)ã€ç»éªŒæŠ€å·§ã€æ¡ˆä¾‹åº”ç”¨ä¹‹è¯¦ç»†æ”»ç•¥-CSDNåšå®¢\n1xx. MultiHop-RAGï¼šå¤šè·³æŸ¥è¯¢çš„åŸºå‡†æ£€ç´¢å¢å¼ºç”Ÿæˆ_ragå¤šè·³æŸ¥è¯¢-CSDNåšå®¢\nLLM+KG çŸ¥è¯†å›¾è°± # Enhanced QA Integrating Unstructured Knowledge Graph Using Neo4j and LangChain\nUsing a Knowledge Graph to implement a DevOps RAG application\n1xx. å¤§æ¨¡å‹è¾…åŠ©å›¾è°±æ„å»ºçš„4ä¸ªç­–ç•¥å¯¹æ¯”ï¼šå…¼çœ‹å¤§æ¨¡å‹ä¸çŸ¥è¯†å›¾è°±ç»“åˆçš„3ä¸ªç»¼è¿° "},{"id":87,"href":"/www6vAIGC/docs/RAG/Overview/RAGSFT/","title":"RAG vs SFT","section":"Overview","content":"\nRAG vs FT[1] # RAG vs å¾®è°ƒ[åœºæ™¯] # åŠ¨æ€æ•°æ®ï¼šRAG\næ¨¡å‹èƒ½åŠ›å®šåˆ¶ï¼šå¾®è°ƒ\nå¹»è§‰ï¼šRAG \u0026gt; å¾®è°ƒ\nå¯è§£é‡Šæ€§ï¼šRAG\næˆæœ¬ï¼šRAG\nä¾èµ–é€šç”¨èƒ½åŠ›ï¼šRAG\nâ€‹ å¾®è°ƒä¼šæœ‰ç¾éš¾æ€§çš„é—å¿˜\nå»¶è¿Ÿï¼šå¾®è°ƒ â€‹ ragçš„æµç¨‹é•¿\næ™ºèƒ½è®¾å¤‡ï¼šå¾®è°ƒ ã€ragå’Œå¾®è°ƒå¯ä»¥ä¸€èµ·ä½¿ç”¨ã€‘\nåº”ç”¨ Case # A: æŠ•èµ„ç†è´¢è§„åˆ’å¸ˆ [ç”¨RAG]\nå¤„ç†åŠ¨æ€æ•°æ®ï¼šRAG å¾ˆå¼ºçš„å¯¹è¯èƒ½åŠ›ï¼šRAG é‡‘èèƒ½åŠ›ï¼šå¾®è°ƒ Ã— B: é‡‘èä¿¡æ¯æŠ½å–Bot [ç”¨å¾®è°ƒ]\nå¾ˆå¼ºçš„æŠ½å–èƒ½åŠ›ï¼šå¾®è°ƒ [ç‰¹å®šçš„èƒ½åŠ›] é‡‘èèƒ½åŠ› C: é”€å”®æœºå™¨äºº [ç”¨RAG+å¾®è°ƒ]\nå¤šè½®å¯¹è¯/åŠ¨æ€ï¼šRAG é”€å”®æŠ€å·§/è¯­æ°”ï¼šå¾®è°ƒ RAG vs FT [2] # todo: æœ‰ä¸­æ–‡ç¿»è¯‘çš„å›¾ç‰‡\nå‚è€ƒ # å¤§æ¨¡å‹é¡¹ç›®é€‰æ‹©RAGè¿˜æ˜¯å¾®è°ƒï¼šä¸‰ä¸ªæ¡ˆä¾‹ v å¤§æ¨¡å‹é¡¹ç›®é€‰æ‹©RAGè¿˜æ˜¯å¾®è°ƒï¼šå…«ä¸ªåˆ¤æ–­ä¾æ® v\n#1ã€ŠRetrieval-Augmented Generation for Large Language Models: A Surveyã€‹\né¢å‘å¤§è¯­è¨€æ¨¡å‹çš„æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ï¼šç»¼è¿° [è¯‘] ç¿»è¯‘\nLLMä¹‹RAGç†è®ºï¼ˆäºŒï¼‰| RAGç»¼è¿°è®ºæ–‡è¯¦è§£\nåŒæµå¤§å­¦å‘å¸ƒæœ€æ–°æ£€ç´¢å¢å¼º(RAG)çš„LLMç”ŸæˆæŠ€æœ¯ç»¼è¿°\né¢å‘å¤§æ¨¡å‹çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç»¼è¿°\nâ€‹ å¤§è¯­è¨€æ¨¡å‹çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æ–¹æ³•\nLLMçŸ¥è¯†å¢å¼ºï¼šRAG\u0026amp;å¾®è°ƒï¼Ÿå¾®è½¯ç»™å‡ºéƒ¨åˆ†ç­”æ¡ˆ microsoft RAG æˆ– Fine Tume - ä¸ºæ‚¨çš„ç”¨ä¾‹é€‰æ‹©æ­£ç¡®æ–¹æ³•çš„æƒå¨æŒ‡å— "},{"id":88,"href":"/www6vAIGC/docs/Prompt-Engineering/PromptingGrok/","title":"(åŸç†)Grok æç¤ºæ¡†æ¶","section":"Prompt Engineering","content":" Grok æç¤ºæ¡†æ¶ # çœ‹çœ‹Gorkçš„æç¤ºè¯5ç§Promptæ¡†æ¶ï¼Œå……åˆ†å‘æŒ¥ Grok çš„æ½œåŠ›ï¼š\nR-T-Fï¼ˆè§’è‰² - ä»»åŠ¡ - æ ¼å¼ï¼‰ T-A-Gï¼ˆä»»åŠ¡ - è¡ŒåŠ¨ - ç›®æ ‡ï¼‰ B-A-Bï¼ˆä¹‹å‰ - ä¹‹å - æ¡¥æ¢ï¼‰ C-A-R-Eï¼ˆèƒŒæ™¯ - è¡ŒåŠ¨ - ç»“æœ - ç¤ºä¾‹ï¼‰ R-I-S-Eï¼ˆè§’è‰² - è¾“å…¥ - æ­¥éª¤ - æœŸæœ›ï¼‰ å‚è€ƒ # Grok æç¤ºæ¡†æ¶ï¼ˆGrok Prompt Frameworksï¼‰\n"},{"id":89,"href":"/www6vAIGC/docs/Deep-Research/%E5%AE%9E%E7%8E%B0/OpenManus/","title":"(å®ç°)OpenManus *","section":"å®ç°","content":" OpenManus # (å®ç°)OpenManus\n"},{"id":90,"href":"/www6vAIGC/docs/Agent/Platform/Dify-deploy/","title":"(å®è·µ)Dify ç”Ÿäº§éƒ¨ç½² *","section":"Platform *","content":"\nå‚è€ƒ # ã€æ·±åº¦ã€‘ä¼ä¸š AI è½åœ°å®è·µï¼ˆå››ï¼‰ï¼šå¦‚ä½•æ„å»ºç«¯åˆ°ç«¯çš„ AI åº”ç”¨è§‚æµ‹ä½“ç³»\n"},{"id":91,"href":"/www6vAIGC/docs/Deep-Research/%E5%AE%9E%E7%8E%B0/researchSystem/","title":"(å®è·µ)Research system[Anthropic]","section":"å®ç°","content":" â€œResearchâ€åŠŸèƒ½æ¶æ„æ¦‚è§ˆ[1] # Prompt engineering and evaluations for research agents[1] # åœ¨å¼€å‘è¿‡ç¨‹ä¸­ï¼Œä»–ä»¬æ€»ç»“äº†8ä¸ªå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„è®¾è®¡åŸåˆ™ï¼š\nåƒæ™ºèƒ½ä½“ä¸€æ ·æ€è€ƒ\nç”¨æ¨¡æ‹Ÿå’Œå¯è§†åŒ–å·¥å…·è§‚å¯Ÿæ™ºèƒ½ä½“å†³ç­–ï¼ŒåŠæ—¶å‘ç°å’Œä¿®æ­£å¤±è´¥æ¨¡å¼ï¼Œç†è§£æç¤ºè¯å¯¹è¡Œä¸ºçš„å½±å“ã€‚\næ•™ä¼šä¸»æ§æ™ºèƒ½ä½“å¦‚ä½•åˆ†å·¥\nä¸»æ™ºèƒ½ä½“éœ€ä¸ºæ¯ä¸ªå­æ™ºèƒ½ä½“åˆ†é…æ¸…æ™°ç›®æ ‡ã€è¾“å‡ºæ ¼å¼ã€å·¥å…·æŒ‡å¼•å’Œä»»åŠ¡è¾¹ç•Œï¼Œé¿å…é‡å¤æˆ–é—æ¼ã€‚\næ ¹æ®ä»»åŠ¡å¤æ‚åº¦åˆ†é…èµ„æº\nåœ¨æç¤ºè¯ä¸­åµŒå…¥â€œè§„æ¨¡è§„åˆ™â€ï¼šç®€å•ä»»åŠ¡ç”¨å°‘é‡æ™ºèƒ½ä½“å’Œå·¥å…·è°ƒç”¨ï¼Œå¤æ‚ä»»åŠ¡ç”¨æ›´å¤šèµ„æºï¼Œé˜²æ­¢èµ„æºæµªè´¹æˆ–è¿‡åº¦æŠ•å…¥ã€‚\nå·¥å…·è®¾è®¡ä¸é€‰æ‹©è‡³å…³é‡è¦\nå·¥å…·æ¥å£è¦åƒäººæœºç•Œé¢ä¸€æ ·æ¸…æ™°ï¼Œæè¿°æ˜ç¡®ï¼Œé¿å…è¯¯ç”¨ã€‚æ™ºèƒ½ä½“éœ€å…ˆè¯„ä¼°æ‰€æœ‰å¯ç”¨å·¥å…·ï¼ŒåŒ¹é…ç”¨æˆ·æ„å›¾é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ã€‚\nè®©æ™ºèƒ½ä½“è‡ªæˆ‘æ”¹è¿›\nåˆ©ç”¨å¤§æ¨¡å‹è‡ªèº«èƒ½åŠ›ä¼˜åŒ–æç¤ºè¯å’Œå·¥å…·æè¿°ï¼Œé€šè¿‡â€œå·¥å…·æµ‹è¯•æ™ºèƒ½ä½“â€ä¸æ–­å‘ç°å’Œä¿®æ­£å·¥å…·ä½¿ç”¨ä¸­çš„é—®é¢˜ã€‚\nå…ˆå¹¿åæ·±\næœç´¢ç­–ç•¥åº”å…ˆç”¨å®½æ³›æŸ¥è¯¢æ¢ç´¢å…¨å±€ï¼Œå†é€æ­¥èšç„¦ç»†èŠ‚ï¼Œé¿å…ä¸€å¼€å§‹å°±é™·å…¥æ­»èƒ¡åŒã€‚\nå¼•å¯¼æ€è€ƒè¿‡ç¨‹\né€šè¿‡â€œæ‰©å±•æ€è€ƒæ¨¡å¼â€è®©æ™ºèƒ½ä½“æ˜¾å¼è§„åˆ’ã€è¯„ä¼°å’Œè°ƒæ•´ç­–ç•¥ï¼Œæå‡é€‚åº”æ€§å’Œæ¨ç†èƒ½åŠ›ã€‚\nå¹¶è¡Œå·¥å…·è°ƒç”¨æå¤§æå‡æ•ˆç‡\nä¸»æ™ºèƒ½ä½“å’Œå­æ™ºèƒ½ä½“éƒ½åº”å¹¶è¡Œè°ƒç”¨å·¥å…·ï¼Œæ˜¾è‘—ç¼©çŸ­ç ”ç©¶æ—¶é—´ï¼Œæå‡è¦†ç›–é¢å’Œæ·±åº¦ã€‚\nä»¥åŠè¯„æµ‹ä¸å·¥ç¨‹åŒ–çš„6æ¡å®è·µç»éªŒï¼š\nç»“æœå¯¼å‘è¯„æµ‹ï¼šå…³æ³¨æœ€ç»ˆç»“æœæ˜¯å¦æ­£ç¡®ï¼Œè€Œéè¿‡ç¨‹æ˜¯å¦å®Œå…¨æŒ‰é¢„è®¾æ‰§è¡Œã€‚ LLM è‡ªåŠ¨è¯„æµ‹ç»“åˆäººå·¥æ£€æŸ¥ï¼šç”¨å¤§æ¨¡å‹è‡ªåŠ¨æ‰“åˆ†ï¼Œäººå·¥è¡¥å……å‘ç°è¾¹ç•Œé—®é¢˜ï¼Œå¿«é€Ÿè¿­ä»£ä¼˜åŒ–ã€‚ çŠ¶æ€ç®¡ç†ä¸é”™è¯¯æ¢å¤ï¼šæ™ºèƒ½ä½“éœ€æŒä¹…åŒ–çŠ¶æ€ï¼Œä¼˜é›…å¤„ç†é”™è¯¯ï¼Œä¸èƒ½ç®€å•é‡å¯ã€‚ ç°åº¦éƒ¨ç½²ä¸å‡çº§ï¼šé‡‡ç”¨æ¸è¿›å¼éƒ¨ç½²ï¼Œé¿å…å½±å“æ­£åœ¨è¿è¡Œçš„æ™ºèƒ½ä½“ã€‚ é•¿å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†ï¼šç”¨æ‘˜è¦ã€å¤–éƒ¨è®°å¿†ç­‰æœºåˆ¶é˜²æ­¢ä¸Šä¸‹æ–‡æº¢å‡ºã€‚ å­æ™ºèƒ½ä½“ç›´æ¥äº§å‡ºç»“æ„åŒ–ç»“æœï¼šå¦‚ä»£ç ã€æŠ¥å‘Šç­‰ï¼Œå‡å°‘ä¿¡æ¯æŸå¤±å’Œ Token æ¶ˆè€—ã€‚ Cookbookæç¤ºç¤ºä¾‹ï¼šhttps://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents/prompts\næ™ºèƒ½ä½“çš„æœ‰æ•ˆè¯„ä¼° # todo\nç”Ÿäº§å¯é æ€§ä¸å·¥ç¨‹æŒ‘æˆ˜ # todo\nå‚è€ƒ # Anthropicè°ˆå¦‚ä½•æ„å»ºç”Ÿäº§çº§å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ How we built our multi-agent research system åŸæ–‡\n1xx. [LangGraph] gemini å¼€æºå…¨æ ˆ deep research åŠ Anthropic multi-agent research system å¯¼è¯» https://github.com/chunhuizhang/prompts_for_academic/blob/main/deepresearch/multi-agent research system.ipynb\n1xx. ä¸€æ–‡è¯»æ‡‚ Claude Researchï¼šå¤šæ™ºèƒ½ä½“ç³»ç»Ÿå¦‚ä½•é‡å¡‘å¤æ‚ä»»åŠ¡å¤„ç†ï¼Ÿ\n"},{"id":92,"href":"/www6vAIGC/docs/Agent/Practice/Agent12Factor/","title":"Agent 12-Factor +","section":"Practice","content":"\nAgent 12-Factor # Agent 12-Factor\n"},{"id":93,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Tool-use/AgentToolGorilla/","title":"(Work)[SFT]Gorilla","section":"Tool use","content":"\nè®ºæ–‡ # è®ºæ–‡åœ°å€ Gorilla: Large Language Model Connected with Massive APIs\nå¼€æºåœ°å€ gorilla git\næ–¹æ³•è®º[1] # æ•°æ®é›†æ”¶é›† # APIæ–‡æ¡£\nHuggingFaceå¹³å°æ‰˜ç®¡å’Œæä¾›äº†çº¦203,681ä¸ªæ¨¡å‹ã€‚ç„¶è€Œï¼Œå…¶ä¸­è®¸å¤šæ¨¡å‹çš„æ–‡æ¡£è´¨é‡è¾ƒå·®ï¼Œç¼ºä¹ä¾èµ–é¡¹ï¼Œæ¨¡å‹å¡ä¸­æ²¡æœ‰ä¿¡æ¯ç­‰é—®é¢˜ã€‚ ä¸ºäº†ç­›é€‰å‡ºè´¨é‡è¾ƒå¥½çš„æ¨¡å‹ï¼Œä»æ¯ä¸ªé¢†åŸŸé€‰æ‹©äº†å‰20ä¸ªæ¨¡å‹ã€‚è€ƒè™‘äº†å¤šæ¨¡æ€æ•°æ®é¢†åŸŸçš„7ä¸ªé¢†åŸŸï¼ŒCVé¢†åŸŸçš„8ä¸ªé¢†åŸŸï¼ŒNLPé¢†åŸŸçš„12ä¸ªé¢†åŸŸï¼ŒéŸ³é¢‘é¢†åŸŸçš„5ä¸ªé¢†åŸŸï¼Œè¡¨æ ¼æ•°æ®é¢†åŸŸçš„2ä¸ªé¢†åŸŸå’Œå¼ºåŒ–å­¦ä¹ é¢†åŸŸçš„2ä¸ªé¢†åŸŸã€‚ ç»è¿‡ç­›é€‰ï¼Œä»HuggingFaceè·å¾—äº†æ€»å…±925ä¸ªæ¨¡å‹ã€‚ä»TensorFlow Hubè·å¾—äº†801ä¸ªæ¨¡å‹ï¼Œå¹¶ä»Torch Hubè·å¾—äº†95ä¸ªæ¨¡å‹ã€‚ è¿™äº›æ¨¡å‹çš„ä¿¡æ¯è¢«è½¬æ¢ä¸ºJSONå¯¹è±¡ï¼Œå…¶ä¸­åŒ…å«äº†é¢†åŸŸï¼ˆdomainï¼‰ã€æ¡†æ¶ï¼ˆframeworkï¼‰ã€åŠŸèƒ½ï¼ˆfunctionalityï¼‰ã€APIåç§°ï¼ˆapi_nameï¼‰ã€APIè°ƒç”¨ï¼ˆapi_callï¼‰ã€APIå‚æ•°ï¼ˆapi_argumentsï¼‰ã€ç¯å¢ƒè¦æ±‚ï¼ˆenvironment_requirementsï¼‰ã€ç¤ºä¾‹ä»£ç ï¼ˆexample_codeï¼‰ã€æ€§èƒ½ï¼ˆperformanceï¼‰å’Œæè¿°ï¼ˆdescriptionï¼‰ç­‰å­—æ®µã€‚ é€‰æ‹©è¿™äº›å­—æ®µæ˜¯ä¸ºäº†å°†å…¶æ³›åŒ–åˆ°æœºå™¨å­¦ä¹ é¢†åŸŸä¹‹å¤–çš„å…¶ä»–é¢†åŸŸï¼ŒåŒ…æ‹¬RESTful APIè°ƒç”¨ã€‚ æ€»è€Œè¨€ä¹‹ï¼Œé€šè¿‡ç­›é€‰å’Œæ•´ç†ï¼Œä»HuggingFaceã€TensorFlow Hubå’ŒTorch Hubç­‰å¹³å°è·å–äº†æ€»å…±1,645ä¸ªæ¨¡å‹çš„ä¿¡æ¯ï¼Œå¹¶å°†å…¶ä»¥JSONå¯¹è±¡çš„å½¢å¼è¿›è¡Œäº†è®°å½•å’Œæè¿°ã€‚è¿™äº›ä¿¡æ¯åŒ…æ‹¬æ¨¡å‹çš„é¢†åŸŸã€æ¡†æ¶ã€åŠŸèƒ½ã€APIè°ƒç”¨ç¤ºä¾‹ã€æ€§èƒ½ç­‰ï¼Œä»¥ä¾¿åœ¨æœºå™¨å­¦ä¹ å’Œå…¶ä»–é¢†åŸŸä¸­ä½¿ç”¨å’Œå‚è€ƒã€‚ æŒ‡ä»¤ç”Ÿæˆ ï¼ˆInstruction Generation ï¼‰\nåœ¨self-instructèŒƒä¾‹[42]çš„æŒ‡å¯¼ä¸‹ï¼Œä½¿ç”¨GPT-4ç”Ÿæˆäº†åˆæˆæŒ‡ä»¤æ•°æ®ã€‚ æä¾›äº†ä¸‰ä¸ªä¸Šä¸‹æ–‡ç¤ºä¾‹å’Œä¸€ä¸ªå‚è€ƒAPIæ–‡æ¡£ï¼Œè¦æ±‚æ¨¡å‹ç”Ÿæˆè°ƒç”¨APIçš„çœŸå®ä¸–ç•Œç”¨ä¾‹ã€‚ æ˜ç¡®æŒ‡ç¤ºæ¨¡å‹åœ¨åˆ›å»ºæŒ‡ä»¤æ—¶ä¸è¦ä½¿ç”¨ä»»ä½•APIåç§°æˆ–æç¤ºã€‚ ä¸ºæ¯ä¸ªä¸‰ä¸ªæ¨¡å‹ä¸­å¿ƒæ„å»ºäº†å…­ä¸ªç¤ºä¾‹ï¼ˆæŒ‡ä»¤-APIå¯¹ï¼‰ï¼Œå…±è®¡18ä¸ªç‚¹ï¼Œè¿™äº›æ•°æ®æ˜¯æ‰‹åŠ¨ç”Ÿæˆæˆ–ä¿®æ”¹çš„ã€‚ å¯¹äº1,645ä¸ªAPIæ•°æ®ç‚¹ä¸­çš„æ¯ä¸€ä¸ªï¼Œä»ç›¸åº”çš„å…­ä¸ªæŒ‡ä»¤ç¤ºä¾‹ä¸­éšæœºé€‰æ‹©3ä¸ªï¼Œç”Ÿæˆæ€»å…±10ä¸ªæŒ‡ä»¤-APIå¯¹ã€‚ å¼ºè°ƒåªéœ€è¦ä½¿ç”¨GPT-4ç”ŸæˆæŒ‡ä»¤ï¼Œå¯ä»¥ä¸å¼€æºæ›¿ä»£æ–¹æ¡ˆï¼ˆå¦‚LLaMAã€Alpacaç­‰ï¼‰è¿›è¡Œäº¤æ¢ã€‚ æ€»è€Œè¨€ä¹‹ï¼Œé€šè¿‡ä½¿ç”¨GPT-4ç”ŸæˆæŒ‡ä»¤ï¼Œå¹¶ç»“åˆä¸Šä¸‹æ–‡ç¤ºä¾‹å’Œå‚è€ƒAPIæ–‡æ¡£ï¼Œåœ¨æ¯ä¸ªæ¨¡å‹ä¸­å¿ƒæ„å»ºäº†å…­ä¸ªç¤ºä¾‹ï¼Œå…±è®¡18ä¸ªç‚¹ã€‚è¿™äº›ç¤ºä¾‹è¢«ç”¨äºç”Ÿæˆ1,645ä¸ªAPIæ•°æ®ç‚¹ä¸­çš„æ¯ä¸€ä¸ªçš„æŒ‡ä»¤-APIå¯¹ï¼Œç”Ÿæˆæ€»å…±10ä¸ªå¯¹åº”å…³ç³»ã€‚ä¸å¼€æºæ›¿ä»£æ–¹æ¡ˆç›¸æ¯”ï¼ŒGPT-4çš„æŒ‡ä»¤ç”ŸæˆåŠŸèƒ½è¢«åº”ç”¨åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ã€‚ Gorilla # å¸¦æœ‰çº¦æŸçš„APIè°ƒç”¨ï¼ˆAPI Call with Constraintsï¼‰\nAPIè°ƒç”¨é€šå¸¸å…·æœ‰å›ºæœ‰çš„çº¦æŸï¼Œè¿™äº›çº¦æŸè¦æ±‚LLMä¸ä»…ç†è§£APIè°ƒç”¨çš„åŠŸèƒ½ï¼Œè¿˜è¦æ ¹æ®ä¸åŒçš„çº¦æŸå‚æ•°å¯¹è°ƒç”¨è¿›è¡Œåˆ†ç±»ã€‚ æœºå™¨å­¦ä¹ APIè°ƒç”¨ä¸­å¸¸è§çš„çº¦æŸé›†æ˜¯å‚æ•°å¤§å°å’Œå‡†ç¡®æ€§çš„ä¸‹é™ã€‚è¿™äº›çº¦æŸè¦æ±‚LLMèƒ½å¤Ÿæ ¹æ®æç¤ºç†è§£å’Œå›ç­”é—®é¢˜ï¼Œä¾‹å¦‚æ ¹æ®æç¤ºé€‰æ‹©å‚æ•°å°‘äº10Mçš„å›¾åƒåˆ†ç±»æ¨¡å‹ï¼Œå¹¶ä¸”è‡³å°‘ä¿æŒ70%çš„ImageNetå‡†ç¡®ç‡ã€‚ å¯¹LLMæ¥è¯´ï¼Œç†è§£å’Œæ¨ç†å‡ºè¯·æ±‚ä¸­åµŒå…¥çš„å„ç§çº¦æŸæ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ã€‚LLMéœ€è¦ç»†è‡´åœ°ç†è§£ç”¨æˆ·çš„åŠŸèƒ½æè¿°ï¼Œå¹¶èƒ½å¤Ÿæ­£ç¡®åœ°å¤„ç†ä¼´éšè¿™äº›è°ƒç”¨çš„å¤æ‚çº¦æŸã€‚ è¿™ä¸ªæŒ‘æˆ˜å‡¸æ˜¾äº†åœ¨å®é™…APIè°ƒç”¨ä¸­å¯¹LLMçš„å¤æ‚è¦æ±‚ã€‚ä»…ä»…ç†è§£APIè°ƒç”¨çš„åŸºæœ¬åŠŸèƒ½æ˜¯ä¸å¤Ÿçš„ï¼Œæ¨¡å‹è¿˜å¿…é¡»èƒ½å¤Ÿåº”å¯¹ä¼´éšè¿™äº›è°ƒç”¨çš„çº¦æŸï¼Œå¦‚å‚æ•°å¤§å°å’Œå‡†ç¡®æ€§è¦æ±‚ã€‚ æ€»è€Œè¨€ä¹‹ï¼Œåœ¨æœºå™¨å­¦ä¹ APIè°ƒç”¨ä¸­ï¼ŒLLMé¢ä¸´ç€ç†è§£å’Œå¤„ç†çº¦æŸçš„æŒ‘æˆ˜ã€‚é™¤äº†ç†è§£APIè°ƒç”¨çš„åŸºæœ¬åŠŸèƒ½å¤–ï¼ŒLLMè¿˜éœ€è¦èƒ½å¤Ÿè¯†åˆ«å’Œæ»¡è¶³ä¼´éšè°ƒç”¨çš„çº¦æŸè¦æ±‚ï¼Œå¦‚å‚æ•°å¤§å°å’Œå‡†ç¡®æ€§çš„ä¸‹é™ã€‚è¿™éœ€è¦æ¨¡å‹å…·å¤‡æ›´ç»†è‡´çš„ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œä»¥æ»¡è¶³å®é™…APIè°ƒç”¨çš„å¤æ‚éœ€æ±‚ã€‚ å‚è€ƒ # Gorillaï¼šä¸å¤§è§„æ¨¡APIç›¸è¿çš„å¤§å‹è¯­è¨€æ¨¡å‹ *** 1xx. Gorillaï¼šé“¾æ¥æµ·é‡APIçš„å¤§å‹è¯­è¨€æ¨¡å‹ V 1xx. å¤§çŒ©çŒ©ï¼ˆGorillaï¼‰ğŸ¦ï¼Œè¿æ¥å¤§é‡ API çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œèƒ½æˆä¸ºæœªæ¥AIåº”ç”¨çš„æ ¸å¿ƒä¹ˆï¼Ÿ ***\n1xx. Gorilla: Large Language Model Connected with Massive APIs 1xx. Gorilla blog\n"},{"id":94,"href":"/www6vAIGC/docs/Application/NL2SQL/opensource/","title":"(å¼€æº)NL2SQL","section":"NL2SQL","content":" å‚è€ƒ # 1xx. å¤§æ¨¡å‹å†æ€»ç»“åŠChatSQLå®è·µæ¡ˆä¾‹åˆ†äº«ï¼šå¤§æ¨¡å‹è®­ç»ƒæ•°æ®åŠå·¥å…·çš„5å¼ è„‘å›¾æ€»ç»“åŠChatSQLå¼€æºé¡¹ç›®å®ç°è§£æ *\n1xx. å¤§æ¨¡å‹Text2SQLä¸»æµæ•°æ®é›†åŠå¯ç”¨å®è·µé¡¹ç›®ï¼šå…¼çœ‹åˆ©ç”¨å¤§æ¨¡å‹è¿›è¡Œ5W1Hæ–°é—»è¦ç´ æå– é—®é¢˜2:å…³äºText2sqlå½“å‰çš„å¯ç”¨é¡¹ç›®åŠæ•°æ®é›†\nhttps://github.com/eosphoros-ai/Awesome-Text2SQL/\nChatbi # supersonic è…¾è®¯éŸ³ä¹ *** DB-GPT é˜¿é‡Œ *** https://github.com/Canner/WrenAI WrenAIï¼šå¼€æºText-to-SQLå¼•æ“è®© SQLè§¦æ‰‹å¯åŠï¼Œæ•°æ®åˆ†æçš„â€œGPTâ€æ—¶åˆ»æ¥äº†ï¼Ÿ https://github.com/vanna-ai/vanna\nå¼€æº Text-to-SQL å·¥å…·å“ªå®¶å¼ºï¼ŸVanna è®© SQL å°ç™½ä¹Ÿèƒ½è½»æ¾ç©è½¬æ•°æ®åˆ†æï¼ https://github.com/defog-ai/sqlcoder * https://github.com/Dataherald/dataherald * https://github.com/zwq2018/Data-Copilot æ±‡æ€» # https://github.com/eosphoros-ai/Awesome-Text2SQL/\n"},{"id":95,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Tool-use/AgentToolformer/","title":"(Work)[SFT]Toolformer","section":"Tool use","content":"\nè®ºæ–‡ # è®ºæ–‡åœ°å€ Toolformer: Language Models Can Teach Themselves to Use Tools\nå¼€æºåœ°å€ Implementation of Toolformer git\nToolformer[1] # ğŸ”‘å…³é”®è¯å’Œæ‘˜è¦ Keywords: Large-scale PLMs, Tool Learning xxx é©±åŠ¨è¯­è¨€æ¨¡å‹å»ä½¿ç”¨ç®€å•çš„æ¨¡å‹æ¥è°ƒç”¨å¤–éƒ¨çš„å·¥å…· Toolformeré€šè¿‡è¯­è¨€æ¨¡å‹çš„æ–¹æ³•å»å†³å®šå»è°ƒç”¨å“ªäº›APIï¼Œä¼ å…¥å“ªäº›å‚æ•° Tooformeræ˜¯åœ¨è‡ªç›‘ç£å±‚é¢æ‰§è¡Œçš„ï¼Œåªéœ€è¦å¯¹æ¯ä¸ªAPIçš„è¯­è¨€æè¿° âš™ï¸ç ”ç©¶è®¾è®¡å’Œç»“è®º æ–¹æ³• Toolformerè°ƒç”¨ç¤ºä¾‹ï¼šxxx å…³é”®è¦ç´ ï¼š æ¨¡å‹å¯¹å·¥å…·çš„ä½¿ç”¨åº”è¯¥æ˜¯è‡ªç›‘ç£çš„ï¼Œè¿™æ ·å¯ä»¥çœå»å¾ˆå¤§çš„æ ‡æ³¨å¼€é”€ æ¨¡å‹åº”è¯¥è‡ªè¡Œåœ°å»å†³å®šåœ¨ä½•æ—¶é—´ï¼Œç”¨ä½•æ–¹æ³•æ¥è°ƒç”¨å·¥å…· æ–¹æ³•æ¦‚è¦ï¼š å—åˆ°in-context learningçš„å¯å‘ï¼Œç»™å®šå°‘é‡çš„äººå†™çš„å…³äºAPIçš„æè¿°ï¼Œè®©æ¨¡å‹å»è‡ªè¡Œç”Ÿæˆæ½œåœ¨APIè°ƒç”¨çš„è¯­è¨€å»ºæ¨¡æ•°æ® æ„å»ºä¸€ä¸ªè‡ªç›‘ç£çš„Losså‡½æ•°ï¼Œè®©æ¨¡å‹æ¥å†³å®šå“ªäº›APIçš„è°ƒç”¨æœ‰åŠ©äºå®ƒçš„è¯­è¨€å»ºæ¨¡çš„é¢„æµ‹ æ–¹æ³•ç»†èŠ‚ï¼š xxx ç»™å®šä¸€ä¸ªçº¯æ–‡æœ¬æ•°æ®é›†ï¼Œæ„å»ºå‡ºä¸€ä¸ªå¸¦æœ‰APIè°ƒç”¨çš„æ•°æ®é›†ï¼Œç„¶ååœ¨æ­¤æ•°æ®é›†ä¸Šåšå¾®è°ƒ ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨in-context learningæ¥ç”Ÿæˆå¤§é‡çš„æ½œåœ¨å¯èƒ½çš„APIè°ƒç”¨ ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œè¿™äº›APIï¼Œè¿”å›å¾—åˆ°ç»“æœ ç¬¬ä¸‰æ­¥ï¼šæ£€æŸ¥è¿”å›çš„ç»“æœæ˜¯å¦æœ‰åŠ©äºè¯­è¨€æ¨¡å‹çš„é¢„æµ‹ï¼Œè¿‡æ»¤æ‰å…¶ä»–çš„API APIè°ƒç”¨é‡‡æ · ç»™æ¯ä¸€ä¸ªAPIæ¥æ’°å†™æç¤ºæ¥é¼“åŠ±æ¨¡å‹ä½¿ç”¨è¿™äº›APIï¼Œä¾‹å¦‚QAçš„æç¤ºæ˜¯ xxx å¯¹äºæ–‡æœ¬çš„æ¯ä¸€ä¸ªä½ç½®ï¼Œå¦‚æœè¿™ä¸ªä½ç½®æ˜¯ï¼ˆå³APIè°ƒç”¨çš„å¼€å§‹ï¼‰çš„æ¦‚ç‡å¤§äºä¸€ä¸ªé˜ˆå€¼ï¼Œåˆ™å°†æ­¤ä½ç½®ä¿ç•™åˆ°ä¸€ä¸ªé›†åˆIä¸­ å¯¹äºé›†åˆIä¸­çš„æ¯ä¸€ä¸ªä½ç½®ï¼Œé€šè¿‡æ¨¡å‹ç”Ÿæˆæœ€å¤šmä¸ªAPIè°ƒç”¨ï¼Œå¹¶ä¸”ä»¥ç»“å°¾ï¼ˆå¦‚æœç”Ÿæˆçš„è°ƒç”¨æ²¡æœ‰ä»¥ç»“å°¾ï¼Œç›´æ¥èˆå»ï¼‰ APIæ‰§è¡Œ å»æ‰§è¡Œæ‰€æœ‰çš„APIè°ƒç”¨ï¼Œè¿”å›æ–‡æœ¬åºåˆ— APIè¿‡æ»¤ æ„å»ºè‡ªç›‘ç£çš„è¯­è¨€æ¨¡å‹çš„losså‡½æ•° ç¬¬ä¸€ä¸ªçš„å«ä¹‰ï¼šè¿›è¡ŒAPIçš„è°ƒç”¨ï¼Œå¹¶ä¸”ä½¿ç”¨APIç»“æœçš„Loss ç¬¬äºŒä¸ªçš„å«ä¹‰ï¼šç©ºå­—ç¬¦ä¸²çš„Losså’Œè°ƒç”¨APIä½†ä¸è¿”å›ç»“æœLossçš„æœ€å°å€¼ è¿™æ—¶æˆ‘ä»¬å¸Œæœ›æ¨¡å‹ä½¿ç”¨APIå¹¶ä¸”è¿”å›ç»“æœå¯¹è¯­è¨€å»ºæ¨¡æœ‰å¸®åŠ©ï¼Œä¸”å¸®åŠ©å¾ˆæ˜æ˜¾-\u0026gt;å‰è€…çš„lossæ˜¾è‘—æ¯”åè€…å° å¾®è°ƒå’Œæ¨ç† åœ¨ç»è¿‡å¦‚ä¸Šæ“ä½œåï¼Œå°±å¯ä»¥å¾—åˆ°å¸¦æœ‰APIè°ƒç”¨çš„æ•°æ®é›†ï¼Œç„¶åå°†æ¨¡å‹åœ¨ä¸Šé¢è¿›è¡Œå¾®è°ƒ å½“æ¨¡å‹åœ¨è§£ç é˜¶æ®µè¾“å‡º\u0026quot;-\u0026gt;\u0026ldquo;ç¬¦å·æ—¶ï¼Œæ„å‘³ç€éœ€è¦è°ƒç”¨APIäº†ï¼Œè°ƒç”¨å¾—åˆ°è¿”å›ç»“æœç„¶åæ‹¼æ¥ä¸Šå» å®éªŒ æ¨¡å‹ï¼šGPT-J ï¼ˆ67äº¿å‚æ•°ï¼‰ åŸå§‹æ•°æ®ï¼šCCNet çŸ¥è¯†æ¢æµ‹ä»»åŠ¡LAMA Toolformerå¯ä»¥å¤§å¹…è¶…è¿‡ä¹‹å‰çš„æ–¹æ³•ï¼Œç”šè‡³æ˜¯GPT-3ç­‰å¤§æ¨¡å‹ æ•°å­¦æ•°æ®é›† é—®ç­” è¿™é‡Œå³ä½¿æ˜¯Toolformerä¹Ÿæ— æ³•è¶…è¶ŠGPT-3ï¼Œå¯è§é¢„è®­ç»ƒè§„æ¨¡å¯ä»¥å›Šæ‹¬æ›´å¤šçŸ¥è¯† æ¨¡å‹è§„æ¨¡çš„å½±å“ æ¨¡å‹çš„å‚æ•°é‡åˆ°ä¸€å®šè§„æ¨¡åæ‰æ‹¥æœ‰ä½¿ç”¨å·¥å…·çš„èƒ½åŠ› ğŸ“šè®ºæ–‡è´¡çŒ® ä¼˜ç‚¹ å°†è¯­è¨€æ¨¡å‹ä½¿ç”¨å¤–éƒ¨å·¥å…·çš„è¿›è¡Œå¾ˆè‡ªç„¶çš„ç»“åˆ ä¸éœ€è¦æ ‡æ³¨å¤§é‡æ•°æ®ï¼Œä½¿ç”¨è‡ªç›‘ç£çš„æ–¹æ³•è¿›è¡Œå­¦ä¹  ç¼ºç‚¹ å·¥å…·æ— æ³•äº¤äº’ï¼Œä¹Ÿæ— æ³•é“¾å¼ä½¿ç”¨ï¼ˆæ¯ä¸ªAPIè°ƒç”¨éƒ½æ˜¯ç‹¬ç«‹çš„ï¼‰ å®šä¹‰çš„å·¥å…·å°šä¸”æœ‰é™ï¼Œæ‰©å±•å·¥å…·åˆ™éœ€è¦ç”¨æ¨¡å‹æ ‡æ³¨æ–°çš„æ•°æ® éšç€åŸºç¡€æ¨¡å‹zero-shotèƒ½åŠ›çš„å¢å¼ºï¼Œè¿™ç§éœ€è¦æ„å»ºæ•°æ®å¹¶ä¸”fine-tuneçš„åšæ³•å¯èƒ½ä¼šæ¯”è¾ƒéº»çƒ¦ OpenBMB BMTools: https://github.com/OpenBMB/BMTools å‚è€ƒ # æ¸…ååšå£«å¸¦ä½ ææ‡‚å¤§æ¨¡å‹è‡ªå­¦å·¥å…·ä½¿ç”¨ï¼ˆToolformer)ã€è®ºæ–‡é€Ÿè¯»ã€‘ V æœ‰æ€ç»´å¯¼å›¾\n1xx. ä½¿LLMå–„å‡äºç‰©: Toolformer 1xx. Prompt Engineering 1xx. Toolformer and Tool Learningï¼ˆLLMså¦‚ä½•ä½¿ç”¨å·¥å…·ï¼‰ "},{"id":96,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Tool-use/AgentTool/","title":"(Work)Agent-Tools","section":"Tool use","content":"\nè®ºæ–‡ # è®ºæ–‡åœ°å€ Tool Learning with Foundation Models\nå¼€æºåœ°å€ ToolLearningPapers git\nåˆ†ç±»[1] # Tool-augmented vs. Tool-oriented [kimi æ€»ç»“] # Tool-augmented Learningï¼ˆå·¥å…·å¢å¼ºå­¦ä¹ ï¼‰:\nè¿™ç§å­¦ä¹ æ–¹å¼æŒ‡çš„æ˜¯åœ¨åŸºç¡€æ¨¡å‹ï¼ˆå¦‚å¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼‰çš„åŸºç¡€ä¸Šï¼Œé€šè¿‡å¼•å…¥å¤–éƒ¨å·¥å…·æ¥å¢å¼ºæ¨¡å‹çš„èƒ½åŠ›ã€‚è¿™äº›å·¥å…·å¯ä»¥æ˜¯ä»»ä½•å¯ä»¥è¢«æ¨¡å‹é€šè¿‡æŸç§æ¥å£è°ƒç”¨çš„ç³»ç»Ÿæˆ–æœåŠ¡ï¼Œä¾‹å¦‚æœç´¢å¼•æ“ã€æ•°æ®åº“ã€APIç­‰ã€‚ å·¥å…·å¢å¼ºå­¦ä¹ çš„æ ¸å¿ƒåœ¨äºæ¨¡å‹åˆ©ç”¨è¿™äº›å·¥å…·æ¥è·å–é¢å¤–çš„ä¿¡æ¯æˆ–æ‰§è¡Œç‰¹å®šçš„ä»»åŠ¡ï¼Œä»è€Œå¼¥è¡¥æ¨¡å‹è‡ªèº«çŸ¥è¯†å’Œèƒ½åŠ›çš„ä¸è¶³ã€‚ ä¾‹å¦‚ï¼Œä¸€ä¸ªè¯­è¨€æ¨¡å‹å¯èƒ½é€šè¿‡è°ƒç”¨å¤©æ°”APIæ¥è·å–æœ€æ–°çš„å¤©æ°”ä¿¡æ¯ï¼Œæˆ–è€…é€šè¿‡æœç´¢å¼•æ“æ¥æ‰¾åˆ°ç›¸å…³é—®é¢˜çš„ç­”æ¡ˆã€‚ Tool-oriented Learningï¼ˆé¢å‘å·¥å…·çš„å­¦ä¹ ï¼‰:\né¢å‘å·¥å…·çš„å­¦ä¹ åˆ™æ›´å¤šåœ°å…³æ³¨äºæ¨¡å‹å¦‚ä½•å­¦ä¹ å’Œç†è§£å¦‚ä½•ä½¿ç”¨è¿™äº›å·¥å…·ã€‚è¿™ä¸ä»…ä»…æ˜¯è°ƒç”¨å·¥å…·APIé‚£ä¹ˆç®€å•ï¼Œè€Œæ˜¯æ¶‰åŠåˆ°æ¨¡å‹å¯¹å·¥å…·çš„æ·±å…¥ç†è§£å’Œç­–ç•¥æ€§ä½¿ç”¨ã€‚ åœ¨è¿™ç§å­¦ä¹ æ¨¡å¼ä¸‹ï¼Œæ¨¡å‹å¯èƒ½éœ€è¦å­¦ä¹ å¦‚ä½•ç»„åˆä½¿ç”¨å¤šä¸ªå·¥å…·ï¼Œæˆ–è€…åœ¨å¤æ‚ä»»åŠ¡ä¸­åŠ¨æ€è°ƒæ•´å¯¹å·¥å…·çš„ä½¿ç”¨ç­–ç•¥ï¼Œä»¥å®ç°æ›´é«˜æ•ˆçš„é—®é¢˜è§£å†³ã€‚ ä¾‹å¦‚ï¼Œæ¨¡å‹å¯èƒ½éœ€è¦å­¦ä¹ å¦‚ä½•åœ¨è§„åˆ’ä¸€æ¬¡æ—…è¡Œæ—¶ï¼Œå…ˆåè°ƒç”¨åœ°å›¾APIã€èˆªç­æœç´¢APIå’Œé…’åº—é¢„è®¢APIï¼ŒåŒæ—¶è¿˜è¦æ ¹æ®ç”¨æˆ·åé¦ˆå’Œç¯å¢ƒå˜åŒ–åŠ¨æ€è°ƒæ•´è®¡åˆ’ã€‚ æ€»çš„æ¥è¯´ï¼ŒTool-augmented Learning å¼ºè°ƒçš„æ˜¯é€šè¿‡å¤–éƒ¨å·¥å…·æ¥æ‰©å±•æ¨¡å‹çš„èƒ½åŠ›ï¼Œè€Œ Tool-oriented Learning åˆ™æ›´ä¾§é‡äºæ¨¡å‹å¯¹å·¥å…·ä½¿ç”¨çš„å­¦ä¹ å’Œä¼˜åŒ–ã€‚ä¸¤è€…éƒ½æ˜¯å·¥å…·å­¦ä¹ ï¼ˆTool Learningï¼‰çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­å¯èƒ½ä¼šæœ‰ä¸åŒçš„å®ç°æ–¹å¼å’Œå…³æ³¨ç‚¹ã€‚\nTool-augmented Learning # Toolformer\n{% post_link \u0026lsquo;gptAgentToolformer\u0026rsquo; %} Tool-oriented Learning # ToolMaker[10] CREATOR[11] ToolLLM [12] Visual ChatGPT[13] HuggingGPT[13] Gorilla {% post_link \u0026lsquo;gptAgentToolGorilla\u0026rsquo; %} å‚è€ƒ # å¤§æ¨¡å‹å·¥å…·å­¦ä¹ æƒå¨ç»¼è¿°ï¼ŒBMTools èƒŒåçš„è®ºæ–‡ï¼ 1xx. æ¸…åå‘å¸ƒå·¥å…·å­¦ä¹ æ¡†æ¶ï¼Œè®©ChatGPTæ“æ§åœ°å›¾ã€è‚¡ç¥¨æŸ¥è¯¢ï¼Œè´¾ç»´æ–¯å·²æ¥ï¼Ÿ\n1xx. å›é¡¾å¤§æ¨¡å‹åœ¨å·¥å…·ä½¿ç”¨ä¸Šçš„æŠ€æœ¯æ€»ç»“ï¼šå…¼çœ‹å›¾æ£€ç´¢å¢å¼ºç”Ÿæˆæ–¹æ¡ˆ-GRAG ã€ŠTool Learning with Large Language Models: A Surveyã€‹\né—®é¢˜2:å…³äºå¤§æ¨¡å‹ä½¿ç”¨å·¥å…·çš„è°ƒç ”æ•´ç†\n1xx. ä¸€ç¯‡å¤§æ¨¡å‹Agentå·¥å…·ä½¿ç”¨å…¨é¢ç ”ç©¶ç»¼è¿°\nã€ŠTool Learning with Large Language Models: A Surveyã€‹\nxxx # LLMèƒ½å¤Ÿè‡ªå·±åˆ¶ä½œå·¥å…·äº†ï¼šè¯¦è§£Large Language Models as Tool Makers\nTHUNLPæˆå‘˜é¢†è¯»EMNLPå¤§æ¨¡å‹å·¥å…·åˆ›é€ æ–°æ¡†æ¶â€œCREATORâ€ V æœ‰æ€ç»´å¯¼å›¾\nã€ŠTOOLLLM: FACILITATING LARGE LANGUAGE MODELS TO MASTER 16000+ REAL-WORLD APISã€‹\nTOOLLLMï¼šè®©å¤§å‹è¯­è¨€æ¨¡å‹æŒæ¡çœŸå®ä¸–ç•Œçš„API ToolBench git\nè®ºæ–‡é˜…è¯»ï¼šToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs\n{% post_link \u0026lsquo;gptAgentMultimodal\u0026rsquo; %} self\nOthers # ã€ŠAugmented Language Modelsã€‹\n1xx. Augmented Language Modelsï¼ˆå¢å¼ºè¯­è¨€æ¨¡å‹ï¼‰\n1xx. å¢å¼ºè¯­è¨€æ¨¡å‹ï¼ˆALMï¼‰ä¹‹ç»¼è¿°ç¯‡\n"},{"id":97,"href":"/www6vAIGC/docs/FineTuning/PEFT/Lora/PEFTQLora/","title":"(åŸç†|å®æˆ˜) QLoRA *","section":"Lora","content":"\nğŸ’¡ QAT 4 bit NormalFloat(NF4) é‡åŒ– åŒé‡åŒ– æŠ€æœ¯åŸç† [1] # ä½¿ç”¨ä¸€ç§æ–°é¢–çš„é«˜ç²¾åº¦æŠ€æœ¯å°†é¢„è®­ç»ƒæ¨¡å‹é‡åŒ–ä¸º 4 bitï¼Œç„¶åæ·»åŠ ä¸€å°ç»„å¯å­¦ä¹ çš„ä½ç§©é€‚é…å™¨æƒé‡ï¼Œè¿™äº›æƒé‡é€šè¿‡é‡åŒ–æƒé‡çš„åå‘ä¼ æ’­æ¢¯åº¦è¿›è¡Œå¾®è°ƒã€‚\nQLoRAæå‡ºäº†ä¸¤ç§æŠ€æœ¯å®ç°é«˜ä¿çœŸ 4 bitå¾®è°ƒâ€”â€”4 bit NormalFloat(NF4) é‡åŒ–å’ŒåŒé‡åŒ–ã€‚\n4bit NormalFloatï¼ˆNF4ï¼‰ï¼šå¯¹äºæ­£æ€åˆ†å¸ƒæƒé‡è€Œè¨€ï¼Œä¸€ç§ä¿¡æ¯ç†è®ºä¸Šæœ€ä¼˜çš„æ–°æ•°æ®ç±»å‹ï¼Œè¯¥æ•°æ®ç±»å‹å¯¹æ­£æ€åˆ†å¸ƒæ•°æ®äº§ç”Ÿæ¯” 4 bitæ•´æ•°å’Œ 4bit æµ®ç‚¹æ•°æ›´å¥½çš„å®è¯ç»“æœã€‚ åŒé‡åŒ–ï¼šå¯¹ç¬¬ä¸€æ¬¡é‡åŒ–åçš„é‚£äº›å¸¸é‡å†è¿›è¡Œä¸€æ¬¡é‡åŒ–ï¼Œå‡å°‘å­˜å‚¨ç©ºé—´ã€‚ åˆ†é¡µä¼˜åŒ–å™¨: ä½¿ç”¨æ­¤åŠŸèƒ½ä¸ºä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆOptimizerï¼‰åˆ†é…åˆ†é¡µå†…å­˜ï¼Œç„¶ååœ¨ GPU å†…å­˜ä¸è¶³æ—¶å°†å…¶è‡ªåŠ¨å¸è½½åˆ° CPU å†…å­˜ï¼Œå¹¶åœ¨ä¼˜åŒ–å™¨æ›´æ–°æ­¥éª¤éœ€è¦æ—¶å°†å…¶åŠ è½½å› GPU å†…å­˜ã€‚ å®éªŒè¯æ˜ï¼Œæ— è®ºæ˜¯ä½¿ç”¨16bitã€8bitè¿˜æ˜¯4bitçš„é€‚é…å™¨æ–¹æ³•ï¼Œéƒ½èƒ½å¤Ÿå¤åˆ¶16bitå…¨å‚æ•°å¾®è°ƒçš„åŸºå‡†æ€§èƒ½ã€‚è¿™è¯´æ˜ï¼Œå°½ç®¡é‡åŒ–è¿‡ç¨‹ä¸­ä¼šå­˜åœ¨æ€§èƒ½æŸå¤±ï¼Œä½†é€šè¿‡é€‚é…å™¨å¾®è°ƒï¼Œå®Œå…¨å¯ä»¥æ¢å¤è¿™äº›æ€§èƒ½ã€‚\næ€»ç»“ # QLoRA [189] quantizes the weights of LLMs into 4-bit and subsequently employs LoRA [224] in BF16 for each 4-bit weight matrix to fine-tune the quantized model. QLoRA allows for the efficient fine-tuning of a 65B parameter LLM on one GPU with only 30GB of memory.\nè€åˆ˜ # QLoRAé€šè¿‡ç»“åˆNF4é‡åŒ–ï¼ˆä¸€ç§è€ƒè™‘æƒé‡åˆ†å¸ƒçš„4ä½é‡åŒ–ï¼‰ã€åŒé‡é‡åŒ–ï¼ˆè¿›ä¸€æ­¥å‹ç¼©é‡åŒ–å¸¸æ•°ï¼‰å’ŒLoRAï¼ˆåªè®­ç»ƒå°‘é‡é€‚é…å™¨å‚æ•°ï¼‰æ¥å®ç°é«˜æ•ˆå¾®è°ƒã€‚å…¶æ ¸å¿ƒä¼˜åŠ¿åœ¨äºï¼Œå®ƒæ˜¾è‘—é™ä½äº†å­˜å‚¨æ¨¡å‹æƒé‡æ‰€éœ€çš„å†…å­˜ï¼Œå¹¶ä¸”åœ¨åå‘ä¼ æ’­ï¼ˆæ¢¯åº¦è®¡ç®—å’Œå‚æ•°æ›´æ–°ï¼‰æœŸé—´ï¼Œå†»ç»“çš„åŸºç¡€æ¨¡å‹æƒé‡ä¿æŒä½ç²¾åº¦ï¼ˆNF4ï¼‰çŠ¶æ€ï¼Œä»è€Œå¤§å¹…å‡å°‘äº†è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ˜¾å­˜å ç”¨ï¼Œä½¿å¾—åœ¨æœ‰é™çš„ç¡¬ä»¶èµ„æºï¼ˆå¦‚å•ä¸ªGPUï¼‰ä¸Šå¾®è°ƒéå¸¸å¤§çš„æ¨¡å‹æˆä¸ºå¯èƒ½ã€‚\nå®æˆ˜ [10] # QLoRA å¾®è°ƒ[llama3] # åŸºäº 4/8 æ¯”ç‰¹ Bitsandbytes/HQQ/EETQ é‡åŒ–è¿›è¡ŒæŒ‡ä»¤ç›‘ç£å¾®è°ƒ[æ¨è]\nllamafactory-cli train examples/train_qlora/llama3_lora_sft_otfq.yaml åŸºäº 4/8 æ¯”ç‰¹ GPTQ é‡åŒ–è¿›è¡ŒæŒ‡ä»¤ç›‘ç£å¾®è°ƒ\nllamafactory-cli train examples/train_qlora/llama3_lora_sft_gptq.yaml åŸºäº 4 æ¯”ç‰¹ AWQ é‡åŒ–è¿›è¡ŒæŒ‡ä»¤ç›‘ç£å¾®è°ƒ\nllamafactory-cli train examples/train_qlora/llama3_lora_sft_awq.yaml ğŸ’¡ LoRAå’ŒQLoRA èƒ½åœ¨é‡åŒ–è¿‡çš„æ¨¡å‹ä¸Šå¾®è°ƒ\nQLoRA å¾®è°ƒ[LLaMA-65B] [11] # å‚æ•° # å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†ç»¼è¿°ï¼ˆäº”ï¼‰-LoRAã€AdaLoRAã€QLoRA 1xx. [å¤§æ¨¡å‹å¾®è°ƒæŠ€æœ¯] LoRAã€QLoRAã€QA-LoRA åŸç†ç¬”è®°\n1xx. å¤§æ¨¡å‹å®æ“ | LoRAã€QLoRAå¾®è°ƒå¤§æ¨¡å‹å®æˆ˜æŠ€å·§åˆ†äº«ï¼Œå«å¸¸è§QAè§£ç­”ï¼\nå®æˆ˜ # LLaMA-Factory examples\né«˜æ•ˆå¾®è°ƒæŠ€æœ¯QLoRAå®æˆ˜ï¼ŒåŸºäºLLaMA-65Bå¾®è°ƒä»…éœ€48Gæ˜¾å­˜ï¼ŒçœŸé¦™\nå…ˆæ˜¯è®­ç»ƒllama-7b, å†æ˜¯è®­ç»ƒllama-65b. qlora git\n1xx. 4bits_training\nã€æ‰‹æŠŠæ‰‹å¸¦ä½ å®æˆ˜HuggingFace Transformers-ä½ç²¾åº¦è®­ç»ƒç¯‡ã€‘4bité‡åŒ–ä¸QLoRAæ¨¡å‹è®­ç»ƒ v åŸç†+å®æˆ˜\n"},{"id":98,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Memory/AgentMemory/","title":"Agent  Memory +","section":"Memory","content":"\nMemory # Memory\n"},{"id":99,"href":"/www6vAIGC/docs/FineTuning/Data/Data-Quality/Instruction-Quality/DataSFTQuality/","title":"(åŸç†)LIMA, LESS","section":"Instruction Quality","content":"\nLIMA [1][kimi] # LIMAï¼ˆLess Is More for Alignmentï¼‰çš„å®éªŒé€šè¿‡ä¸€ç³»åˆ—è®¾è®¡ç²¾è‰¯çš„æ­¥éª¤æ¥æ¢ç©¶æ•°æ®è´¨é‡ã€å¤šæ ·æ€§ä»¥åŠæ•°é‡å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œä»è€Œå¾—å‡ºäº†æé«˜æ•°æ®è´¨é‡å’Œå¢åŠ æç¤ºå¤šæ ·æ€§æ¯”å•çº¯å¢åŠ æ•°æ®é‡æ›´èƒ½æå‡æ¨¡å‹æ€§èƒ½çš„ç»“è®ºã€‚ä»¥ä¸‹æ˜¯å®éªŒæ–¹æ³•çš„å…³é”®æ­¥éª¤ï¼š\nç²¾å¿ƒç­–åˆ’çš„å¾®è°ƒæ•°æ®ï¼šLIMAæ¨¡å‹åœ¨1000ä¸ªç²¾å¿ƒç­–åˆ’çš„æç¤ºå’Œå›å¤ä¸Šè¿›è¡Œäº†å¾®è°ƒï¼Œè¿™äº›æ•°æ®è¢«è®¾è®¡ä¸ºæ¨¡æ‹ŸçœŸå®ç”¨æˆ·ä¸AIåŠ©æ‰‹çš„äº¤äº’ã€‚\næ¶ˆèå®éªŒï¼šé€šè¿‡æ¶ˆèå®éªŒï¼Œç ”ç©¶è€…ä»¬è§‚å¯Ÿäº†åœ¨å¢åŠ æ•°æ®é‡çš„åŒæ—¶ä¸å¢åŠ æç¤ºå¤šæ ·æ€§æ—¶ï¼Œæ¨¡å‹æ€§èƒ½çš„æå‡æ˜¯å¦æœ‰é™ï¼›è€Œåœ¨ä¼˜åŒ–æ•°æ®è´¨é‡æ—¶ï¼Œæ€§èƒ½æ˜¯å¦æœ‰æ˜¾è‘—æå‡ã€‚\næ•°æ®æ„é€ ï¼šç ”ç©¶è€…ä»Stack Exchangeã€wikiHowå’ŒPushshift Redditæ•°æ®é›†æ”¶é›†æ•°æ®ï¼Œå¹¶è¿›è¡Œäº†è´¨é‡å’Œå¤šæ ·æ€§çš„æ§åˆ¶ã€‚è¿™äº›æ•°æ®é›†è¢«ç”¨æ¥æ„é€ è®­ç»ƒæ ·æœ¬ï¼Œä»¥ç¡®ä¿è¾“å…¥çš„å¤šæ ·æ€§å’Œè¾“å‡ºçš„ä¸€è‡´æ€§ã€‚\nè´¨é‡ä¸å¤šæ ·æ€§çš„å¯¹æ¯”ï¼šç ”ç©¶è€…æ¯”è¾ƒäº†ç»è¿‡è´¨é‡è¿‡æ»¤çš„Stack Exchangeæ•°æ®å’ŒåŒè´¨åŒ–çš„wikiHowæ•°æ®å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚ç»“æœæ˜¾ç¤ºï¼Œæ›´å¤šæ ·åŒ–çš„Stack Exchangeæ•°æ®åœ¨æ€§èƒ½ä¸Šä¼˜äºåŒè´¨åŒ–çš„wikiHowæ•°æ®ã€‚ ã€å¤šæ ·åŒ–ã€‘\næ•°é‡çš„å¯¹æ¯”ï¼šç ”ç©¶è€…å¯¹ä»Stack ExchangeæŠ½å–çš„æŒ‡æ•°çº§å¢åŠ çš„è®­ç»ƒé›†è¿›è¡Œäº†æµ‹è¯•ï¼Œå‘ç°è®­ç»ƒé›†çš„ç¿»å€å¹¶æ²¡æœ‰æ”¹å–„å“åº”è´¨é‡ï¼Œä»è€Œè¯´æ˜å•çº¯å¢åŠ æ•°æ®é‡å¹¶ä¸ä¸€å®šèƒ½æå‡æ€§èƒ½ã€‚ã€æ•°é‡ã€‘\nè´¨é‡æ§åˆ¶çš„å®éªŒï¼šç ”ç©¶è€…è¿˜æ¯”è¾ƒäº†æœªç»è¿‡ä»»ä½•è´¨é‡æˆ–é£æ ¼è¿‡æ»¤çš„Stack Exchangeæ•°æ®é›†ä¸ç»è¿‡è¿‡æ»¤çš„æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹æ€§èƒ½ï¼Œå‘ç°è¿‡æ»¤åçš„æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹æ€§èƒ½æ›´ä¼˜ã€‚ã€è´¨é‡ã€‘\näººç±»è¯„ä¼°ï¼šä¸ºäº†è¯„ä¼°LIMAæ¨¡å‹çš„æ€§èƒ½ï¼Œç ”ç©¶è€…è¿›è¡Œäº†äººç±»åå¥½ç ”ç©¶ï¼Œå°†LIMAçš„è¾“å‡ºä¸å…¶ä»–å‡ ä¸ªåŸºçº¿æ¨¡å‹çš„è¾“å‡ºè¿›è¡Œæ¯”è¾ƒï¼Œå¹¶è®©äººç¾¤å·¥ä½œè€…é€‰æ‹©ä»–ä»¬æ›´å–œæ¬¢çš„è¾“å‡ºã€‚\né€šè¿‡è¿™äº›å®éªŒæ­¥éª¤ï¼ŒLIMAçš„ç ”ç©¶å¾—å‡ºäº†æ•°æ®è´¨é‡å’Œæç¤ºå¤šæ ·æ€§å¯¹äºæå‡æ¨¡å‹æ€§èƒ½çš„é‡è¦æ€§è¿œè¶…è¿‡å•çº¯å¢åŠ æ•°æ®é‡çš„ç»“è®ºã€‚è¿™äº›å‘ç°æ”¯æŒäº†â€œæµ…å±‚å¯¹é½å‡è¯´â€ï¼Œå³æ¨¡å‹åœ¨é¢„è®­ç»ƒé˜¶æ®µå·²ç»å­¦ä¹ åˆ°äº†å‡ ä¹æ‰€æœ‰çŸ¥è¯†å’Œèƒ½åŠ›ï¼Œè€Œå¾®è°ƒè¿‡ç¨‹ä¸»è¦æ˜¯å­¦ä¹ ä¸äººç±»äº¤äº’çš„é£æ ¼å’Œæ ¼å¼ã€‚\næ€»ç»“ [1]\næ¶ˆèå®éªŒæ˜¾ç¤ºï¼Œå½“æ‰©å¤§æ•°æ®é‡è€Œä¸åŒæ—¶æ‰©å¤§æç¤ºå¤šæ ·æ€§æ—¶ï¼Œæ”¶ç›Šä¼šå¤§å¤§å‡å°‘ï¼Œè€Œåœ¨ä¼˜åŒ–æ•°æ®è´¨é‡æ—¶ï¼Œæ”¶ç›Šä¼šå¤§å¤§å¢åŠ  ã€æ•°é‡ \u0026lt;\u0026ndash;\u0026gt; å¤šæ ·æ€§ è´¨é‡ã€‘\nLESS æ ¸å¿ƒæ€æƒ³ [10] # é€šè¿‡ä»…ç»™å‡ºå°‘æ•°ä½“ç°ç‰¹å®šèƒ½åŠ›çš„ç¤ºä¾‹ï¼Œä»å¤§é‡æŒ‡ä»¤æ•°æ®é›†ä¸­æœ‰æ•ˆåœ°é€‰æ‹©5%æœ‰å½±å“åŠ›çš„æ•°æ®ç”¨äºç›®æ ‡æŒ‡ä»¤å¾®è°ƒï¼Œç»“æœä¼˜äºå…¨é‡æ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼Œå¹¶ä¸”æ‰€é€‰å­é›†åœ¨ä¸åŒæ¨¡å‹å‚æ•°è§„æ¨¡å’Œä¸åŒæ¨¡å‹ç³»åˆ—ä¸­ä»ç„¶æ™®éæœ‰æ•ˆã€‚\nLESS[10][kimi] # LESSï¼ˆSelecting Influential Data for Targeted Instruction Tuningï¼‰çš„å®éªŒæ–¹æ³•å’Œç›¸åº”çš„ç»“è®ºå¦‚ä¸‹ï¼š\nå®éªŒæ–¹æ³•ï¼š # çƒ­èº«è®­ç»ƒï¼ˆWarmup Trainingï¼‰ï¼šä½¿ç”¨LoRAï¼ˆLow-Rank Adaptationï¼‰æŠ€æœ¯å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œçƒ­èº«è®­ç»ƒï¼Œä»¥é€‚åº”ç‰¹å®šçš„æ•°æ®åˆ†å¸ƒã€‚\næ¢¯åº¦æ•°æ®å­˜å‚¨ï¼ˆGradient Data Storeï¼‰ï¼šæ„å»ºäº†ä¸€ä¸ªå…·æœ‰æŠ•å½±ä½ç»´æ¢¯åº¦ç‰¹å¾çš„æ¢¯åº¦æ•°æ®å­˜å‚¨ï¼Œè¯¥å­˜å‚¨å¯ä»¥é‡å¤ç”¨äºä¸åŒçš„ç›®æ ‡ä»»åŠ¡ã€‚\næ•°æ®é€‰æ‹©ç®—æ³•ï¼šåˆ©ç”¨æ•°æ®å­˜å‚¨å’Œç®—æ³•é€‰æ‹©ä¸ä½“ç°ç‰¹å®šèƒ½åŠ›çš„å°‘æ•°ç¤ºä¾‹æœ€ç›¸ä¼¼çš„è®­ç»ƒæ•°æ®ç‚¹ã€‚?\næ¨¡å‹è®­ç»ƒï¼šä½¿ç”¨é€‰æ‹©çš„æ•°æ®å­é›†æ¥è®­ç»ƒç›®æ ‡æ¨¡å‹ã€‚\nè¯„ä¼°ï¼šåœ¨ä¸åŒçš„ä¸‹æ¸¸ä»»åŠ¡ä¸Šè¯„ä¼°LESSé€‰æ‹©çš„æ•°æ®å­é›†çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬MMLUã€TYDIQAå’ŒBBHæ•°æ®é›†ã€‚\nç»“è®ºï¼š # LESSçš„æœ‰æ•ˆæ€§ï¼šLESSåœ¨ä¸åŒçš„æ¨¡å‹ä¸­éƒ½æ˜¯æœ‰æ•ˆçš„ï¼Œèƒ½å¤Ÿåœ¨å¤šä¸ªè¯„ä¼°æ•°æ®é›†ä¸Šæé«˜æ€§èƒ½ã€‚\næ•°æ®å­é›†çš„æ€§èƒ½ï¼šä½¿ç”¨LESSé€‰æ‹©çš„5%çš„æ•°æ®é€šå¸¸ä¼˜äºä½¿ç”¨å®Œæ•´æ•°æ®é›†è¿›è¡Œè®­ç»ƒçš„ç»“æœã€‚è¿™è¡¨æ˜å®Œæ•´æ•°æ®é›†å¯èƒ½åŒ…å«ä¸ç‰¹å®šç›®æ ‡ä»»åŠ¡æ— å…³æˆ–æœ‰å®³çš„æ•°æ®ç‚¹ã€‚\næ•°æ®çš„å¯è½¬ç§»æ€§ï¼šä½¿ç”¨è¾ƒå°æ¨¡å‹é€‰æ‹©çš„æ•°æ®å¯ä»¥æé«˜è¾ƒå¤§æ¨¡å‹å’Œä¸åŒæ¨¡å‹ç³»åˆ—çš„æ€§èƒ½ï¼Œè¯æ˜äº†LESSé€‰æ‹©çš„æ•°æ®å…·æœ‰é«˜åº¦çš„å¯è½¬ç§»æ€§ã€‚\nä¸å…¶ä»–æ–¹æ³•çš„æ¯”è¾ƒï¼šLESSæ˜¯å”¯ä¸€ä¸€è‡´æœ‰æ•ˆçš„æ–¹æ³•ï¼Œç›¸è¾ƒäºå…¶ä»–åŸºçº¿æ–¹æ³•ï¼ˆå¦‚éšæœºé€‰æ‹©ã€BM25ã€DSIRã€RDSï¼‰è¡¨ç°å‡ºæ›´å¥½çš„æ€§èƒ½ã€‚\nè®¡ç®—æˆæœ¬ï¼šLESSçš„è®¡ç®—æˆæœ¬è¾ƒé«˜ï¼Œä½†ç”±äºå…¶æœ‰æ•ˆæ€§ï¼Œè¿™ä¸€æˆæœ¬æ˜¯åˆç†çš„ã€‚\nå®šæ€§åˆ†æï¼šLESSé€‰æ‹©çš„æ•°æ®èƒ½å¤Ÿä½“ç°é¢„æœŸä¸‹æ¸¸åº”ç”¨æ‰€éœ€çš„æ¨ç†æŠ€èƒ½ï¼Œè€Œä¸æ˜¯ä»…ä»…åŸºäºè¡¨é¢å½¢å¼çº¿ç´¢ã€‚\nå±€é™æ€§ï¼šLESSéœ€è¦çƒ­èº«è®­ç»ƒé˜¶æ®µï¼Œè¿™å¢åŠ äº†è®¡ç®—è´Ÿè½½ã€‚æ­¤å¤–ï¼Œä½¿ç”¨è¡¥å…¨Tokençš„å¹³å‡æ¢¯åº¦å¯èƒ½å¯¼è‡´æ€§èƒ½é—®é¢˜ã€‚è¿˜æœ‰ï¼Œæœ€å°åŒ–éªŒè¯æŸå¤±å¹¶ä¸æ€»èƒ½æé«˜ä»»åŠ¡æ€§èƒ½ï¼Œä¸”æ•°æ®é€‰æ‹©ä¸­çš„çº¿æ€§åº¦å‡è®¾æ˜¯LESSçš„ä¸€ä¸ªé™åˆ¶ã€‚\næ€»ä½“è€Œè¨€ï¼ŒLESSé€šè¿‡é€‰æ‹©ä¸ç›®æ ‡ä»»åŠ¡é«˜åº¦ç›¸å…³çš„æ•°æ®ç‚¹ï¼Œèƒ½å¤Ÿåœ¨æŒ‡ä»¤å¾®è°ƒä¸­å®ç°é«˜æ•ˆçš„æ€§èƒ½æå‡ï¼Œå°½ç®¡å­˜åœ¨ä¸€äº›å±€é™æ€§å’Œè®¡ç®—æˆæœ¬ã€‚\nã€æ€»ç»“: å°‘é‡æœ‰è´¨é‡çš„æ•°æ® ä¼˜äº å…¨é‡æ•°æ® ã€‘ ã€æ•°æ®é€‰æ‹©ç®—æ³•ã€‘\nå‚è€ƒ # LIMA # å¤§æ¨¡å‹å¾®è°ƒç©¶ç«Ÿéœ€è¦å¤šå°‘æ•°æ®ï¼šä»ä¸‰ä¸ªç°æœ‰ä»£è¡¨å·¥ä½œçœ‹å‡ ç»„ç»“è®ºåŠä¸€ç‚¹æ€è€ƒ æŒ‡ä»¤æ ¼å¼çš„å¤šæ ·æ€§ ã€ŠLIMA: Less Is More for Alignmentã€‹ ã€ŠMAYBE ONLY 0.5% DATA IS NEEDEDã€‹ 1xx. ã€è®ºæ–‡ç¬”è®°ã€‘LIMA: Less Is More for Alignment\nLESS # LESSï¼šä»…é€‰æ‹©5%æœ‰å½±å“åŠ›çš„æ•°æ®ä¼˜äºå…¨é‡æ•°æ®é›†è¿›è¡Œç›®æ ‡æŒ‡ä»¤å¾®è°ƒ 1xx. LESS å®è·µï¼šç”¨å°‘é‡çš„æ•°æ®è¿›è¡Œç›®æ ‡æŒ‡ä»¤å¾®è°ƒ\n"},{"id":100,"href":"/www6vAIGC/docs/FineTuning/Data/DatasetSFTList/","title":"(List)SFTæ•°æ®é›†","section":"Data","content":"\nSFTæ•°æ®é›†[1][2] # å‚è€ƒ # å¤§æ¨¡å‹å†æ€»ç»“åŠChatSQLå®è·µæ¡ˆä¾‹åˆ†äº«ï¼šå¤§æ¨¡å‹è®­ç»ƒæ•°æ®åŠå·¥å…·çš„5å¼ è„‘å›¾æ€»ç»“åŠChatSQLå¼€æºé¡¹ç›®å®ç°è§£æ 1ã€é€šç”¨æŒ‡ä»¤å¾®è°ƒæ•°æ®\nå¼€æºSFTæ•°æ®é›†æ•´ç†\n"},{"id":101,"href":"/www6vAIGC/docs/Agent/%E7%BB%84%E4%BB%B6/Reflection/AgentReflection/","title":"Reflection Agent *","section":"Reflection","content":"\nReAct # è®ºæ–‡ # è®ºæ–‡åœ°å€\nReAct: Synergizing Reasoning and Acting in Language Models\nå¼€æºåœ°å€\nReAct git\nProject page\nReAct: Synergizing Reasoning and Acting in Language Models\nå®ç°[1] # import json import sys folder = \u0026#39;./prompts/\u0026#39; prompt_file = \u0026#39;prompts_naive.json\u0026#39; with open(folder + prompt_file, \u0026#39;r\u0026#39;) as f: prompt_dict = json.load(f) webthink_examples = prompt_dict[\u0026#39;webthink_simple6\u0026#39;] instruction = \u0026#34;\u0026#34;\u0026#34;Solve a question answering task with interleaving Thought, Action, Observation steps. Thought can reason about the current situation, and Action can be three types: (1) Search[entity], which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it will return some similar entities to search. (2) Lookup[keyword], which returns the next sentence containing keyword in the current passage. (3) Finish[answer], which returns the answer and finishes the task. Here are some examples. \u0026#34;\u0026#34;\u0026#34; webthink_prompt = instruction + webthink_examples Reflexion # è®ºæ–‡ # è®ºæ–‡åœ°å€ Reflexion: Language Agents with Verbal Reinforcement Learning\nå¼€æºåœ°å€ reflexion git\nå¦‚å›¾æ‰€ç¤ºï¼ŒReflexionæ¡†æ¶åŒ…å«å››ä¸ªç»„æˆéƒ¨åˆ†ï¼š\nActor: Actorç”±LLMæ‹…ä»»ï¼Œä¸»è¦å·¥ä½œæ˜¯åŸºäºå½“å‰ç¯å¢ƒç”Ÿæˆä¸‹ä¸€æ­¥çš„åŠ¨ä½œã€‚ Evaluator: Evlauatorä¸»è¦å·¥ä½œæ˜¯è¡¡é‡Actorç”Ÿæˆç»“æœçš„è´¨é‡ã€‚å°±åƒå¼ºåŒ–å­¦ä¹ ä¸­çš„Rewardå‡½æ•°å¯¹Actorçš„æ‰§è¡Œç»“æœè¿›è¡Œæ‰“åˆ†ã€‚ Self-reflexionï¼šSelf-reflexionä¸€èˆ¬ç”±LLMæ‹…ä»»ï¼Œæ˜¯Reflexionæ¡†æ¶ä¸­æœ€é‡è¦çš„éƒ¨åˆ†ã€‚å®ƒèƒ½ç»“åˆç¦»æ•£çš„rewardä¿¡å·(å¦‚success/fail)ã€trajectoryç­‰ç”Ÿæˆå…·ä½“ä¸”è¯¦ç»†è¯­è¨€åé¦ˆä¿¡å·ï¼Œè¿™ç§åé¦ˆä¿¡å·ä¼šå‚¨å­˜åœ¨Memoryä¸­ï¼Œå¯å‘ä¸‹ä¸€æ¬¡å®éªŒçš„Actoræ‰§è¡ŒåŠ¨ä½œã€‚ç›¸æ¯”rewardåˆ†æ•°ï¼Œè¿™ç§è¯­è¨€åé¦ˆä¿¡å·å‚¨å­˜æ›´ä¸°å¯Œçš„ä¿¡æ¯ï¼Œä¾‹å¦‚åœ¨ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒRewardåªä¼šå‘Šè¯‰ä½ ä»»åŠ¡æ˜¯å¤±è´¥è¿˜æ˜¯æˆåŠŸï¼Œä½†æ˜¯Self-reflexionä¼šå‘Šè¯‰ä½ å“ªä¸€æ­¥é”™äº†ï¼Œé”™è¯¯çš„åŸå› æ˜¯ä»€ä¹ˆç­‰ã€‚ Memoryï¼šåˆ†ä¸ºçŸ­æœŸè®°å¿†(short-term)å’Œé•¿æœŸè®°å¿†(long-term)ã€‚åœ¨ä¸€æ¬¡å®éªŒä¸­çš„ä¸Šä¸‹æ–‡ç§°ä¸ºçŸ­æœŸè®°å¿†ï¼Œå¤šæ¬¡è¯•éªŒä¸­Self-reflexionçš„ç»“æœç§°ä¸ºé•¿æœŸè®°å¿†ã€‚ç±»æ¯”äººç±»æ€è€ƒè¿‡ç¨‹ï¼Œåœ¨æ¨ç†é˜¶æ®µActorä¼šä¸ä»…ä¼šåˆ©ç”¨çŸ­æœŸè®°å¿†ï¼Œè¿˜ä¼šç»“åˆé•¿æœŸè®°å¿†ä¸­å­˜å‚¨çš„é‡è¦ç»†èŠ‚ï¼Œè¿™æ˜¯Reflexionæ¡†æ¶èƒ½å–å¾—æ•ˆæœçš„å…³é”®ã€‚ å®ç°[10] # Initial responder import datetime actor_prompt_template = ChatPromptTemplate.from_messages( [ ( \u0026#34;system\u0026#34;, \u0026#34;\u0026#34;\u0026#34;You are expert researcher. Current time: {time} 1. {first_instruction} 2. Reflect and critique your answer. Be severe to maximize improvement. 3. Recommend search queries to research information and improve your answer.\u0026#34;\u0026#34;\u0026#34;, ), MessagesPlaceholder(variable_name=\u0026#34;messages\u0026#34;), ( \u0026#34;user\u0026#34;, \u0026#34;\\n\\n\u0026lt;system\u0026gt;Reflect on the user\u0026#39;s original question and the\u0026#34; \u0026#34; actions taken thus far. Respond using the {function_name} function.\u0026lt;/reminder\u0026gt;\u0026#34;, ), ] ).partial( time=lambda: datetime.datetime.now().isoformat(), ) initial_answer_chain = actor_prompt_template.partial( first_instruction=\u0026#34;Provide a detailed ~250 word answer.\u0026#34;, function_name=AnswerQuestion.__name__, ) | llm.bind_tools(tools=[AnswerQuestion]) validator = PydanticToolsParser(tools=[AnswerQuestion]) first_responder = ResponderWithRetries( runnable=initial_answer_chain, validator=validator ) Revision revise_instructions = \u0026#34;\u0026#34;\u0026#34;Revise your previous answer using the new information. - You should use the previous critique to add important information to your answer. - You MUST include numerical citations in your revised answer to ensure it can be verified. - Add a \u0026#34;References\u0026#34; section to the bottom of your answer (which does not count towards the word limit). In form of: - [1] https://example.com - [2] https://example.com - You should use the previous critique to remove superfluous information from your answer and make SURE it is not more than 250 words. \u0026#34;\u0026#34;\u0026#34; # Extend the initial answer schema to include references. # Forcing citation in the model encourages grounded responses class ReviseAnswer(AnswerQuestion): \u0026#34;\u0026#34;\u0026#34;Revise your original answer to your question. Provide an answer, reflection, cite your reflection with references, and finally add search queries to improve the answer.\u0026#34;\u0026#34;\u0026#34; references: list[str] = Field( description=\u0026#34;Citations motivating your updated answer.\u0026#34; ) revision_chain = actor_prompt_template.partial( first_instruction=revise_instructions, function_name=ReviseAnswer.__name__, ) | llm.bind_tools(tools=[ReviseAnswer]) revision_validator = PydanticToolsParser(tools=[ReviseAnswer]) revisor = ResponderWithRetries(runnable=revision_chain, validator=revision_validator) æ€»ç»“ # ã€ReAct å’Œ Reflexion å®ç°ä¸»è¦é  prompt å·¥ç¨‹ã€‘\nå‚è€ƒ # ReAct # hotpotqa.ipynb Reflexion # reflexion.ipynb git ã€è®ºæ–‡é˜…è¯»ã€‘Reflexion: å¤§æ¨¡å‹å¦‚ä½•ä»é”™è¯¯ç»éªŒä¸­å­¦ä¹ ï¼Ÿ 1xx. Reflection Agents\nLangGraphï¼šReflection Agents å®æˆ˜ V\n1xx. Reflexion: å¸¦è¨€è¯­å¼ºåŒ–å­¦ä¹ çš„è¯­è¨€æ™ºä½“\nxxx # Agentå››å¤§èŒƒå¼ | CRITICï¼šå´æ©è¾¾åŠ›æ¨Agentè®¾è®¡èŒƒå¼\nPractice # Translation Agent: Agentic translation using reflection workflow\n"},{"id":102,"href":"/www6vAIGC/docs/FineTuning/Data/Data-Quality/Instruction-Complexity/DataWizard/","title":"(åŸç†)Wizard","section":"Instruction Complexity","content":"\nWizard æ–¹æ³• # è‡ªåŠ¨æŒ‡ä»¤æ•°æ®è¿›åŒ– [1] # 1ï¼‰æŒ‡ä»¤è¿›åŒ–\nIn-Depth Evolving æç¤º [æ·±åº¦] äº”ç§ç±»å‹çš„æç¤ºæ¥å¢å¼ºæŒ‡ä»¤ å¢åŠ çº¦æŸ + æ·±åŒ– + å…·ä½“åŒ– + å¢åŠ æ¨ç†æ­¥éª¤ + å¤æ‚åŒ–è¾“å…¥ æ ¸å¿ƒéƒ¨åˆ† In-Depth Evolvingçš„æç¤ºçš„æ ¸å¿ƒéƒ¨åˆ†æ˜¯ \u0026ldquo;ä½ çš„ç›®æ ‡æ˜¯å°†ä¸€ä¸ªç»™å®šçš„æç¤ºæ”¹å†™æˆæ›´å¤æ‚çš„ç‰ˆæœ¬ï¼Œä½¿é‚£äº›è‘—åçš„äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼ˆå¦‚ChatGPTå’ŒGPT4ï¼‰æ›´éš¾å¤„ç†ã€‚ä½†æ”¹å†™åçš„æç¤ºå¿…é¡»æ˜¯åˆç†çš„ï¼Œèƒ½è¢«äººç†è§£ï¼Œå¹¶èƒ½è¢«äººå›åº”\u0026rdquo; In-Breadth Evolvingæç¤º [å¹¿åº¦] ç›®çš„ æ—¨åœ¨æé«˜ä¸»é¢˜è¦†ç›–ç‡ã€æŠ€èƒ½è¦†ç›–ç‡å’Œæ•´ä½“æ•°æ®é›†çš„å¤šæ ·æ€§ 2ï¼‰å“åº”ç”Ÿæˆ\n3ï¼‰æ¶ˆé™¤è¿›åŒ– å³è¿‡æ»¤æœªèƒ½è¿›åŒ–çš„æŒ‡ä»¤\nå‚è€ƒ # è´¨é‡-\u0026gt; å¤šæ ·æ€§, å¤æ‚åº¦ # å¦‚ä½•æ„é€ å¤æ‚å¤šæ ·çš„å¾®è°ƒæŒ‡ä»¤æ•°æ®ï¼šWizardLMå¤æ‚æŒ‡ä»¤æ„é€ æ€æƒ³ä¸å®éªŒåˆ†æå·¥ä½œæ€»ç»“ WizardLM git "},{"id":103,"href":"/www6vAIGC/docs/Agent/Platform/AgentList/","title":"(List)Agent äº§å“ å¹³å°","section":"Platform *","content":"\nåº”ç”¨ # åˆ†ç±» [10][11][12] # Action agents\nFunction Call ReACT Simulation agents ç”Ÿæˆå¼æ™ºèƒ½ä½“ï¼Œ CAMELï¼Œ Generative Agents\nAutomomous Agent AutoGPTï¼Œ BabyAGI, AutoGen MetaGPT ChatDev\nè·¨æ¨¡æ€Agents HuggingGPT\nHuggingGPT # BabyAGI [AIGC] # Plan-and-execute agents The planning is almost always done by an LLM. The execution is usually done by a separate agent (equipped with tools).\nAutoGPT[10] # AutoGPT çš„æ ¸å¿ƒé€»è¾‘æ˜¯ä¸€ä¸ª Prompt Loopï¼Œæ­¥éª¤å¦‚ä¸‹\nAutoGPT ä¼šåŸºäºä¸€å®šç­–ç•¥è‡ªåŠ¨ç»„è£… Command Promptï¼Œè¿™äº›é¦–æ¬¡ä¼šåŒ…å«ç”¨æˆ·è¾“å…¥çš„ Name, Roleå’ŒGoals Command Prompt çš„ç›®æ ‡ä¸æ˜¯ä¸ºäº†æ‹¿åˆ°æœ€ç»ˆç»“æœï¼Œè€Œæ˜¯é€šè¿‡ GPT Chat API(Thinking çš„è¿‡ç¨‹)è¿”å›ä¸‹ä¸€æ­¥çš„ Command (åŒ…å«nameå’Œarguments, å¦‚browser_website(url = \u0026quot;www.baidu.com\u0026quot;) ) è¿™äº› Command éƒ½æ˜¯å¯æ‰©å±•çš„ï¼Œæ¯ä¸€ç§å‘½ä»¤ä»£è¡¨ä¸€ç§å¤–éƒ¨èƒ½åŠ›(æ¯”å¦‚çˆ¬è™«ã€Googleæœç´¢ï¼Œä¹ŸåŒ…æ‹¬GPTçš„èƒ½åŠ›)ï¼Œé€šè¿‡è¿™äº› Command è°ƒç”¨è¿”å›çš„ Result åˆä¼šæˆä¸ºåˆ° Command Prompt çš„ç»„æˆå…ƒç´ ï¼Œ å›åˆ°ç¬¬ 1 æ­¥å¾€å¤å¾ªç¯ï¼Œç›´åˆ°æ‹¿åˆ°æœ€ç»ˆç»“æœç»“æœï¼ˆçŠ¶æ€ä¸ºâ€œcompeleteâ€ï¼‰ Platform[20] # å­—èŠ‚ Coze[21,22] # ä¼˜åŠ¿: æœ‰RAGï¼Œç»“æ„åŒ–æ•°æ®\nåŠ£åŠ¿: åªèƒ½å‘å¸ƒåˆ°é£ä¹¦ï¼Œå¾®ä¿¡\nç™¾åº¦ AppBuilder # Dify # å‚è€ƒ # 1xx. ã€ŒAgentã€é€šä¿—æ˜“æ‡‚åœ°èŠèŠAI Agentï¼ˆé™„66ä¸ªå¼€æº+44ä¸ªé—­æºAgenté¡¹ç›®ï¼‰\n1xx. ä¸»æµAgentæ¡†æ¶åŠé‡‘èAgent-FinRobotï¼šå…¼çœ‹é¢å‘å®ä½“å¢å¼ºçš„ç»†ç²’åº¦å®ä½“æè¿°çŸ¥è¯†åº“é¡¹ç›® Agent-FinRobot åŸºäºautogen å®ç°\nxxx # 2023å¹´æ–°ç”Ÿä»£å¤§æ¨¡å‹AgentsæŠ€æœ¯,ReAct,Self-Ask,Plan-and-execute,ä»¥åŠAutoGPT, HuggingGPTç­‰åº”ç”¨ *** è®ºæ–‡+ä»£ç  å…¬å¼€è¯¾ å…¬å¼€è¯¾ Platform # AgentBuilder ä¸­å°ä¼ä¸šå¦‚ä½•é€‰æ‹©ï¼šcozeã€difyã€appbuilderã€æ¯•æ™Ÿ V COZEï¼šä¸­å°ä¼ä¸šå‡å¯0é—¨æ§›åˆ›å»ºä¸šåŠ¡agent V åˆ©ç”¨Coze å®ç°å´æ©è¾¾çš„4ç§ AI Agent è®¾è®¡æ¨¡å¼ äº§å“ \u0026amp;è°ƒç ” # 1xx. 2024 å¹´æœ€å®Œæ•´çš„ AI Agents æ¸…å•æ¥äº†ï¼Œæ¶‰åŠ 13 ä¸ªé¢†åŸŸï¼Œä¸Šç™¾ä¸ª Agentsï¼ å¼€æº é—­æº ***\n1xx. å…¨çƒAI Agentå¤§ç›˜ç‚¹ï¼Œå¤§è¯­è¨€æ¨¡å‹åˆ›ä¸šä¸€å®šè¦å‚è€ƒçš„60ä¸ªAIæ™ºèƒ½ä½“\n1xx. å¤§æ¨¡å‹æ—¶ä»£çš„APP\u0026ndash;2024å¹´ AI Agentè¡Œä¸šæŠ¥å‘Š ***\nmodelscope-agent AgentFabric # 1xx. LLM å¤§æ¨¡å‹å­¦ä¹ å¿…çŸ¥å¿…ä¼šç³»åˆ—(å)ï¼šåŸºäºAgentFabricå®ç°äº¤äº’å¼æ™ºèƒ½ä½“åº”ç”¨,Agentå®æˆ˜-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘\n1xx. modelscope-agent/apps/agentfabric at master Â· modelscope/modelscope-agent\n1xx. Modelscope Agentå®æ“ï¼ˆä¸€ï¼‰ï¼š0ä»£ç åˆ›å»ºã€å‘å¸ƒå¹¶åˆ†äº«ä¸€ä¸ªä¸“å±Agent\n1xx. ä»agentfabricå¼€å§‹ä½“éªŒé­”æ­Agent\n1xx. ç¤¾åŒºä¾›ç¨¿ | GLM-4é€‚é…ModelScope-Agentæœ€ä½³å®è·µ\n"},{"id":104,"href":"/www6vAIGC/docs/FineTuning/Data/Task-composition/DatasetSFT/","title":"(åŸç†)SFT æ•°æ®ç»„åˆ *","section":"Task composition","content":"\nè®ºæ–‡ # è®ºæ–‡åœ°å€ ã€ŠHOW ABILITIES IN LARGE LANGUAGE MODELS ARE AFFECTED BY SUPERVISED FINE-TUNING DATA COM- POSITIONã€‹\nkeyword: SFT æ•°æ®ç»„åˆ é—®é¢˜[1] # 1ã€æ¨ç†ã€ç¼–ç å’Œé€šç”¨èƒ½åŠ›å¦‚ä½•éšSFTæ•°æ®é‡è€Œå˜åŒ–ï¼Ÿ\n2ã€åœ¨SFTä¸­ç»“åˆä¸‰ç§èƒ½åŠ›æ—¶æ˜¯å¦å­˜åœ¨æ€§èƒ½å†²çªï¼Ÿ\n3ã€å¯¼è‡´æ€§èƒ½å†²çªçš„å…³é”®å› ç´ æ˜¯ä»€ä¹ˆï¼Ÿ\n4ã€ä¸åŒçš„SFTç­–ç•¥å¯¹ç»„åˆæ•°æ®æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ\nå®éªŒç»“æœ[1] # 1ã€ä¸åŒçš„èƒ½åŠ›è¡¨ç°å‡ºä¸åŒçš„æ‰©å±•æ¨¡å¼ï¼Œåœ¨æ•°æ®é‡ç›¸åŒçš„æƒ…å†µä¸‹ï¼Œè¾ƒå¤§çš„æ¨¡å‹é€šå¸¸è¡¨ç°å‡ºæ›´ä¼˜è¶Šçš„æ€§èƒ½ã€‚\n2ã€éšç€æ•°æ®é‡çš„æŒç»­å¢åŠ ï¼Œæ•°å­¦æ¨ç†å’Œä»£ç ç”Ÿæˆèƒ½åŠ›ä¹Ÿåœ¨ä¸æ–­æé«˜ï¼Œä¸€èˆ¬èƒ½åŠ›åˆ™æ˜¯åœ¨æ ·æœ¬æ•°è¾¾åˆ°ä¸€åƒå·¦å³æ—¶æ‰å¾—åˆ°æå‡ï¼Œä¸”æå‡é€Ÿåº¦è¾ƒæ…¢ã€‚\n3ã€åœ¨æ•°æ®é‡è¾ƒä½çš„æƒ…å†µä¸‹ï¼Œæ•°æ®ç»„åˆä¼šå¸¦æ¥å„ç§èƒ½åŠ›çš„æé«˜ï¼Œè€Œåœ¨æ•°æ®é‡è¾ƒé«˜çš„æƒ…å†µä¸‹ï¼Œèƒ½åŠ›åˆ™ä¼šå‘ç”Ÿå†²çªã€‚\n4ã€ç»„æˆæ•°æ®é‡ä¼šå½±å“æ€§èƒ½ï¼Œè€Œç»„æˆæ¯”ä¾‹çš„å½±å“åˆ™å¾®ä¹å…¶å¾®ã€‚\nã€æ¨¡å‹å¤§å°ã€‘\nã€æ•°æ®æ•°é‡ã€‘\nã€æ•°æ®æ•°é‡ \u0026lt;\u0026ndash;\u0026gt; å¤šæ ·æ€§ã€‘ï¼Ÿ\nã€ç»„æˆæ¯”ä¾‹ã€‘\né—®é¢˜2 åœ¨SFTä¸­ç»“åˆä¸‰ç§èƒ½åŠ›æ—¶æ˜¯å¦å­˜åœ¨æ€§èƒ½å†²çªï¼Ÿ[kimi][paper] # é—®é¢˜2 æ¢è®¨çš„æ˜¯åœ¨ç›‘ç£å¼å¾®è°ƒï¼ˆSupervised Fine-Tuning, SFTï¼‰ä¸­ç»“åˆæ¨ç†ã€ç¼–ç å’Œé€šç”¨èƒ½åŠ›æ—¶æ˜¯å¦å­˜åœ¨æ€§èƒ½å†²çªã€‚\nç»“è®ºï¼š # æ€§èƒ½å†²çªçš„å­˜åœ¨ï¼šåœ¨é«˜èµ„æºè®¾ç½®ä¸‹ï¼Œå³å½“SFTæ•°æ®é›†æ··åˆä½¿ç”¨æ—¶ï¼Œä¸åŒèƒ½åŠ›é¢†åŸŸï¼ˆå¦‚æ•°å­¦æ¨ç†ã€ç¼–ç å’Œé€šç”¨å¯¹é½èƒ½åŠ›ï¼‰ä¹‹é—´ä¼šå‘ç”Ÿæ€§èƒ½å†²çªã€‚ç„¶è€Œï¼Œåœ¨ä½èµ„æºè®¾ç½®ä¸‹ï¼Œæ··åˆæ•°æ®æºèƒ½å¤Ÿæå‡æ€§èƒ½ã€‚ æ€§èƒ½å†²çªä¸èµ„æºé‡çš„å…³ç³»ï¼šéšç€æ•°æ®é‡çš„å¢åŠ ï¼Œç‰¹å®šä»»åŠ¡çš„æ€§èƒ½å¯èƒ½ä¼šå› ä¸ºå…¶ä»–ä»»åŠ¡çš„å­˜åœ¨è€Œä¸‹é™ã€‚è¿™è¡¨æ˜åœ¨æ•°æ®é‡è¾ƒå¤§æ—¶ï¼Œä¸åŒä»»åŠ¡ä¹‹é—´å¯èƒ½ä¼šç›¸äº’å¹²æ‰°ï¼Œå¯¼è‡´æ€§èƒ½å†²çªã€‚ æ¨¡å‹å¤§å°å¯¹æ€§èƒ½çš„å½±å“ï¼šéšç€æ¨¡å‹å¤§å°çš„å¢åŠ ï¼Œåœ¨ä½èµ„æºè®¾ç½®ä¸‹ï¼Œæ•°å­¦å’Œé€šç”¨èƒ½åŠ›çš„æ€§èƒ½æå‡æ›´åŠ æ˜æ˜¾ã€‚ é—®é¢˜3 å¯¼è‡´æ€§èƒ½å†²çªçš„å…³é”®å› ç´ æ˜¯ä»€ä¹ˆï¼Ÿ[kimi][paper] # åœ¨SFTï¼ˆç›‘ç£å¼å¾®è°ƒï¼‰ä¸­ç»“åˆæ¨ç†ã€ç¼–ç å’Œé€šç”¨èƒ½åŠ›æ—¶ï¼Œå¯¼è‡´æ€§èƒ½å†²çªçš„å…³é”®å› ç´ åŒ…æ‹¬ï¼š\næ•°æ®ç»„æˆå’Œæ¯”ä¾‹ï¼šå½“ä¸åŒèƒ½åŠ›é¢†åŸŸçš„æ•°æ®æ··åˆåœ¨ä¸€èµ·è¿›è¡ŒSFTæ—¶ï¼Œå¦‚æœæ•°æ®é‡å……è¶³ï¼Œæ¥è‡ªå…¶ä»–é¢†åŸŸçš„æ•°æ®å¯èƒ½ä¼šè¢«è§†ä¸ºå™ªå£°ï¼Œä»è€Œå½±å“ç‰¹å®šé¢†åŸŸçš„æ€§èƒ½ã€‚ æ¨¡å‹å¤§å°ï¼šè¾ƒå¤§çš„æ¨¡å‹åœ¨ç›¸åŒæ•°æ®é‡ä¸‹é€šå¸¸è¡¨ç°æ›´å¥½ï¼Œå¹¶ä¸”åœ¨ä½èµ„æºè®¾ç½®ä¸‹å¯¹äºæ•°å­¦å’Œé€šç”¨èƒ½åŠ›çš„æ€§èƒ½å¢ç›Šæ›´å¤§ã€‚ è®­ç»ƒç­–ç•¥ï¼šå¤šä»»åŠ¡å­¦ä¹ è™½ç„¶èƒ½å¤Ÿä¿ç•™ä¸“ä¸šèƒ½åŠ›ï¼Œä½†å¯¹é€šç”¨èƒ½åŠ›çš„ä¼¤å®³æœ€å¤§ï¼›è€Œé¡ºåºè®­ç»ƒå’Œæ··åˆé¡ºåºè®­ç»ƒè™½ç„¶ä¿ç•™äº†é€šç”¨èƒ½åŠ›ï¼Œä½†ä¼šä¸¢å¤±å¤ªå¤šçš„ä¸“ä¸šèƒ½åŠ›ã€‚ æ•°æ®é‡ä¸èƒ½åŠ›çš„å…³ç³»ï¼šæ•°å­¦æ¨ç†å’Œç¼–ç èƒ½åŠ›éšç€æ•°æ®é‡çš„å¢åŠ è€ŒæŒç»­æé«˜ï¼Œè€Œé€šç”¨èƒ½åŠ›åœ¨å¤§çº¦ä¸€åƒä¸ªæ ·æœ¬åè¶‹äºå¹³ç¨³ã€‚ ä»»åŠ¡ç‰¹æ€§å·®å¼‚ï¼šæ¨ç†å’Œç¼–ç ä»»åŠ¡éœ€è¦å¤æ‚çš„é€»è¾‘æ¥åˆ†è§£ä»»åŠ¡æŒ‡ä»¤å’Œå¤„ç†éè¯­è¨€å’Œç¬¦å·ç‰¹å¾ï¼Œè€Œå¯¹é½äººç±»æ„å›¾åˆ™éœ€è¦å¤šæ ·æ€§å’Œç†è§£æ¨¡ç³Šçš„äººç±»æŒ‡ä»¤ã€‚ ç›¸åº”çš„ç»“è®ºåŒ…æ‹¬ï¼š\nåœ¨ä½èµ„æºè®¾ç½®ä¸‹ï¼Œæ··åˆæ•°æ®æºå¯ä»¥æé«˜æ€§èƒ½ï¼Œä½†åœ¨é«˜èµ„æºè®¾ç½®ä¸‹ï¼Œå¯èƒ½ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚ æ•°æ®é‡ç›´æ¥å½±å“åŠ›èƒ½è¡¨ç°ï¼Œè€Œæ•°æ®æ¯”ä¾‹çš„å½±å“ä¸æ˜¾è‘—ã€‚ æå‡ºçš„åŒé˜¶æ®µæ··åˆå¾®è°ƒï¼ˆDMTï¼‰ç­–ç•¥æœ‰æ•ˆåœ°å‡è½»äº†å¤šä»»åŠ¡å­¦ä¹ ä¸­çš„æ€§èƒ½å†²çªå’Œé¡ºåºè®­ç»ƒä¸­çš„ç¾éš¾æ€§é—å¿˜ï¼Œå®ç°äº†é€šç”¨ä¸ä¸“ä¸šèƒ½åŠ›ä¹‹é—´çš„å¹³è¡¡ã€‚ è¿™äº›ç»“è®ºå¼ºè°ƒäº†åœ¨SFTé˜¶æ®µç†è§£å’Œè§£å†³æ•°æ®ç»„æˆé—®é¢˜å¯¹äºå…¨é¢æé«˜LLMsï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼‰çš„èƒ½åŠ›è‡³å…³é‡è¦ã€‚\nå‚è€ƒ # SFTå¾®è°ƒçš„æ•°æ®ç»„åˆåŠè®­ç»ƒç­–ç•¥å¦‚ä½•å½±å“å¤§æ¨¡å‹æ€§èƒ½ï¼š4ä¸ªç»å…¸é—®é¢˜åŠå®éªŒç»“è®ºåˆ†äº« 1xx. å†çœ‹å¤§æ¨¡å‹å¾®è°ƒä¸åº”ç”¨ï¼š3å¤§è¡Œä¸š18ä¸ªå¼€æºå‚ç›´å¾®è°ƒæ¨¡å‹ã€å¾®è°ƒæ•°æ®ã€å·¥å…·èµ„æºåŠæœ‰è¶£çš„AIGCåº”ç”¨é›†åˆ äºŒ ä¸‰\n1xx. ä¹Ÿè°ˆå¤§æ¨¡å‹ç ”å‘ä¸­çš„å¾®è°ƒæ•°æ®è§„æ¨¡è¯„ä¼°ä¸è´¨é‡é—®é¢˜ï¼šæ•°æ®è§„æ¨¡å¤§å°çš„å½±å“è¯„ä¼°ã€æ•°æ®ä¸»è¦é—®é¢˜åŠæ¸…æ´—é¡¹ç›®\n1xx. ä¹Ÿè°ˆå¾®è°ƒæ•°æ®è´¨é‡ã€å¤šæ ·æ€§è§„æ¨¡å¯¹å¤§æ¨¡å‹æ€§èƒ½çš„å½±å“ä¸è¯„ä¼°æ–¹æ¡ˆï¼šBelleé¡¹ç›®å¼€æºå®éªŒå·¥ä½œæŠ¥å‘Šä»‹ç»\n"},{"id":105,"href":"/www6vAIGC/docs/FineTuning/PEFT/Lora/PEFTLora/","title":"(å®æˆ˜) Lora +","section":"Lora","content":"\nLora å®æˆ˜ # (å®æˆ˜) Lora "}]