<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dataset on 基于LLM的系统设计与实现</title>
    <link>https://www6v.github.io/www6vAIGC/tags/dataset/</link>
    <description>Recent content in Dataset on 基于LLM的系统设计与实现</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Thu, 27 Apr 2023 17:22:35 +0000</lastBuildDate>
    <atom:link href="https://www6v.github.io/www6vAIGC/tags/dataset/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>(原理)SFT Scaling</title>
      <link>https://www6v.github.io/www6vAIGC/docs/FineTuning/Data/DataSFTScaling/</link>
      <pubDate>Wed, 26 Apr 2023 16:55:39 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAIGC/docs/FineTuning/Data/DataSFTScaling/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;论文&#34;&gt;&#xA;  论文&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e8%ae%ba%e6%96%87&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;论文地址&#xA;《When Scaling Meets LLM Fine-tuning: The Effect of Data, Model and Fine-tuning Method》&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;摘要1&#34;&gt;&#xA;  摘要[1]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e6%91%98%e8%a6%811&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;这篇论文研究了大型语言模型（LLMs）的微调（finetuning）问题，尤其是在不同规模因素下的微调性能。作者探讨了包括LLM模型大小、预训练数据大小、新微调参数大小和微调数据大小在内的多个因素，并考虑了两种微调方法：全模型微调（FMT）和参数高效微调（PET，包括prompt tuning和LoRA）。研究发现LLM微调遵循基于&lt;strong&gt;功率的乘法联合规模法则&lt;/strong&gt;，&lt;strong&gt;LLM模型规模的增加对微调性能的提升大于预训练数据规模的增加，而PET参数规模的增加通常效果不佳&lt;/strong&gt;。此外，&lt;strong&gt;微调方法的选择高度依赖于具体任务和微调数据&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;p&gt;【 功率的乘法联合规模法则: 微调数据数量 &amp;lt;&amp;ndash;&amp;gt; xxx】&lt;br&gt;&#xA;【模型大小(标题里的Model ) &amp;gt; 预训练数据(标题里的Data),   PET参数(标题里的Fine-tuning Method) 无效】&lt;br&gt;&#xA;【微调方法的选择高度依赖于具体任务和微调数据】&lt;/p&gt;&#xA;&lt;h1 id=&#34;实验方法1&#34;&gt;&#xA;  实验方法[1]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%ae%9e%e9%aa%8c%e6%96%b9%e6%b3%951&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;实验基于两组预训练的双语LLMs（英语&amp;amp;德语，英语&amp;amp;中文），模型大小从1B到16B。作者在WMT机器翻译（英语-德语、英语-中文）和多语言摘要（英语、德语、法语和西班牙语）任务上进行了大规模研究，最多使用20M微调示例。实验设置包括：&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;下游任务&lt;/strong&gt;：选择机器翻译和多语言摘要作为微调的下游任务。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;LLMs和预训练&lt;/strong&gt;：采用解码器仅Transformer模型，使用修改后的UL2目标进行训练。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;微调设置&lt;/strong&gt;：研究了三种微调方法（FMT、Prompt和LoRA），并探索了四种不同的规模因素。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;评估&lt;/strong&gt;：使用基于token级别的困惑度（PPL）选择最佳检查点进行评估，并使用BLEURT和RougeL评估生成质量。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;结论1&#34;&gt;&#xA;  结论[1]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e7%bb%93%e8%ae%ba1&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;提出了一个乘法联合规模法则来描述微调数据大小和其他规模因素之间的规模关系。&lt;/li&gt;&#xA;&lt;li&gt;LLM模型规模的增加对微调性能的提升大于预训练数据规模的增加。&lt;/li&gt;&#xA;&lt;li&gt;PET参数规模的增加对于LoRA和Prompt的效果有限，且有时甚至会导致反向规模效应。&lt;/li&gt;&#xA;&lt;li&gt;微调方法的选择对于下游任务来说并不简单，需要根据任务特性和微调数据的可用性来决定。&lt;/li&gt;&#xA;&lt;li&gt;微调可能会提高模型对相关任务的零样本泛化能力，尤其是当基础LLM较大时，Prompt和LoRA通常比FMT表现得更好。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;作者指出，尽管研究提供了有价值的见解，但也存在一些局限性，如联合规模法则主要基于封闭生成任务的实证结果，缺乏理论基础。未来的工作将扩展到多模态LLMs，探索微调数据质量的影响，并考虑开放和创造性的生成任务以及微调的多任务设置。&lt;/p&gt;&#xA;&lt;h1 id=&#34;重要结论2&#34;&gt;&#xA;  重要结论[2]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e9%87%8d%e8%a6%81%e7%bb%93%e8%ae%ba2&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;作者们探讨了大型语言模型（LLMs）在微调（finetuning）过程中不同规模因素对性能的影响。以下是论文的一些重要结论及其对“SCALING”概念的解释：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;乘法联合缩放法则&lt;/strong&gt;：作者提出了一个基于&lt;strong&gt;乘法的联合缩放法则（multiplicative joint scaling law）&lt;/strong&gt;，用于描述微调数据大小与其他缩放因素（如LLM模型大小、预训练数据大小、PET参数大小）之间的关系。这个法则表明，&lt;strong&gt;微调性能与这些因素的乘法组合有关&lt;/strong&gt;，而不是简单的加法关系。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;模型大小对微调的影响&lt;/strong&gt;：研究发现，&lt;strong&gt;增加LLM模型的大小对微调性能的提升比增加预训练数据的大小更为显著&lt;/strong&gt;。这表明在有限资源下，&lt;strong&gt;优先考虑扩大模型规模而不是数据规模&lt;/strong&gt;，可能会带来更好的微调效果。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;参数高效微调（PET）的局限性&lt;/strong&gt;：尽管PET方法（如prompt tuning和LoRA）旨在通过优化少量参数来提高性能，但研究发现&lt;strong&gt;增加PET参数的大小对于微调性能的提升效果有限，有时甚至会出现反向缩放现象&lt;/strong&gt;。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;任务和数据依赖性&lt;/strong&gt;：微调的缩放特性高度依赖于具体任务和数据。这意味着&lt;strong&gt;没有一种通用的最优微调方法&lt;/strong&gt;，选择哪种微调方法需要根据下游任务的特性和可用的微调数据量来决定。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;微调对零样本泛化能力的影响&lt;/strong&gt;：尽管微调通常是为了提高特定任务的性能，但研究发现，基于LLM的微调仍然可以促进对相关任务的零样本泛化能力。特别是PET方法在保留模型的泛化能力方面表现更好。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;微调数据量的临界点&lt;/strong&gt;：论文中还讨论了不同微调方法之间的临界点，即在特定的微调数据量下，一种方法可能比另一种方法表现得更好。这个临界点会随着任务和模型大小的不同而变化。&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;这些结论对理解LLM微调过程中的“SCALING”具有重要意义。它们揭示了不同规模因素如何相互作用以及它们对微调性能的共同影响，为在实际应用中选择和优化微调策略提供了理论依据。通过这些发现，研究者和实践者可以更好地理解在特定条件下如何有效地缩放和配置他们的模型以获得最佳性能。&lt;/p&gt;</description>
    </item>
    <item>
      <title>(原理)LIMA, LESS</title>
      <link>https://www6v.github.io/www6vAIGC/docs/FineTuning/Data/Data-Quality/Instruction-Quality/DataSFTQuality/</link>
      <pubDate>Thu, 27 Apr 2023 17:22:35 +0000</pubDate>
      <guid>https://www6v.github.io/www6vAIGC/docs/FineTuning/Data/Data-Quality/Instruction-Quality/DataSFTQuality/</guid>
      <description>&lt;p&gt;&lt;/p&gt;&#xA;&lt;!-- more --&gt;&#xA;&lt;h1 id=&#34;lima-1kimi&#34;&gt;&#xA;  LIMA [1][kimi]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#lima-1kimi&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;LIMA（Less Is More for Alignment）的实验通过一系列设计精良的步骤来探究数据质量、多样性以及数量对模型性能的影响，从而得出了&lt;strong&gt;提高数据质量和增加提示多样性比单纯增加数据量更能提升模型性能的结论&lt;/strong&gt;。以下是&lt;strong&gt;实验方法&lt;/strong&gt;的关键步骤：&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;精心策划的微调数据&lt;/strong&gt;：LIMA模型在&lt;strong&gt;1000个&lt;/strong&gt;精心策划的提示和回复上进行了&lt;strong&gt;微调&lt;/strong&gt;，这些数据被设计为模拟真实用户与AI助手的交互。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;消融实验&lt;/strong&gt;：通过消融实验，研究者们观察了在增加数据量的同时不增加提示多样性时，模型性能的提升是否有限；而在优化数据质量时，性能是否有显著提升。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;数据构造&lt;/strong&gt;：研究者从Stack Exchange、wikiHow和Pushshift Reddit数据集收集数据，并进行了&lt;strong&gt;质量和多样性&lt;/strong&gt;的控制。这些数据集被用来构造训练样本，以确保输入的多样性和输出的一致性。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;质量与多样性的对比&lt;/strong&gt;：研究者比较了经过质量过滤的Stack Exchange数据和同质化的wikiHow数据对模型性能的影响。结果显示，更&lt;strong&gt;多样化的Stack Exchange数据在性能上优于同质化的wikiHow数据&lt;/strong&gt;。 【多样化】&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;数量的对比&lt;/strong&gt;：研究者对从Stack Exchange抽取的指数级增加的训练集进行了测试，发现&lt;strong&gt;训练集的翻倍并没有改善响应质量&lt;/strong&gt;，从而说明单纯增加数据量并不一定能提升性能。【数量】&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;质量控制的实验&lt;/strong&gt;：研究者还比较了未经过任何质量或风格过滤的Stack Exchange数据集与经过过滤的数据集上训练的模型性能，发现&lt;strong&gt;过滤后&lt;/strong&gt;的数据集上训练的模型性能&lt;strong&gt;更优&lt;/strong&gt;。【质量】&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;人类评估&lt;/strong&gt;：为了评估LIMA模型的性能，研究者进行了人类偏好研究，将LIMA的输出与其他几个基线模型的输出进行比较，并让人群工作者选择他们更喜欢的输出。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;通过这些实验步骤，LIMA的研究得出了&lt;strong&gt;数据质量和提示多样性对于提升模型性能的重要性远超过单纯增加数据量的结论&lt;/strong&gt;。这些发现支持了“浅层对齐假说”，即模型在预训练阶段已经学习到了几乎所有知识和能力，而微调过程主要是学习与人类交互的风格和格式。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;总结 [1]&lt;/p&gt;&#xA;&lt;p&gt;消融实验显示，&lt;strong&gt;当扩大数据量而不同时扩大提示多样性时，收益会大大减少，而在优化数据质量时，收益会大大增加&lt;/strong&gt;&#xA;【&lt;strong&gt;数量&lt;/strong&gt; &amp;lt;&amp;ndash;&amp;gt; &lt;strong&gt;多样性&lt;/strong&gt;  &lt;strong&gt;质量&lt;/strong&gt;】&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;less-核心思想-10&#34;&gt;&#xA;  LESS 核心思想 [10]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#less-%e6%a0%b8%e5%bf%83%e6%80%9d%e6%83%b3-10&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;通过仅给出&lt;strong&gt;少数体现特定能力的示例&lt;/strong&gt;，从大量指令数据集中&lt;strong&gt;有效地选择5%有影响力的数据&lt;/strong&gt;用于目标指令微调，结果优于全量数据集进行微调，并且所选子集在不同模型参数规模和不同模型系列中仍然普遍有效。&lt;/p&gt;&#xA;&lt;h1 id=&#34;less10kimi&#34;&gt;&#xA;  LESS[10][kimi]&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#less10kimi&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;LESS（Selecting Influential Data for Targeted Instruction Tuning）的实验方法和相应的结论如下：&lt;/p&gt;&#xA;&lt;h3 id=&#34;实验方法&#34;&gt;&#xA;  实验方法：&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e5%ae%9e%e9%aa%8c%e6%96%b9%e6%b3%95&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;热身训练（Warmup Training）&lt;/strong&gt;：使用LoRA（Low-Rank Adaptation）技术对预训练模型进行热身训练，以适应特定的数据分布。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;梯度数据存储（Gradient Data Store）&lt;/strong&gt;：构建了一个具有投影低维梯度特征的梯度数据存储，该存储可以重复用于不同的目标任务。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;数据选择算法&lt;/strong&gt;：利用数据存储和算法选择与体现特定能力的少数示例最相似的训练数据点。?&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;模型训练&lt;/strong&gt;：使用选择的数据子集来训练目标模型。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;评估&lt;/strong&gt;：在不同的下游任务上评估LESS选择的数据子集的性能，包括MMLU、TYDIQA和BBH数据集。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;结论&#34;&gt;&#xA;  结论：&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#%e7%bb%93%e8%ae%ba&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;LESS的有效性&lt;/strong&gt;：LESS&lt;strong&gt;在不同的模型中都是有效的&lt;/strong&gt;，能够在多个评估数据集上提高性能。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;数据子集的性能&lt;/strong&gt;：&lt;strong&gt;使用LESS选择的5%的数据通常优于使用完整数据集进行训练的结果&lt;/strong&gt;。这表明完整数据集可能包含与特定目标任务无关或有害的数据点。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;数据的可转移性&lt;/strong&gt;：使用较小模型选择的数据可以提高较大模型和不同模型系列的性能，证明了LESS选择的数据具有高度的可转移性。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;与其他方法的比较&lt;/strong&gt;：LESS是唯一一致有效的方法，相较于其他基线方法（如随机选择、BM25、DSIR、RDS）表现出更好的性能。&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;计算成本&lt;/strong&gt;：LESS的计算成本较高，但由于其有效性，这一成本是合理的。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
